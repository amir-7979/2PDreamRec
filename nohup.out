Tuning lr:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 65.0791; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.8702; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.5129; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.3921; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.3437; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 2.4850; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.2570; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.1902; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.1692; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1550; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.531457   0.399347   0.600993   0.421363  
Loss: 0.1548
Fold 1 Epoch 011; Train loss: 0.1467; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1369; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.1311; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.1275; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.1215; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.1157; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.1155; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.1070; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.1071; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.1027; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.460265   0.368133   0.526490   0.389548  
Loss: 0.1115
Fold 1 Epoch 021; Train loss: 0.1001; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.0947; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.0909; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.0858; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.0868; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.0833; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.0806; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.0781; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.0737; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0714; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.485099   0.356260   0.554636   0.378972  
Loss: 0.0791
Fold 1 Epoch 031; Train loss: 0.0702; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0682; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0665; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0651; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0630; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0610; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0591; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0550; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0545; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0532; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.418874   0.280297   0.543046   0.319553  
Loss: 0.0548
Fold 1 Epoch 041; Train loss: 0.0522; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0490; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0513; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0551; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0620; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0702; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0657; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0513; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0434; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0402; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.408940   0.302629   0.518212   0.337877  
Loss: 0.0384
Fold 1 Epoch 051; Train loss: 0.0376; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0374; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0364; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0361; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0350; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0342; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0329; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0340; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0310; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0304; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.458609   0.359425   0.604305   0.405817  
Loss: 0.0359
Fold 1 Epoch 061; Train loss: 0.0303; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0297; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0316; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0339; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0372; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0390; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0348; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0283; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0254; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0249; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.503311   0.389105   0.675497   0.441504  
Loss: 0.0261
Fold 1 Epoch 071; Train loss: 0.0223; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0217; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0218; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0213; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0201; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0198; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0193; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0189; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0182; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0172; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.543046   0.377726   0.698675   0.429367  
Loss: 0.0188
Fold 1 Epoch 081; Train loss: 0.0173; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0169; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0158; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0153; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0151; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0140; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0130; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0130; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0123; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0148; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.548013   0.376961   0.773179   0.447615  
Loss: 0.0300
Fold 1 Epoch 091; Train loss: 0.0273; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0361; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0182; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0084; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0062; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0053; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0044; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0037; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0029; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0023; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.548013   0.314398   0.899007   0.425069  
Loss: 0.0029
[lr candidate 0.05] Fold 1: HR@10 = [np.float64(0.6009933774834437), np.float64(0.5264900662251656), np.float64(0.554635761589404), np.float64(0.543046357615894), np.float64(0.5182119205298014), np.float64(0.6043046357615894), np.float64(0.6754966887417219), np.float64(0.6986754966887417), np.float64(0.7731788079470199), np.float64(0.8990066225165563)]
Tuning lr:  25%|██▌       | 1/4 [01:30<04:31, 90.46s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 0.6517; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.2873; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.1995; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.1716; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.1597; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.1421; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.1343; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.1271; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.1246; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1210; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.407285   0.338232   0.567881   0.389339  
Loss: 0.1449
Fold 1 Epoch 011; Train loss: 0.1155; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1119; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.1085; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.1050; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.1019; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.0961; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.0938; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.0908; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.0865; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.0841; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.561258   0.439713   0.672185   0.475375  
Loss: 0.1119
Fold 1 Epoch 021; Train loss: 0.0839; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.0796; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.0776; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.0735; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.0699; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.0667; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.0642; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.0635; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.0622; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0593; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.543046   0.428453   0.736755   0.489964  
Loss: 0.0734
Fold 1 Epoch 031; Train loss: 0.0547; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0527; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0515; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0500; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0463; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0449; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0443; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0409; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0393; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0381; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.566225   0.431083   0.748344   0.489006  
Loss: 0.0480
Fold 1 Epoch 041; Train loss: 0.0363; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0339; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0328; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0294; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0287; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0274; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0271; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0243; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0231; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0215; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.475166   0.322046   0.745033   0.408111  
Loss: 0.0236
Fold 1 Epoch 051; Train loss: 0.0201; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0182; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0173; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0165; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0159; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0146; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0132; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0118; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0109; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0105; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.561258   0.303209   0.905629   0.421821  
Loss: 0.0137
Fold 1 Epoch 061; Train loss: 0.0098; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0091; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0080; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0075; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0068; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0061; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0057; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0051; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0047; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0040; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.556291   0.318917   0.902318   0.438427  
Loss: 0.0044
Fold 1 Epoch 071; Train loss: 0.0035; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0032; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0029; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0025; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0023; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0020; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0019; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0017; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0014; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0012; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.316053   0.894040   0.434605  
Loss: 0.0016
Fold 1 Epoch 081; Train loss: 0.0010; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0003; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.895695   0.437632  
Loss: 0.0007
Fold 1 Epoch 091; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0001; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0001; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.899007   0.438946  
Loss: 0.0004
[lr candidate 0.01] Fold 1: HR@10 = [np.float64(0.5678807947019867), np.float64(0.6721854304635762), np.float64(0.7367549668874173), np.float64(0.7483443708609272), np.float64(0.7450331125827815), np.float64(0.9056291390728477), np.float64(0.902317880794702), np.float64(0.8940397350993378), np.float64(0.8956953642384106), np.float64(0.8990066225165563)]
Tuning lr:  50%|█████     | 2/4 [02:59<02:59, 89.53s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 0.7860; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.4063; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.2839; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.2207; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.1958; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.1805; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.1662; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.1576; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.1530; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1485; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.508278   0.417251   0.690397   0.474750  
Loss: 0.1763
Fold 1 Epoch 011; Train loss: 0.1444; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1368; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.1374; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.1366; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.1304; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.1283; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.1254; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.1239; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.1216; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.1201; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.526490   0.445338   0.662252   0.488948  
Loss: 0.1427
Fold 1 Epoch 021; Train loss: 0.1161; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.1124; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.1108; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.1111; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.1084; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.1115; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.1066; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.1035; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.1013; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.1018; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.543046   0.450985   0.728477   0.510862  
Loss: 0.1255
Fold 1 Epoch 031; Train loss: 0.0979; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0984; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0971; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0950; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0942; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0930; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0894; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0859; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0852; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0854; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.518212   0.437317   0.652318   0.480406  
Loss: 0.1121
Fold 1 Epoch 041; Train loss: 0.0835; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0814; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0785; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0767; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0781; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0760; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0769; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0737; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0720; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0693; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.543046   0.447904   0.695364   0.496544  
Loss: 0.0911
Fold 1 Epoch 051; Train loss: 0.0675; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0682; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0665; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0672; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0646; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0622; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0624; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0593; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0575; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0566; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.513245   0.424116   0.690397   0.479840  
Loss: 0.0709
Fold 1 Epoch 061; Train loss: 0.0558; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0552; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0546; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0524; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0508; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0490; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0482; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0457; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0452; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0447; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.518212   0.421857   0.700331   0.478873  
Loss: 0.0528
Fold 1 Epoch 071; Train loss: 0.0432; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0432; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0405; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0402; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0396; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0374; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0374; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0365; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0354; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0325; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.526490   0.384732   0.716887   0.444727  
Loss: 0.0403
Fold 1 Epoch 081; Train loss: 0.0327; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0304; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0303; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0288; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0280; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0271; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0258; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0248; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0241; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0233; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.533113   0.386352   0.738411   0.452162  
Loss: 0.0264
Fold 1 Epoch 091; Train loss: 0.0224; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0212; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0206; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0202; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0191; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0184; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0176; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0164; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0163; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0152; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.506623   0.373507   0.822848   0.474398  
Loss: 0.0164
[lr candidate 0.005] Fold 1: HR@10 = [np.float64(0.6903973509933775), np.float64(0.6622516556291391), np.float64(0.7284768211920529), np.float64(0.652317880794702), np.float64(0.695364238410596), np.float64(0.6903973509933775), np.float64(0.7003311258278145), np.float64(0.7168874172185431), np.float64(0.7384105960264901), np.float64(0.8228476821192053)]
Tuning lr:  75%|███████▌  | 3/4 [04:28<01:29, 89.25s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 0.9384; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.7334; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.6130; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.5212; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.4584; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.4028; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.3576; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.3263; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.2950; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.2757; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.549669   0.468653   0.685430   0.512439  
Loss: 0.3429
Fold 1 Epoch 011; Train loss: 0.2564; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.2394; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.2278; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.2164; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.2123; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.1994; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.1948; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.1922; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.1845; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.1805; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.459010   0.672185   0.497292  
Loss: 0.2231
Fold 1 Epoch 021; Train loss: 0.1792; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.1726; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.1728; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.1656; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.1607; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.1617; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.1596; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.1542; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.1558; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.1531; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.539735   0.457993   0.653974   0.494868  
Loss: 0.1913
Fold 1 Epoch 031; Train loss: 0.1520; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.1514; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.1501; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.1480; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.1455; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.1411; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.1439; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.1441; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.1424; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.1427; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.447884   0.642384   0.486303  
Loss: 0.1655
Fold 1 Epoch 041; Train loss: 0.1385; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.1416; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.1361; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.1367; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.1355; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.1381; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.1330; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.1304; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.1271; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.1309; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.556291   0.469358   0.658940   0.501964  
Loss: 0.1666
Fold 1 Epoch 051; Train loss: 0.1329; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.1284; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.1271; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.1277; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.1276; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.1290; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.1280; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.1294; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.1267; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.1284; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.544702   0.452369   0.687086   0.497938  
Loss: 0.1519
Fold 1 Epoch 061; Train loss: 0.1248; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.1250; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.1248; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.1249; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.1227; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.1206; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.1184; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.1203; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.1199; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.1202; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.582781   0.482036   0.685430   0.514797  
Loss: 0.1438
Fold 1 Epoch 071; Train loss: 0.1181; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.1197; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.1188; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.1205; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.1178; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.1183; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.1209; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.1175; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.1141; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.1171; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.557947   0.451489   0.685430   0.491916  
Loss: 0.1398
Fold 1 Epoch 081; Train loss: 0.1144; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.1148; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.1127; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.1151; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.1105; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.1152; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.1095; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.1145; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.1100; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.1091; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.557947   0.467960   0.700331   0.513054  
Loss: 0.1405
Fold 1 Epoch 091; Train loss: 0.1122; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.1100; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.1077; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.1086; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.1120; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.1086; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.1066; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.1096; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.1072; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.1069; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.531457   0.447122   0.657285   0.486913  
Loss: 0.1315
[lr candidate 0.001] Fold 1: HR@10 = [np.float64(0.6854304635761589), np.float64(0.6721854304635762), np.float64(0.6539735099337748), np.float64(0.6423841059602649), np.float64(0.6589403973509934), np.float64(0.6870860927152318), np.float64(0.6854304635761589), np.float64(0.6854304635761589), np.float64(0.7003311258278145), np.float64(0.6572847682119205)]
Tuning lr: 100%|██████████| 4/4 [05:57<00:00, 89.19s/it]Tuning lr: 100%|██████████| 4/4 [05:57<00:00, 89.34s/it]

Best learning rate found: 0.05
Tuning optimizer:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 48.8161; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.7042; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.3735; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 1.5731; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.8532; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.2161; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.1960; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.1792; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.1691; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1535; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.357616   0.261002   0.476821   0.298808  
Loss: 0.1562
Fold 1 Epoch 011; Train loss: 0.1500; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1428; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.1379; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.1329; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.1282; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.1250; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.1195; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.1164; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.1115; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.1070; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.302980   0.217793   0.422185   0.256546  
Loss: 0.1135
Fold 1 Epoch 021; Train loss: 0.1060; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.1037; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.0985; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.0969; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.0917; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0924; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.0871; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.0847; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.0827; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0807; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.372517   0.257815   0.504967   0.301212  
Loss: 0.0899
Fold 1 Epoch 031; Train loss: 0.0777; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0749; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0727; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0708; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0680; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0646; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0646; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0663; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0831; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0963; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.554636   0.399534   0.619205   0.419887  
Loss: 0.1010
Fold 1 Epoch 041; Train loss: 0.0662; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0530; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0494; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0482; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0462; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0451; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0436; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0419; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0402; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0385; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.379139   0.252463   0.538079   0.302571  
Loss: 0.0342
Fold 1 Epoch 051; Train loss: 0.0360; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0365; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0361; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0346; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0334; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0325; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0338; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0354; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0378; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0410; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.443709   0.343647   0.576159   0.386174  
Loss: 0.0395
Fold 1 Epoch 061; Train loss: 0.0394; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0335; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0292; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0275; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0263; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0264; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0253; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0258; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0252; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0239; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.485099   0.365491   0.634106   0.413708  
Loss: 0.0226
Fold 1 Epoch 071; Train loss: 0.0234; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0230; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0229; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0227; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0239; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0283; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0377; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0373; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0260; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0204; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.571192   0.416910   0.723510   0.466656  
Loss: 0.0175
Fold 1 Epoch 081; Train loss: 0.0186; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0179; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0173; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0169; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0160; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0151; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0148; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0144; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0139; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0127; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.591060   0.396789   0.721854   0.440562  
Loss: 0.0114
Fold 1 Epoch 091; Train loss: 0.0119; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0115; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0105; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0097; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0091; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0081; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0075; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0070; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0072; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0094; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.622517   0.402321   0.774834   0.452672  
Loss: 0.0126
[optimizer candidate nadam] Fold 1: HR@10 = [np.float64(0.4768211920529801), np.float64(0.42218543046357615), np.float64(0.5049668874172185), np.float64(0.6192052980132451), np.float64(0.5380794701986755), np.float64(0.5761589403973509), np.float64(0.6341059602649006), np.float64(0.7235099337748344), np.float64(0.7218543046357616), np.float64(0.7748344370860927)]
Tuning optimizer:  25%|██▌       | 1/4 [01:31<04:34, 91.50s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 0.7815; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.3221; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.1982; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.1688; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.1302; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.1016; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.0794; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.0604; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.0471; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.0336; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.260829   0.855960   0.362281  
Loss: 0.0395
Fold 1 Epoch 011; Train loss: 0.0234; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.0152; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.0092; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.0055; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.0035; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.0027; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.0020; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.0017; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.0016; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.0012; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.054636   0.030840   0.182119   0.070817  
Loss: 0.0013
Fold 1 Epoch 021; Train loss: 0.0011; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0005; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.046358   0.021665   0.100993   0.039568  
Loss: 0.0005
Fold 1 Epoch 031; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0004; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.299669   0.120677   0.370861   0.142874  
Loss: 0.0005
Fold 1 Epoch 041; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0004; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.038079   0.018712   0.390728   0.133891  
Loss: 0.0004
Fold 1 Epoch 051; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0004; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.051325   0.024076   0.084437   0.034338  
Loss: 0.0003
Fold 1 Epoch 061; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0004; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.281457   0.121446   0.392384   0.155450  
Loss: 0.0003
Fold 1 Epoch 071; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0004; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.096026   0.042378   0.435430   0.144720  
Loss: 0.0003
Fold 1 Epoch 081; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0003; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.026490   0.013711   0.344371   0.108555  
Loss: 0.0003
Fold 1 Epoch 091; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0004; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.066225   0.034324   0.425497   0.157715  
Loss: 0.0003
[optimizer candidate lamb] Fold 1: HR@10 = [np.float64(0.8559602649006622), np.float64(0.18211920529801323), np.float64(0.10099337748344371), np.float64(0.3708609271523179), np.float64(0.39072847682119205), np.float64(0.08443708609271523), np.float64(0.3923841059602649), np.float64(0.43543046357615894), np.float64(0.3443708609271523), np.float64(0.42549668874172186)]
Tuning optimizer:  50%|█████     | 2/4 [03:01<03:01, 90.66s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 11.9327; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 1.8161; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.9930; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.5893; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.3930; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.2979; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.2275; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.1754; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.1478; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1282; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.312914   0.291447   0.415563   0.323190  
Loss: 0.2069
Fold 1 Epoch 011; Train loss: 0.1151; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1044; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.0975; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.0902; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.0832; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.0784; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.0726; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.0687; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.0613; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.0593; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.354305   0.280027   0.417219   0.300279  
Loss: 0.1110
Fold 1 Epoch 021; Train loss: 0.0531; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.0504; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.0482; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.0440; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.0395; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.0377; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.0366; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.0344; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.0314; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0314; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.359272   0.312564   0.498344   0.355038  
Loss: 0.0628
Fold 1 Epoch 031; Train loss: 0.0304; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0278; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0269; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0252; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0240; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0232; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0226; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0220; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0206; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0192; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.362583   0.314013   0.680464   0.409310  
Loss: 0.0392
Fold 1 Epoch 041; Train loss: 0.0184; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0170; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0160; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0153; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0143; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0130; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0114; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0092; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0079; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0065; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.327815   0.298285   0.408940   0.325205  
Loss: 0.0211
Fold 1 Epoch 051; Train loss: 0.0049; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0037; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0026; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0021; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0016; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0014; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0012; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0012; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0011; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0011; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.056291   0.031271   0.334437   0.123700  
Loss: 0.0147
Fold 1 Epoch 061; Train loss: 0.0011; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0010; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0010; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0011; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0008; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.089404   0.045481   0.415563   0.142277  
Loss: 0.0112
Fold 1 Epoch 071; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0006; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.074503   0.037125   0.114238   0.049767  
Loss: 0.0090
Fold 1 Epoch 081; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0005; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.099338   0.062532   0.390728   0.149013  
Loss: 0.0071
Fold 1 Epoch 091; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0004; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.312914   0.130380   0.369205   0.148454  
Loss: 0.0044
[optimizer candidate adamw] Fold 1: HR@10 = [np.float64(0.4155629139072848), np.float64(0.41721854304635764), np.float64(0.49834437086092714), np.float64(0.6804635761589404), np.float64(0.40894039735099336), np.float64(0.3344370860927152), np.float64(0.4155629139072848), np.float64(0.11423841059602649), np.float64(0.39072847682119205), np.float64(0.36920529801324503)]
Tuning optimizer:  75%|███████▌  | 3/4 [04:31<01:30, 90.31s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Fold 1 Epoch 001; Train loss: 1.0246; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.9234; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.8862; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.8334; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.7836; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.7317; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.6867; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.6399; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.6088; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.5698; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.491722   0.365718   0.836093   0.477278  
Loss: 0.7405
Fold 1 Epoch 011; Train loss: 0.5437; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.5121; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.4829; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.4668; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.4476; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.4236; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.4063; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.3946; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.3852; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.3693; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.571192   0.441538   0.763245   0.502858  
Loss: 0.5339
Fold 1 Epoch 021; Train loss: 0.3561; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.3438; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.3457; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.3370; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.3250; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.3198; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.3140; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.3094; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.3005; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.2969; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.609272   0.468378   0.736755   0.508649  
Loss: 0.4401
Fold 1 Epoch 031; Train loss: 0.2948; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.2845; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.2831; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.2756; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.2766; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.2710; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.2676; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.2622; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.2616; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.2556; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.609272   0.466266   0.741722   0.508775  
Loss: 0.3735
Fold 1 Epoch 041; Train loss: 0.2551; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.2486; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.2446; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.2453; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.2374; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.2384; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.2381; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.2315; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.2315; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.2240; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.605960   0.458257   0.738411   0.501277  
Loss: 0.3128
Fold 1 Epoch 051; Train loss: 0.2243; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.2278; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.2211; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.2145; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.2155; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.2141; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.2094; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.2098; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.2121; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.2057; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.615894   0.466797   0.756623   0.511595  
Loss: 0.2800
Fold 1 Epoch 061; Train loss: 0.2073; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.2046; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.2006; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.2023; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.1976; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.1969; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.1997; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.1974; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.1954; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.1915; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.610927   0.478958   0.738411   0.519781  
Loss: 0.2686
Fold 1 Epoch 071; Train loss: 0.1957; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.1891; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.1885; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.1872; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.1863; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.1852; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.1847; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.1834; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.1869; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.1825; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.617550   0.476170   0.736755   0.514355  
Loss: 0.2323
Fold 1 Epoch 081; Train loss: 0.1797; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.1810; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.1804; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.1792; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.1762; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.1757; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.1786; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.1778; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.1775; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.1754; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.612583   0.482350   0.738411   0.522882  
Loss: 0.2305
Fold 1 Epoch 091; Train loss: 0.1751; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.1764; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.1707; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.1747; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.1714; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.1696; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.1675; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.1666; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.1726; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.1706; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.615894   0.487670   0.735099   0.526015  
Loss: 0.2165
[optimizer candidate adabelief] Fold 1: HR@10 = [np.float64(0.8360927152317881), np.float64(0.7632450331125827), np.float64(0.7367549668874173), np.float64(0.7417218543046358), np.float64(0.7384105960264901), np.float64(0.7566225165562914), np.float64(0.7384105960264901), np.float64(0.7367549668874173), np.float64(0.7384105960264901), np.float64(0.7350993377483444)]
Tuning optimizer: 100%|██████████| 4/4 [06:01<00:00, 90.08s/it]Tuning optimizer: 100%|██████████| 4/4 [06:01<00:00, 90.30s/it]

Best optimizer found: nadam
Tuning timesteps:   0%|          | 0/5 [00:00<?, ?it/s]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 65.5063; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.7336; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.3736; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 1.7781; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.2354; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.2049; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.1883; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.1685; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.1483; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1382; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.334479   0.615894   0.363458  
Loss: 0.1246
Fold 1 Epoch 011; Train loss: 0.1261; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1114; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.1085; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.1031; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.0967; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.0865; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.0799; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.0770; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.0741; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.0706; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.359272   0.284282   0.475166   0.322495  
Loss: 0.0772
Fold 1 Epoch 021; Train loss: 0.0675; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.0708; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.0890; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.0856; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.0629; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.0570; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.0551; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0534; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0507; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0504; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.370861   0.291707   0.451987   0.318373  
Loss: 0.0572
Fold 1 Epoch 031; Train loss: 0.0485; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0483; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0564; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0550; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0466; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0438; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0416; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0412; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0402; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0394; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.399007   0.319612   0.476821   0.345032  
Loss: 0.0517
Fold 1 Epoch 041; Train loss: 0.0390; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0375; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0361; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0373; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0384; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0370; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0350; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0340; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0326; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0324; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.374172   0.292380   0.460265   0.320231  
Loss: 0.0433
Fold 1 Epoch 051; Train loss: 0.0302; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0294; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0309; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0310; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0300; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0299; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0272; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0259; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0249; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0244; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.394040   0.311579   0.521523   0.353108  
Loss: 0.0293
Fold 1 Epoch 061; Train loss: 0.0245; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0240; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0234; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0225; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0238; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0247; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0232; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0221; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0212; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0204; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.506623   0.378306   0.673841   0.432487  
Loss: 0.0264
Fold 1 Epoch 071; Train loss: 0.0193; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0200; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0196; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0193; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0189; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0183; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0190; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0177; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0180; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0180; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.556291   0.416293   0.667219   0.452163  
Loss: 0.0244
Fold 1 Epoch 081; Train loss: 0.0173; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0170; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0170; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0167; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0154; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0150; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0150; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0150; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0145; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0146; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.455298   0.330039   0.557947   0.363119  
Loss: 0.0171
Fold 1 Epoch 091; Train loss: 0.0145; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0150; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0143; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0149; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0140; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0151; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0137; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0137; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0140; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0134; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.370861   0.271810   0.480132   0.307381  
Loss: 0.0171
[timesteps candidate 100] Fold 1: HR@10 = [np.float64(0.6158940397350994), np.float64(0.47516556291390727), np.float64(0.4519867549668874), np.float64(0.4768211920529801), np.float64(0.4602649006622517), np.float64(0.5215231788079471), np.float64(0.6738410596026491), np.float64(0.6672185430463576), np.float64(0.5579470198675497), np.float64(0.48013245033112584)]
Tuning timesteps:  20%|██        | 1/5 [01:31<06:04, 91.04s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 79.2595; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 1.1311; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.4306; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.3240; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.2943; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 1.2744; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.2195; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.1777; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.1643; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1450; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.374172   0.277584   0.574503   0.342448  
Loss: 0.1551
Fold 1 Epoch 011; Train loss: 0.1331; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1220; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.1163; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.1080; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.1024; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.0984; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.0927; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.0896; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.0884; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.0833; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.332781   0.269126   0.476821   0.314668  
Loss: 0.1189
Fold 1 Epoch 021; Train loss: 0.0805; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.0769; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0759; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.0748; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0698; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.0689; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.0672; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.0654; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.0627; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0618; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.324503   0.250516   0.402318   0.275442  
Loss: 0.0865
Fold 1 Epoch 031; Train loss: 0.0592; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0572; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0559; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0533; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0533; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0508; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0492; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0478; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0457; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0457; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.319536   0.261615   0.425497   0.296589  
Loss: 0.0685
Fold 1 Epoch 041; Train loss: 0.0425; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0431; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0402; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0414; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0387; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0378; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0377; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0352; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0350; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0337; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.359272   0.282259   0.475166   0.320498  
Loss: 0.0574
Fold 1 Epoch 051; Train loss: 0.0327; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0319; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0322; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0297; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0297; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0294; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0284; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0276; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0273; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0261; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.302980   0.250942   0.387417   0.277878  
Loss: 0.0421
Fold 1 Epoch 061; Train loss: 0.0251; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0246; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0261; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0247; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0236; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0238; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0223; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0221; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0219; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0221; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.294702   0.245493   0.379139   0.272799  
Loss: 0.0341
Fold 1 Epoch 071; Train loss: 0.0221; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0213; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0209; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0207; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0205; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0204; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0203; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0201; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0197; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0193; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.289735   0.236124   0.437086   0.282474  
Loss: 0.0289
Fold 1 Epoch 081; Train loss: 0.0191; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0180; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0191; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0188; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0177; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0180; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0182; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0168; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0170; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0166; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.302980   0.248032   0.586093   0.335326  
Loss: 0.0260
Fold 1 Epoch 091; Train loss: 0.0163; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0158; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0164; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0162; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0154; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0147; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0153; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0143; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0143; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0144; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.367550   0.270631   0.678808   0.372819  
Loss: 0.0168
[timesteps candidate 150] Fold 1: HR@10 = [np.float64(0.5745033112582781), np.float64(0.4768211920529801), np.float64(0.402317880794702), np.float64(0.42549668874172186), np.float64(0.47516556291390727), np.float64(0.38741721854304634), np.float64(0.3791390728476821), np.float64(0.4370860927152318), np.float64(0.5860927152317881), np.float64(0.6788079470198676)]
Tuning timesteps:  40%|████      | 2/5 [03:01<04:31, 90.63s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 38.6591; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.7847; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.3521; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.2696; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.2331; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.2117; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.1923; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.2075; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.1599; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1454; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.385762   0.295504   0.549669   0.348046  
Loss: 0.1489
Fold 1 Epoch 011; Train loss: 0.1384; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1305; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.1229; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.1225; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.1223; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.1725; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.1681; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.1080; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.1013; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0963; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.503311   0.352757   0.634106   0.395214  
Loss: 0.1040
Fold 1 Epoch 021; Train loss: 0.0975; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.0933; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.0905; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.0857; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.0858; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.0841; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.0953; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.1270; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.1053; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0787; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.400662   0.272192   0.536424   0.315747  
Loss: 0.0638
Fold 1 Epoch 031; Train loss: 0.0696; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0649; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0640; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0595; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0610; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0570; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0549; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0541; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0522; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0514; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.518212   0.357117   0.650662   0.400040  
Loss: 0.0492
Fold 1 Epoch 041; Train loss: 0.0483; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0520; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0716; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0949; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0588; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0439; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0397; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0401; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0378; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0362; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.456954   0.313966   0.591060   0.356401  
Loss: 0.0299
Fold 1 Epoch 051; Train loss: 0.0356; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0331; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0330; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0319; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0318; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0299; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0283; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0274; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0265; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0251; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.533113   0.348023   0.635762   0.381560  
Loss: 0.0243
Fold 1 Epoch 061; Train loss: 0.0257; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0260; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0301; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0456; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0473; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0288; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0207; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0202; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0191; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0181; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.354305   0.250980   0.521523   0.303660  
Loss: 0.0180
Fold 1 Epoch 071; Train loss: 0.0176; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0170; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0164; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0164; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0152; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0140; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0137; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0121; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0118; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0103; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.639073   0.452886   0.819536   0.512864  
Loss: 0.0103
Fold 1 Epoch 081; Train loss: 0.0101; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0092; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0087; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0104; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0166; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0183; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0116; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0056; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0039; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0031; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.779801   0.495909   0.892384   0.532967  
Loss: 0.0030
Fold 1 Epoch 091; Train loss: 0.0024; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0019; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0014; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0011; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0004; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.892384   0.530784  
Loss: 0.0007
[timesteps candidate 200] Fold 1: HR@10 = [np.float64(0.5496688741721855), np.float64(0.6341059602649006), np.float64(0.5364238410596026), np.float64(0.6506622516556292), np.float64(0.5910596026490066), np.float64(0.6357615894039735), np.float64(0.5215231788079471), np.float64(0.8195364238410596), np.float64(0.8923841059602649), np.float64(0.8923841059602649)]
Tuning timesteps:  60%|██████    | 3/5 [04:33<03:02, 91.25s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 42.5561; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 1.0158; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 0.3501; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 1.4038; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.2524; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.2091; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.1853; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.1676; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.1540; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1421; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.333196   0.773179   0.413765  
Loss: 0.1504
Fold 1 Epoch 011; Train loss: 0.1324; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1245; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.1175; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.1143; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.1085; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.1019; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.0960; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.0944; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.0899; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.1003; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.653974   0.458642   0.748344   0.488950  
Loss: 0.0981
Fold 1 Epoch 021; Train loss: 0.1226; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.0974; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.0716; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.0682; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.0647; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.0614; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.0592; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.0561; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.0542; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0509; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.432119   0.282197   0.604305   0.336188  
Loss: 0.0539
Fold 1 Epoch 031; Train loss: 0.0504; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0488; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0490; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0538; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0620; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0492; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0410; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0381; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0389; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0381; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.653974   0.412788   0.822848   0.467663  
Loss: 0.0506
Fold 1 Epoch 041; Train loss: 0.0400; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0339; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0299; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0291; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0261; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0239; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0231; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0208; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0195; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0188; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.700331   0.481215   0.867550   0.537396  
Loss: 0.0195
Fold 1 Epoch 051; Train loss: 0.0176; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0162; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0146; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0137; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0124; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0115; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0120; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0173; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0256; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0159; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.413907   0.189019   0.831126   0.324387  
Loss: 0.0058
Fold 1 Epoch 061; Train loss: 0.0083; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0066; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0054; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0045; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0038; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0031; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0025; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0020; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0016; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0013; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.314705   0.899007   0.434732  
Loss: 0.0028
Fold 1 Epoch 071; Train loss: 0.0011; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0010; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0011; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0015; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0026; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0039; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0053; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0048; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0024; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0011; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.316053   0.899007   0.430059  
Loss: 0.0019
Fold 1 Epoch 081; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0004; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.899007   0.438946  
Loss: 0.0011
Fold 1 Epoch 091; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0013; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0029; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0045; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0045; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0022; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.897351   0.444680  
Loss: 0.0011
[timesteps candidate 250] Fold 1: HR@10 = [np.float64(0.7731788079470199), np.float64(0.7483443708609272), np.float64(0.6043046357615894), np.float64(0.8228476821192053), np.float64(0.8675496688741722), np.float64(0.8311258278145696), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8973509933774835)]
Tuning timesteps:  80%|████████  | 4/5 [06:05<01:31, 91.45s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 27.3345; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.6778; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.5550; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.3472; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.2650; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.2309; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.2122; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.2530; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.2110; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1669; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.253311   0.176984   0.344371   0.205400  
Loss: 0.1749
Fold 1 Epoch 011; Train loss: 0.1590; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1460; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.1388; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.1282; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.1215; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.1137; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.1055; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.0974; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.0956; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.0988; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.311258   0.227697   0.385762   0.251493  
Loss: 0.1324
Fold 1 Epoch 021; Train loss: 0.0966; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.0802; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.0737; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.0664; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.0631; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.0584; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.0541; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.0504; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.0500; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0577; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.483444   0.392773   0.751656   0.474473  
Loss: 0.0415
Fold 1 Epoch 031; Train loss: 0.0488; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0410; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0379; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0346; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0334; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0306; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0287; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0267; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0260; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0248; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.523179   0.355966   0.751656   0.432035  
Loss: 0.0182
Fold 1 Epoch 041; Train loss: 0.0257; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0235; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0189; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0164; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0146; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0125; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0105; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0089; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0086; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0075; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.665563   0.480191   0.897351   0.558541  
Loss: 0.0034
Fold 1 Epoch 051; Train loss: 0.0057; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0038; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0026; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0019; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0013; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0011; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0014; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0015; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0014; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0010; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.316053   0.899007   0.430059  
Loss: 0.0007
Fold 1 Epoch 061; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0006; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.434926   0.899007   0.548931  
Loss: 0.0005
Fold 1 Epoch 071; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0012; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0015; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0011; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0004; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.899007   0.527547  
Loss: 0.0004
Fold 1 Epoch 081; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0005; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.892384   0.525633  
Loss: 0.0003
Fold 1 Epoch 091; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0003; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.412381   0.892384   0.530494  
Loss: 0.0003
[timesteps candidate 300] Fold 1: HR@10 = [np.float64(0.3443708609271523), np.float64(0.38576158940397354), np.float64(0.7516556291390728), np.float64(0.7516556291390728), np.float64(0.8973509933774835), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8923841059602649), np.float64(0.8923841059602649)]
Tuning timesteps: 100%|██████████| 5/5 [07:37<00:00, 91.62s/it]Tuning timesteps: 100%|██████████| 5/5 [07:37<00:00, 91.41s/it]

Best timesteps found: 250
Tuning dropout_rate:   0%|          | 0/5 [00:00<?, ?it/s]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 63.2456; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.8703; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.3762; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.3152; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.2629; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.2311; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.3217; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.5782; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.1717; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1609; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.509934   0.308781   0.647351   0.353169  
Loss: 0.1684
Fold 1 Epoch 011; Train loss: 0.1531; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1413; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.1367; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.1283; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.1230; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.1220; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.1175; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.1136; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.1075; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.1036; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.458609   0.335984   0.637417   0.394419  
Loss: 0.1071
Fold 1 Epoch 021; Train loss: 0.1043; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.1219; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.1071; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.0876; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0835; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0826; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0811; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0844; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.0840; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0851; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.496689   0.312624   0.607616   0.347949  
Loss: 0.0662
Fold 1 Epoch 031; Train loss: 0.0745; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0637; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0595; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0578; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0543; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0543; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0508; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0498; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0479; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0468; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.501656   0.336403   0.640728   0.381365  
Loss: 0.0409
Fold 1 Epoch 041; Train loss: 0.0478; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0502; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0560; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0576; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0461; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0392; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0357; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0349; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0326; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0313; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.427152   0.342676   0.627483   0.405881  
Loss: 0.0276
Fold 1 Epoch 051; Train loss: 0.0293; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0293; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0290; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0269; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0262; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0251; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0253; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0239; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0229; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0231; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.389073   0.322021   0.678808   0.419503  
Loss: 0.0200
Fold 1 Epoch 061; Train loss: 0.0216; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0210; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0237; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0266; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0268; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0229; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0172; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0152; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0132; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0114; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.483444   0.352972   0.821192   0.465718  
Loss: 0.0095
Fold 1 Epoch 071; Train loss: 0.0109; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0093; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0084; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0071; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0063; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0054; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0044; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0038; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0031; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0027; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.576159   0.335327   0.892384   0.444328  
Loss: 0.0020
Fold 1 Epoch 081; Train loss: 0.0027; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0032; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0041; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0049; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0052; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0044; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0032; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0018; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0011; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0007; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.316053   0.892384   0.434357  
Loss: 0.0006
Fold 1 Epoch 091; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0003; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.316053   0.899007   0.436080  
Loss: 0.0005
[dropout_rate candidate 0.1] Fold 1: HR@10 = [np.float64(0.6473509933774835), np.float64(0.6374172185430463), np.float64(0.6076158940397351), np.float64(0.640728476821192), np.float64(0.6274834437086093), np.float64(0.6788079470198676), np.float64(0.8211920529801324), np.float64(0.8923841059602649), np.float64(0.8923841059602649), np.float64(0.8990066225165563)]
Tuning dropout_rate:  20%|██        | 1/5 [01:32<06:08, 92.11s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 22.4367; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 1.5300; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.3433; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.2691; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.2287; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.2616; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.3840; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.2240; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.1428; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1272; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.521523   0.370793   0.662252   0.415837  
Loss: 0.1378
Fold 1 Epoch 011; Train loss: 0.1179; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1096; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.1037; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.1022; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.1102; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.2047; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.1502; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.0767; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.0694; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0657; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.461921   0.350487   0.629139   0.404372  
Loss: 0.0665
Fold 1 Epoch 021; Train loss: 0.0631; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.0561; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.0515; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.0484; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.0458; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.0436; Time: 00:00:00
Fold 1 Epoch 027; Train loss: 0.0395; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.0376; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.0343; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0332; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.503311   0.378860   0.710265   0.444286  
Loss: 0.0263
Fold 1 Epoch 031; Train loss: 0.0315; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0298; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0285; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0269; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0252; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0247; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0417; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.1217; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0359; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0181; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.471854   0.350048   0.745033   0.439806  
Loss: 0.0125
Fold 1 Epoch 041; Train loss: 0.0153; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0141; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0125; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0107; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0092; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0077; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0063; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0052; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0041; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0033; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.596026   0.414995   0.867550   0.506444  
Loss: 0.0016
Fold 1 Epoch 051; Train loss: 0.0023; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0016; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0011; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0015; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.411034   0.892384   0.529146  
Loss: 0.0023
Fold 1 Epoch 061; Train loss: 0.0027; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0036; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0038; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0033; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0021; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0016; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0011; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0007; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.436086   0.897351   0.549613  
Loss: 0.0007
Fold 1 Epoch 071; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0010; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0013; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0019; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0028; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0037; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0035; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0035; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0025; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.788079   0.406482   0.899007   0.441481  
Loss: 0.0019
Fold 1 Epoch 081; Train loss: 0.0013; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0004; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0004; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.411034   0.899007   0.531060  
Loss: 0.0005
Fold 1 Epoch 091; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0015; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0023; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0037; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0050; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0036; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0018; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0004; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.788079   0.470030   0.892384   0.503809  
Loss: 0.0002
[dropout_rate candidate 0.01] Fold 1: HR@10 = [np.float64(0.6622516556291391), np.float64(0.6291390728476821), np.float64(0.7102649006622517), np.float64(0.7450331125827815), np.float64(0.8675496688741722), np.float64(0.8923841059602649), np.float64(0.8973509933774835), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8923841059602649)]
Tuning dropout_rate:  40%|████      | 2/5 [03:05<04:38, 92.79s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 41.8037; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.6930; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 0.3050; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.2702; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.9020; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.1757; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.1578; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.1456; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.1361; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1287; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.355960   0.280964   0.600993   0.359690  
Loss: 0.1451
Fold 1 Epoch 011; Train loss: 0.1244; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1178; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.1107; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.1074; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.1005; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.0942; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.0916; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.0862; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.0829; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.0780; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.412252   0.254735   0.559603   0.303431  
Loss: 0.0893
Fold 1 Epoch 021; Train loss: 0.0729; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.0698; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0665; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.0635; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0640; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0856; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0942; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0617; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0486; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.0449; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.382450   0.299774   0.554636   0.353808  
Loss: 0.0430
Fold 1 Epoch 031; Train loss: 0.0424; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0394; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0372; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0347; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0332; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0338; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0321; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0299; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0298; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0275; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.359272   0.297204   0.632450   0.385059  
Loss: 0.0250
Fold 1 Epoch 041; Train loss: 0.0272; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0266; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0264; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0284; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0338; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0453; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0352; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0230; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0184; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0171; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.387417   0.288061   0.630795   0.370064  
Loss: 0.0142
Fold 1 Epoch 051; Train loss: 0.0160; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0151; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0136; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0126; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0115; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0104; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0087; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0074; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0061; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0048; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.548013   0.349997   0.892384   0.463192  
Loss: 0.0040
Fold 1 Epoch 061; Train loss: 0.0037; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0029; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0022; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0016; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0011; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0008; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0016; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.379602   0.892384   0.497714  
Loss: 0.0031
Fold 1 Epoch 071; Train loss: 0.0053; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0141; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0125; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0038; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0002; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.379602   0.899007   0.499629  
Loss: 0.0003
Fold 1 Epoch 081; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0001; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0002; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.316053   0.899007   0.436080  
Loss: 0.0002
Fold 1 Epoch 091; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0001; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.316053   0.899007   0.436080  
Loss: 0.0003
[dropout_rate candidate 0.001] Fold 1: HR@10 = [np.float64(0.6009933774834437), np.float64(0.5596026490066225), np.float64(0.554635761589404), np.float64(0.6324503311258278), np.float64(0.6307947019867549), np.float64(0.8923841059602649), np.float64(0.8923841059602649), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563)]
Tuning dropout_rate:  60%|██████    | 3/5 [04:41<03:08, 94.47s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 90.3427; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.8646; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 1.5679; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.7039; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.2697; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.2439; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.2116; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.1955; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.2054; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.4489; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.394040   0.332644   0.698675   0.427376  
Loss: 0.3644
Fold 1 Epoch 011; Train loss: 0.2262; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1491; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.1449; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.1367; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.1372; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.1250; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.1265; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.1180; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.1189; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.1118; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.408940   0.296479   0.526490   0.333574  
Loss: 0.1304
Fold 1 Epoch 021; Train loss: 0.1084; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.1083; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.1029; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.1005; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.1020; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.1248; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.1626; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.1121; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0841; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.0792; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.539735   0.374744   0.642384   0.408051  
Loss: 0.0879
Fold 1 Epoch 031; Train loss: 0.0772; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.0735; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.0703; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0678; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0652; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0627; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0598; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0567; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0566; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0555; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.508278   0.387538   0.640728   0.430568  
Loss: 0.0580
Fold 1 Epoch 041; Train loss: 0.0521; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0517; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0526; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0563; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0652; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0678; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0479; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0418; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0395; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0373; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.433775   0.339545   0.579470   0.386290  
Loss: 0.0380
Fold 1 Epoch 051; Train loss: 0.0377; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0369; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0341; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0335; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0323; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0312; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0313; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0305; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0285; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0282; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.408940   0.331587   0.536424   0.371355  
Loss: 0.0251
Fold 1 Epoch 061; Train loss: 0.0273; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0260; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0258; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0278; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0286; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0288; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0271; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0253; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0213; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0202; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.567881   0.374818   0.697020   0.416588  
Loss: 0.0175
Fold 1 Epoch 071; Train loss: 0.0202; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0217; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0245; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0306; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0253; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0164; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0134; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0123; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0109; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0102; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.562914   0.361965   0.867550   0.463145  
Loss: 0.0074
Fold 1 Epoch 081; Train loss: 0.0090; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0083; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0072; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0063; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0056; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0051; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0043; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0036; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0031; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0027; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.673841   0.377302   0.899007   0.453687  
Loss: 0.0017
Fold 1 Epoch 091; Train loss: 0.0024; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0021; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0019; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0018; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0019; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0021; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0024; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0025; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0024; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0019; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.316053   0.897351   0.435601  
Loss: 0.0016
[dropout_rate candidate 0.0001] Fold 1: HR@10 = [np.float64(0.6986754966887417), np.float64(0.5264900662251656), np.float64(0.6423841059602649), np.float64(0.640728476821192), np.float64(0.5794701986754967), np.float64(0.5364238410596026), np.float64(0.6970198675496688), np.float64(0.8675496688741722), np.float64(0.8990066225165563), np.float64(0.8973509933774835)]
Tuning dropout_rate:  80%|████████  | 4/5 [06:17<01:35, 95.08s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 39.4235; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 0.9077; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 2.7691; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.3309; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.2440; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.2108; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.1813; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.1669; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.1576; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.1430; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.534768   0.368520   0.647351   0.404868  
Loss: 0.1677
Fold 1 Epoch 011; Train loss: 0.1428; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.1348; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.1277; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.1212; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.1175; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.1104; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.1061; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.1031; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.0999; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.0922; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.420530   0.240746   0.533113   0.275791  
Loss: 0.0966
Fold 1 Epoch 021; Train loss: 0.0906; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.0845; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.0850; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.1047; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.2335; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.1371; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0715; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0643; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0615; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0598; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.516556   0.377273   0.639073   0.417097  
Loss: 0.0509
Fold 1 Epoch 031; Train loss: 0.0572; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0556; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0522; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0498; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0476; Time: 00:00:00
Fold 1 Epoch 036; Train loss: 0.0473; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0446; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0448; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0407; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0411; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.460265   0.305990   0.594371   0.348808  
Loss: 0.0376
Fold 1 Epoch 041; Train loss: 0.0394; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0373; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0360; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0356; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0327; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0321; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0310; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0301; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0301; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0327; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.274834   0.167059   0.470199   0.227673  
Loss: 0.0339
Fold 1 Epoch 051; Train loss: 0.0473; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0732; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.0534; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.0272; Time: 00:00:00
Fold 1 Epoch 055; Train loss: 0.0228; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.0207; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.0198; Time: 00:00:00
Fold 1 Epoch 058; Train loss: 0.0193; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.0180; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.0166; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.639073   0.472401   0.872517   0.553154  
Loss: 0.0131
Fold 1 Epoch 061; Train loss: 0.0154; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0146; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0131; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0118; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0108; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0093; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0084; Time: 00:00:00
Fold 1 Epoch 068; Train loss: 0.0070; Time: 00:00:00
Fold 1 Epoch 069; Train loss: 0.0058; Time: 00:00:00
Fold 1 Epoch 070; Train loss: 0.0046; Time: 00:00:00
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.615894   0.297470   0.899007   0.389952  
Loss: 0.0033
Fold 1 Epoch 071; Train loss: 0.0037; Time: 00:00:00
Fold 1 Epoch 072; Train loss: 0.0030; Time: 00:00:00
Fold 1 Epoch 073; Train loss: 0.0023; Time: 00:00:00
Fold 1 Epoch 074; Train loss: 0.0018; Time: 00:00:00
Fold 1 Epoch 075; Train loss: 0.0013; Time: 00:00:00
Fold 1 Epoch 076; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 077; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 078; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 080; Train loss: 0.0004; Time: 00:00:00
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.899007   0.444968  
Loss: 0.0008
Fold 1 Epoch 081; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.0018; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.0069; Time: 00:00:00
Fold 1 Epoch 084; Train loss: 0.0276; Time: 00:00:00
Fold 1 Epoch 085; Train loss: 0.0264; Time: 00:00:00
Fold 1 Epoch 086; Train loss: 0.0063; Time: 00:00:00
Fold 1 Epoch 087; Train loss: 0.0009; Time: 00:00:00
Fold 1 Epoch 088; Train loss: 0.0003; Time: 00:00:00
Fold 1 Epoch 089; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 090; Train loss: 0.0002; Time: 00:00:00
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.899007   0.533760  
Loss: 0.0004
Fold 1 Epoch 091; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 092; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 093; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 095; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0002; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.899007   0.444968  
Loss: 0.0003
[dropout_rate candidate 1e-05] Fold 1: HR@10 = [np.float64(0.6473509933774835), np.float64(0.5331125827814569), np.float64(0.6390728476821192), np.float64(0.5943708609271523), np.float64(0.47019867549668876), np.float64(0.8725165562913907), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563)]
Tuning dropout_rate: 100%|██████████| 5/5 [07:51<00:00, 94.39s/it]Tuning dropout_rate: 100%|██████████| 5/5 [07:51<00:00, 94.21s/it]

Best dropout_rate found: 0.1
Tuning l2_decay:   0%|          | 0/5 [00:00<?, ?it/s]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 4.1969; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 14.0978; Time: 00:00:00
Fold 1 Epoch 003; Train loss: 0.1856; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 0.1230; Time: 00:00:00
Fold 1 Epoch 005; Train loss: 0.0830; Time: 00:00:00
Fold 1 Epoch 006; Train loss: 0.0545; Time: 00:00:00
Fold 1 Epoch 007; Train loss: 0.0354; Time: 00:00:00
Fold 1 Epoch 008; Train loss: 0.0224; Time: 00:00:00
Fold 1 Epoch 009; Train loss: 0.0138; Time: 00:00:00
Fold 1 Epoch 010; Train loss: 0.0085; Time: 00:00:00
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.521523   0.272714   0.865894   0.376934  
Loss: 0.0047
Fold 1 Epoch 011; Train loss: 0.0052; Time: 00:00:00
Fold 1 Epoch 012; Train loss: 0.0032; Time: 00:00:00
Fold 1 Epoch 013; Train loss: 0.0020; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.0013; Time: 00:00:00
Fold 1 Epoch 015; Train loss: 0.0010; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.0005; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.173841   0.076890   0.451987   0.164879  
Loss: 0.0005
Fold 1 Epoch 021; Train loss: 0.0005; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 023; Train loss: 0.0006; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 025; Train loss: 0.0007; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.0008; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.149007   0.072882   0.640728   0.228748  
Loss: 0.0008
Fold 1 Epoch 031; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.0010; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.0011; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0012; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.125828   0.062658   0.564570   0.199758  
Loss: 0.0012
Fold 1 Epoch 041; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 044; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 046; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 048; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.0012; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.097682   0.050644   0.478477   0.169756  
Loss: 0.0013
Fold 1 Epoch 051; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0015; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 056; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.0015; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.107616   0.054269   0.493377   0.176317  
Loss: 0.0014
Fold 1 Epoch 061; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 066; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 067; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.0015; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0016; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.201987   0.116348   0.534768   0.221134  
Loss: 0.0017
Fold 1 Epoch 071; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0015; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0015; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0015; Time: 00:00:01
Fold 1 Epoch 075; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0014; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.188742   0.094020   0.596026   0.222741  
Loss: 0.0013
Fold 1 Epoch 081; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0015; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0015; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0016; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.105960   0.055715   0.481788   0.174476  
Loss: 0.0016
Fold 1 Epoch 091; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0017; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0017; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0015; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0015; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.094371   0.049386   0.486755   0.172688  
Loss: 0.0015
[l2_decay candidate 0.1] Fold 1: HR@10 = [np.float64(0.8658940397350994), np.float64(0.4519867549668874), np.float64(0.640728476821192), np.float64(0.5645695364238411), np.float64(0.478476821192053), np.float64(0.49337748344370863), np.float64(0.5347682119205298), np.float64(0.5960264900662252), np.float64(0.4817880794701987), np.float64(0.4867549668874172)]
Tuning l2_decay:  20%|██        | 1/5 [02:14<08:56, 134.10s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 88.4035; Time: 00:00:01
Fold 1 Epoch 002; Train loss: 1.4830; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 0.4466; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.3002; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 0.2492; Time: 00:00:01
Fold 1 Epoch 006; Train loss: 0.1570; Time: 00:00:01
Fold 1 Epoch 007; Train loss: 0.1171; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1404; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.0880; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.0555; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.720199   0.524930   0.819536   0.556548  
Loss: 0.0449
Fold 1 Epoch 011; Train loss: 0.0440; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.1649; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.0335; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.0277; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.0231; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.0199; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.0471; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 13309.6142; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 12.4107; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 5.4514; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.259934   0.129970   0.559603   0.234845  
Loss: 14.0873
Fold 1 Epoch 021; Train loss: 21.4552; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 1.1027; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.9267; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 2.2192; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 10.7275; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 2.3432; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.4092; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.3413; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.2978; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.2599; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.135762   0.108086   0.413907   0.200935  
Loss: 0.2579
Fold 1 Epoch 031; Train loss: 0.2238; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.1879; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.1638; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.1461; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.1226; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.1093; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.0946; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0861; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0763; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0678; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.061258   0.036783   0.342715   0.124313  
Loss: 0.0630
Fold 1 Epoch 041; Train loss: 0.0612; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0536; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0477; Time: 00:00:01
Fold 1 Epoch 044; Train loss: 0.0468; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.0449; Time: 00:00:01
Fold 1 Epoch 046; Train loss: 0.0381; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.0369; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0460; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0870; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.2409; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.615894   0.475603   0.892384   0.571469  
Loss: 0.4853
Fold 1 Epoch 051; Train loss: 1.0130; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 2.0757; Time: 00:00:00
Fold 1 Epoch 053; Train loss: 0.7129; Time: 00:00:00
Fold 1 Epoch 054; Train loss: 0.1080; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0632; Time: 00:00:00
Fold 1 Epoch 056; Train loss: 0.1446; Time: 00:00:00
Fold 1 Epoch 057; Train loss: 0.4701; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 1.0147; Time: 00:00:00
Fold 1 Epoch 059; Train loss: 0.9049; Time: 00:00:00
Fold 1 Epoch 060; Train loss: 0.2320; Time: 00:00:00
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.433421   0.892384   0.457955  
Loss: 0.0801
Fold 1 Epoch 061; Train loss: 0.0503; Time: 00:00:00
Fold 1 Epoch 062; Train loss: 0.0232; Time: 00:00:00
Fold 1 Epoch 063; Train loss: 0.0186; Time: 00:00:00
Fold 1 Epoch 064; Train loss: 0.0178; Time: 00:00:00
Fold 1 Epoch 065; Train loss: 0.0173; Time: 00:00:00
Fold 1 Epoch 066; Train loss: 0.0172; Time: 00:00:00
Fold 1 Epoch 067; Train loss: 0.0170; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.0166; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.0168; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0190; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.436625   0.892384   0.461063  
Loss: 0.0231
Fold 1 Epoch 071; Train loss: 0.0308; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0439; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0540; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0670; Time: 00:00:01
Fold 1 Epoch 075; Train loss: 0.0895; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.1396; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.2366; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.3953; Time: 00:00:00
Fold 1 Epoch 079; Train loss: 0.6520; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.9672; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.530231   0.892384   0.554765  
Loss: 1.0185
Fold 1 Epoch 081; Train loss: 0.8124; Time: 00:00:00
Fold 1 Epoch 082; Train loss: 0.3049; Time: 00:00:00
Fold 1 Epoch 083; Train loss: 0.1058; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0493; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0328; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0261; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0237; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0248; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0260; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0319; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.525144   0.892384   0.549486  
Loss: 0.0414
Fold 1 Epoch 091; Train loss: 0.0536; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0782; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.1094; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.1544; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.2133; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.2660; Time: 00:00:00
Fold 1 Epoch 097; Train loss: 0.1989; Time: 00:00:00
Fold 1 Epoch 098; Train loss: 0.1159; Time: 00:00:00
Fold 1 Epoch 099; Train loss: 0.0711; Time: 00:00:00
Fold 1 Epoch 100; Train loss: 0.0469; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.516589   0.892384   0.540932  
Loss: 0.0312
[l2_decay candidate 0.01] Fold 1: HR@10 = [np.float64(0.8195364238410596), np.float64(0.5596026490066225), np.float64(0.4139072847682119), np.float64(0.34271523178807944), np.float64(0.8923841059602649), np.float64(0.8923841059602649), np.float64(0.8923841059602649), np.float64(0.8923841059602649), np.float64(0.8923841059602649), np.float64(0.8923841059602649)]
Tuning l2_decay:  40%|████      | 2/5 [04:14<06:18, 126.05s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 59.6725; Time: 00:00:00
Fold 1 Epoch 002; Train loss: 1.0389; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 0.5423; Time: 00:00:00
Fold 1 Epoch 004; Train loss: 1.1681; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 1.8464; Time: 00:00:01
Fold 1 Epoch 006; Train loss: 0.2390; Time: 00:00:01
Fold 1 Epoch 007; Train loss: 0.1958; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1659; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.1403; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.1248; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.440397   0.320011   0.612583   0.375063  
Loss: 0.1133
Fold 1 Epoch 011; Train loss: 0.1101; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.0942; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.0848; Time: 00:00:00
Fold 1 Epoch 014; Train loss: 0.0788; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.0719; Time: 00:00:00
Fold 1 Epoch 016; Train loss: 0.0678; Time: 00:00:00
Fold 1 Epoch 017; Train loss: 0.0683; Time: 00:00:00
Fold 1 Epoch 018; Train loss: 0.0790; Time: 00:00:00
Fold 1 Epoch 019; Train loss: 0.0830; Time: 00:00:00
Fold 1 Epoch 020; Train loss: 0.0666; Time: 00:00:00
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.509934   0.377729   0.687086   0.435197  
Loss: 0.0450
Fold 1 Epoch 021; Train loss: 0.0563; Time: 00:00:00
Fold 1 Epoch 022; Train loss: 0.0503; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0512; Time: 00:00:00
Fold 1 Epoch 024; Train loss: 0.0646; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0569; Time: 00:00:00
Fold 1 Epoch 026; Train loss: 0.0452; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0383; Time: 00:00:00
Fold 1 Epoch 028; Train loss: 0.0360; Time: 00:00:00
Fold 1 Epoch 029; Train loss: 0.0407; Time: 00:00:00
Fold 1 Epoch 030; Train loss: 0.0518; Time: 00:00:00
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.365894   0.322090   0.556291   0.383460  
Loss: 0.0321
Fold 1 Epoch 031; Train loss: 0.0353; Time: 00:00:00
Fold 1 Epoch 032; Train loss: 0.0281; Time: 00:00:00
Fold 1 Epoch 033; Train loss: 0.0251; Time: 00:00:00
Fold 1 Epoch 034; Train loss: 0.0264; Time: 00:00:00
Fold 1 Epoch 035; Train loss: 0.0465; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.0244; Time: 00:00:00
Fold 1 Epoch 037; Train loss: 0.0188; Time: 00:00:00
Fold 1 Epoch 038; Train loss: 0.0173; Time: 00:00:00
Fold 1 Epoch 039; Train loss: 0.0203; Time: 00:00:00
Fold 1 Epoch 040; Train loss: 0.0268; Time: 00:00:00
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.594371   0.407430   0.741722   0.454884  
Loss: 0.0135
Fold 1 Epoch 041; Train loss: 0.0145; Time: 00:00:00
Fold 1 Epoch 042; Train loss: 0.0111; Time: 00:00:00
Fold 1 Epoch 043; Train loss: 0.0105; Time: 00:00:00
Fold 1 Epoch 044; Train loss: 0.0215; Time: 00:00:00
Fold 1 Epoch 045; Train loss: 0.0130; Time: 00:00:00
Fold 1 Epoch 046; Train loss: 0.0056; Time: 00:00:00
Fold 1 Epoch 047; Train loss: 0.0043; Time: 00:00:00
Fold 1 Epoch 048; Train loss: 0.0043; Time: 00:00:00
Fold 1 Epoch 049; Train loss: 0.0227; Time: 00:00:00
Fold 1 Epoch 050; Train loss: 0.0098; Time: 00:00:00
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.359159   0.894040   0.477750  
Loss: 0.0018
Fold 1 Epoch 051; Train loss: 0.0020; Time: 00:00:00
Fold 1 Epoch 052; Train loss: 0.0015; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.0010; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 056; Train loss: 0.0325; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.0125; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.0005; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.892384   0.443053  
Loss: 0.0004
Fold 1 Epoch 061; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.0085; Time: 00:00:01
Fold 1 Epoch 066; Train loss: 0.0211; Time: 00:00:01
Fold 1 Epoch 067; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0001; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.899007   0.438946  
Loss: 0.0001
Fold 1 Epoch 071; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0039; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0165; Time: 00:00:01
Fold 1 Epoch 075; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0001; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.899007   0.438946  
Loss: 0.0001
Fold 1 Epoch 081; Train loss: 0.0021; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.3726; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0140; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0017; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0001; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.634106   0.425148   0.867550   0.494504  
Loss: 0.0001
Fold 1 Epoch 091; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0000; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.028146   0.013749   0.109272   0.040069  
Loss: 0.0000
[l2_decay candidate 0.001] Fold 1: HR@10 = [np.float64(0.6125827814569537), np.float64(0.6870860927152318), np.float64(0.5562913907284768), np.float64(0.7417218543046358), np.float64(0.8940397350993378), np.float64(0.8923841059602649), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8675496688741722), np.float64(0.10927152317880795)]
Tuning l2_decay:  60%|██████    | 3/5 [06:10<04:03, 121.57s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 36.7126; Time: 00:00:01
Fold 1 Epoch 002; Train loss: 1.1188; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 0.4046; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.9615; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 0.2378; Time: 00:00:01
Fold 1 Epoch 006; Train loss: 0.2079; Time: 00:00:01
Fold 1 Epoch 007; Train loss: 0.1835; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1634; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.1476; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.1363; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.346026   0.280848   0.445364   0.312615  
Loss: 0.1435
Fold 1 Epoch 011; Train loss: 0.1289; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.1236; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.1177; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.1088; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.1096; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.1354; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.1698; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.1085; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.0859; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0794; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.365894   0.290386   0.437086   0.312965  
Loss: 0.0749
Fold 1 Epoch 021; Train loss: 0.0753; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.0703; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0690; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.0647; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0624; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0594; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0571; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0552; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0561; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.0575; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.528146   0.399897   0.663907   0.441077  
Loss: 0.0691
Fold 1 Epoch 031; Train loss: 0.0645; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.0778; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.0597; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.0473; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.0401; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.0385; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.0385; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0365; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0336; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0315; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.541391   0.406124   0.822848   0.502279  
Loss: 0.0319
Fold 1 Epoch 041; Train loss: 0.0326; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.0297; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0280; Time: 00:00:01
Fold 1 Epoch 044; Train loss: 0.0269; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.0258; Time: 00:00:01
Fold 1 Epoch 046; Train loss: 0.0245; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.0238; Time: 00:00:01
Fold 1 Epoch 048; Train loss: 0.0232; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.0208; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.0210; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.562914   0.371739   0.701987   0.418262  
Loss: 0.0187
Fold 1 Epoch 051; Train loss: 0.0191; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.0179; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0177; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.0189; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0227; Time: 00:00:01
Fold 1 Epoch 056; Train loss: 0.0246; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.0163; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.0102; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.0072; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.0058; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.422501   0.899007   0.536506  
Loss: 0.0053
Fold 1 Epoch 061; Train loss: 0.0047; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0038; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.0030; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0023; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.0018; Time: 00:00:01
Fold 1 Epoch 066; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 067; Train loss: 0.0011; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.0010; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0008; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.410817   0.899007   0.530844  
Loss: 0.0008
Fold 1 Epoch 071; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 075; Train loss: 0.0032; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.0063; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0064; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0035; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0015; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0007; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.379602   0.899007   0.499820  
Loss: 0.0005
Fold 1 Epoch 081; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0003; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.379602   0.897351   0.499150  
Loss: 0.0004
Fold 1 Epoch 091; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0031; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.0070; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0044; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0002; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.316053   0.899007   0.436080  
Loss: 0.0003
[l2_decay candidate 0.0001] Fold 1: HR@10 = [np.float64(0.445364238410596), np.float64(0.4370860927152318), np.float64(0.6639072847682119), np.float64(0.8228476821192053), np.float64(0.7019867549668874), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8973509933774835), np.float64(0.8990066225165563)]
Tuning l2_decay:  80%|████████  | 4/5 [08:19<02:04, 124.37s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 47.3017; Time: 00:00:01
Fold 1 Epoch 002; Train loss: 0.9049; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 0.4093; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.4400; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 2.5768; Time: 00:00:01
Fold 1 Epoch 006; Train loss: 0.2402; Time: 00:00:01
Fold 1 Epoch 007; Train loss: 0.2067; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1920; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.1751; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.1683; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.357616   0.264116   0.543046   0.322899  
Loss: 0.1760
Fold 1 Epoch 011; Train loss: 0.1600; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.1532; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.1447; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.1401; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.1332; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.1287; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.1226; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.1186; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.1177; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.1143; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.312914   0.198877   0.562914   0.279716  
Loss: 0.1144
Fold 1 Epoch 021; Train loss: 0.1069; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.1006; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0981; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.0941; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0889; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0837; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0807; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0773; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0747; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.0689; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.326159   0.275199   0.481788   0.324238  
Loss: 0.0632
Fold 1 Epoch 031; Train loss: 0.0677; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.0642; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.0593; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.0585; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.0549; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.0530; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.0497; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0488; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0445; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0422; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.365894   0.252481   0.645695   0.341427  
Loss: 0.0348
Fold 1 Epoch 041; Train loss: 0.0415; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.0399; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0402; Time: 00:00:01
Fold 1 Epoch 044; Train loss: 0.0421; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.0507; Time: 00:00:01
Fold 1 Epoch 046; Train loss: 0.0578; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.0536; Time: 00:00:01
Fold 1 Epoch 048; Train loss: 0.0382; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.0308; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.0294; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.410596   0.239481   0.629139   0.309824  
Loss: 0.0240
Fold 1 Epoch 051; Train loss: 0.0281; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.0272; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0254; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.0250; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0246; Time: 00:00:01
Fold 1 Epoch 056; Train loss: 0.0227; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.0218; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.0202; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.0202; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.0183; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.389073   0.271677   0.627483   0.349641  
Loss: 0.0156
Fold 1 Epoch 061; Train loss: 0.0167; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0164; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.0144; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0136; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.0135; Time: 00:00:01
Fold 1 Epoch 066; Train loss: 0.0142; Time: 00:00:01
Fold 1 Epoch 067; Train loss: 0.0200; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.0275; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.0263; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0146; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.387417   0.242456   0.725166   0.350025  
Loss: 0.0052
Fold 1 Epoch 071; Train loss: 0.0070; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0048; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0039; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0032; Time: 00:00:01
Fold 1 Epoch 075; Train loss: 0.0025; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.0020; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0010; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0009; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.384106   0.240171   0.728477   0.359417  
Loss: 0.0011
Fold 1 Epoch 081; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0006; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.899007   0.534322  
Loss: 0.0005
Fold 1 Epoch 091; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0039; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0085; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0132; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.556291   0.275132   0.892384   0.392457  
Loss: 0.0096
[l2_decay candidate 1e-05] Fold 1: HR@10 = [np.float64(0.543046357615894), np.float64(0.5629139072847682), np.float64(0.4817880794701987), np.float64(0.6456953642384106), np.float64(0.6291390728476821), np.float64(0.6274834437086093), np.float64(0.7251655629139073), np.float64(0.7284768211920529), np.float64(0.8990066225165563), np.float64(0.8923841059602649)]
Tuning l2_decay: 100%|██████████| 5/5 [10:28<00:00, 125.92s/it]Tuning l2_decay: 100%|██████████| 5/5 [10:28<00:00, 125.61s/it]

Best l2_decay found: 0.0001
Tuning eps:   0%|          | 0/5 [00:00<?, ?it/s]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 0.7800; Time: 00:00:01
Fold 1 Epoch 002; Train loss: 0.4701; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 0.3621; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.3166; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 0.2807; Time: 00:00:01
Fold 1 Epoch 006; Train loss: 0.2621; Time: 00:00:01
Fold 1 Epoch 007; Train loss: 0.2445; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.2302; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.2243; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.2180; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.528146   0.418960   0.672185   0.465373  
Loss: 0.2732
Fold 1 Epoch 011; Train loss: 0.2084; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.2078; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.2056; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.2026; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.2008; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.1921; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.1930; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.1871; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.1908; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.1834; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.523179   0.411296   0.675497   0.459907  
Loss: 0.2292
Fold 1 Epoch 021; Train loss: 0.1868; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.1839; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.1831; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.1809; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.1796; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.1757; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.1792; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.1777; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.1777; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.1792; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.518212   0.420351   0.658940   0.465528  
Loss: 0.2142
Fold 1 Epoch 031; Train loss: 0.1739; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.1731; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.1769; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.1734; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.1727; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.1696; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.1692; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.1704; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.1764; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.1706; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.531457   0.435571   0.693709   0.487356  
Loss: 0.2021
Fold 1 Epoch 041; Train loss: 0.1667; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.1685; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.1636; Time: 00:00:01
Fold 1 Epoch 044; Train loss: 0.1667; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.1641; Time: 00:00:01
Fold 1 Epoch 046; Train loss: 0.1655; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.1608; Time: 00:00:01
Fold 1 Epoch 048; Train loss: 0.1600; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.1652; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.1633; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.516556   0.431534   0.653974   0.475343  
Loss: 0.2195
Fold 1 Epoch 051; Train loss: 0.1609; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.1593; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.1639; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.1610; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.1581; Time: 00:00:01
Fold 1 Epoch 056; Train loss: 0.1607; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.1591; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.1606; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.1609; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.1605; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.544702   0.442943   0.710265   0.495749  
Loss: 0.1940
Fold 1 Epoch 061; Train loss: 0.1571; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.1574; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.1560; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.1572; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.1576; Time: 00:00:01
Fold 1 Epoch 066; Train loss: 0.1572; Time: 00:00:01
Fold 1 Epoch 067; Train loss: 0.1534; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.1546; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.1593; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.1592; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.521523   0.440970   0.690397   0.495040  
Loss: 0.1981
Fold 1 Epoch 071; Train loss: 0.1550; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.1584; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.1548; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.1542; Time: 00:00:01
Fold 1 Epoch 075; Train loss: 0.1541; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.1516; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.1524; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.1526; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.1494; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.1556; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.526490   0.433109   0.693709   0.486866  
Loss: 0.1912
Fold 1 Epoch 081; Train loss: 0.1544; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.1533; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.1546; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.1480; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.1496; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.1497; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.1499; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.1500; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.1514; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.1456; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.519868   0.431880   0.662252   0.477419  
Loss: 0.1857
Fold 1 Epoch 091; Train loss: 0.1479; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.1531; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.1497; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.1472; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.1501; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.1525; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.1475; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.1491; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.1512; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.1488; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.549669   0.453084   0.705298   0.502840  
Loss: 0.1807
[eps candidate 0.1] Fold 1: HR@10 = [np.float64(0.6721854304635762), np.float64(0.6754966887417219), np.float64(0.6589403973509934), np.float64(0.6937086092715232), np.float64(0.6539735099337748), np.float64(0.7102649006622517), np.float64(0.6903973509933775), np.float64(0.6937086092715232), np.float64(0.6622516556291391), np.float64(0.7052980132450332)]
Tuning eps:  20%|██        | 1/5 [01:53<07:35, 113.92s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 0.8238; Time: 00:00:01
Fold 1 Epoch 002; Train loss: 0.2601; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 0.2196; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.1996; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 0.1964; Time: 00:00:01
Fold 1 Epoch 006; Train loss: 0.1799; Time: 00:00:01
Fold 1 Epoch 007; Train loss: 0.1753; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1729; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.1693; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.1673; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.567881   0.466686   0.705298   0.511103  
Loss: 0.1945
Fold 1 Epoch 011; Train loss: 0.1608; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.1582; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.1575; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.1544; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.1515; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.1458; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.1478; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.1482; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.1419; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.1399; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.620861   0.495666   0.776490   0.546231  
Loss: 0.1653
Fold 1 Epoch 021; Train loss: 0.1364; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.1340; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.1331; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.1299; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.1287; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.1243; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.1221; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.1201; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.1194; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.1184; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.581126   0.463591   0.731788   0.512165  
Loss: 0.1514
Fold 1 Epoch 031; Train loss: 0.1153; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.1170; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.1095; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.1097; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.1086; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.1062; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.1019; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.1038; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.1011; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0989; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.586093   0.463747   0.758278   0.518687  
Loss: 0.1312
Fold 1 Epoch 041; Train loss: 0.0969; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.0955; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0925; Time: 00:00:01
Fold 1 Epoch 044; Train loss: 0.0918; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.0921; Time: 00:00:01
Fold 1 Epoch 046; Train loss: 0.0885; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.0868; Time: 00:00:01
Fold 1 Epoch 048; Train loss: 0.0831; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.0813; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.0810; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.577815   0.403680   0.860927   0.494271  
Loss: 0.1100
Fold 1 Epoch 051; Train loss: 0.0780; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.0781; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0768; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.0743; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0701; Time: 00:00:01
Fold 1 Epoch 056; Train loss: 0.0707; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.0685; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.0662; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.0655; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.0642; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.604305   0.355710   0.847682   0.435932  
Loss: 0.0910
Fold 1 Epoch 061; Train loss: 0.0609; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0616; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.0570; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0562; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.0562; Time: 00:00:01
Fold 1 Epoch 066; Train loss: 0.0546; Time: 00:00:01
Fold 1 Epoch 067; Train loss: 0.0512; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.0523; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.0501; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0497; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.468543   0.273557   0.877483   0.408116  
Loss: 0.0766
Fold 1 Epoch 071; Train loss: 0.0481; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0482; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0461; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0451; Time: 00:00:01
Fold 1 Epoch 075; Train loss: 0.0446; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.0440; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0428; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0413; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0414; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0413; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.432119   0.264734   0.862583   0.407271  
Loss: 0.0649
Fold 1 Epoch 081; Train loss: 0.0396; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0403; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0387; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0373; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0364; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0365; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0355; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0345; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0343; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0354; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.428808   0.245952   0.870861   0.390191  
Loss: 0.0519
Fold 1 Epoch 091; Train loss: 0.0320; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0321; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0319; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.0307; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0305; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0293; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0290; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0283; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0275; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0275; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.387417   0.247610   0.879139   0.410727  
Loss: 0.0437
[eps candidate 0.01] Fold 1: HR@10 = [np.float64(0.7052980132450332), np.float64(0.7764900662251656), np.float64(0.7317880794701986), np.float64(0.7582781456953642), np.float64(0.8609271523178808), np.float64(0.847682119205298), np.float64(0.8774834437086093), np.float64(0.8625827814569537), np.float64(0.8708609271523179), np.float64(0.8791390728476821)]
Tuning eps:  40%|████      | 2/5 [03:47<05:40, 113.45s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 18.0853; Time: 00:00:01
Fold 1 Epoch 002; Train loss: 1.5409; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 0.2874; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.3819; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 0.3126; Time: 00:00:01
Fold 1 Epoch 006; Train loss: 0.1927; Time: 00:00:01
Fold 1 Epoch 007; Train loss: 0.1812; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1699; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.1635; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.1549; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.355960   0.284485   0.516556   0.334906  
Loss: 0.1777
Fold 1 Epoch 011; Train loss: 0.1470; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.1402; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.1344; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.1318; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.1241; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.1208; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.1138; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.1062; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.1028; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0961; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.354305   0.305203   0.536424   0.360252  
Loss: 0.1118
Fold 1 Epoch 021; Train loss: 0.0908; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.0840; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0797; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.0740; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0713; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0674; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0671; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0733; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0623; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.0540; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.408940   0.349745   0.711921   0.446006  
Loss: 0.0517
Fold 1 Epoch 031; Train loss: 0.0497; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.0478; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.0445; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.0417; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.0399; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.0367; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.0350; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0336; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0312; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0285; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.394040   0.306235   0.736755   0.412926  
Loss: 0.0264
Fold 1 Epoch 041; Train loss: 0.0274; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.0247; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0238; Time: 00:00:01
Fold 1 Epoch 044; Train loss: 0.0214; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.0198; Time: 00:00:01
Fold 1 Epoch 046; Train loss: 0.0183; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.0172; Time: 00:00:01
Fold 1 Epoch 048; Train loss: 0.0150; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.0132; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.0118; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.473510   0.325438   0.771523   0.423377  
Loss: 0.0115
Fold 1 Epoch 051; Train loss: 0.0107; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.0096; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0084; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.0076; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0067; Time: 00:00:01
Fold 1 Epoch 056; Train loss: 0.0058; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.0052; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.0050; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.0052; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.0055; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.549669   0.427110   0.907285   0.548601  
Loss: 0.0052
Fold 1 Epoch 061; Train loss: 0.0037; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0022; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0010; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 066; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 067; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0004; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.434926   0.899007   0.554952  
Loss: 0.0004
Fold 1 Epoch 071; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 075; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0002; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.436086   0.899007   0.556113  
Loss: 0.0002
Fold 1 Epoch 081; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0002; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.436086   0.899007   0.550092  
Loss: 0.0002
Fold 1 Epoch 091; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0001; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.436086   0.892384   0.548177  
Loss: 0.0001
[eps candidate 0.001] Fold 1: HR@10 = [np.float64(0.5165562913907285), np.float64(0.5364238410596026), np.float64(0.7119205298013245), np.float64(0.7367549668874173), np.float64(0.7715231788079471), np.float64(0.9072847682119205), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8923841059602649)]
Tuning eps:  60%|██████    | 3/5 [05:57<04:02, 121.08s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 47.2106; Time: 00:00:01
Fold 1 Epoch 002; Train loss: 0.9411; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 0.4332; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 3.4465; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 0.2944; Time: 00:00:01
Fold 1 Epoch 006; Train loss: 0.2288; Time: 00:00:01
Fold 1 Epoch 007; Train loss: 0.1992; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1801; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.1741; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.1543; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.420530   0.351153   0.592715   0.404675  
Loss: 0.1642
Fold 1 Epoch 011; Train loss: 0.1440; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.1377; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.1319; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.1306; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.1218; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.1203; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.1176; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.1092; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.1033; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0976; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.382450   0.294778   0.495033   0.330697  
Loss: 0.1042
Fold 1 Epoch 021; Train loss: 0.0998; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.0922; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0875; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.0810; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0760; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0760; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0749; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0677; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0632; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.0650; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.466887   0.342646   0.620861   0.393447  
Loss: 0.0531
Fold 1 Epoch 031; Train loss: 0.0588; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.0590; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.0532; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.0521; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.0513; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.0468; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.0453; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0434; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0420; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0414; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.475166   0.387934   0.594371   0.425475  
Loss: 0.0351
Fold 1 Epoch 041; Train loss: 0.0388; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.0378; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0370; Time: 00:00:01
Fold 1 Epoch 044; Train loss: 0.0354; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.0330; Time: 00:00:01
Fold 1 Epoch 046; Train loss: 0.0332; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.0311; Time: 00:00:01
Fold 1 Epoch 048; Train loss: 0.0292; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.0293; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.0280; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.483444   0.379646   0.807947   0.484320  
Loss: 0.0216
Fold 1 Epoch 051; Train loss: 0.0273; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.0261; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0258; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.0238; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0239; Time: 00:00:01
Fold 1 Epoch 056; Train loss: 0.0216; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.0215; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.0205; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.0192; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.0181; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.635762   0.422765   0.784768   0.471118  
Loss: 0.0161
Fold 1 Epoch 061; Train loss: 0.0169; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0161; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.0166; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0207; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.0352; Time: 00:00:01
Fold 1 Epoch 066; Train loss: 0.0352; Time: 00:00:01
Fold 1 Epoch 067; Train loss: 0.0156; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.0094; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.0076; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0069; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.650662   0.438045   0.819536   0.493482  
Loss: 0.0049
Fold 1 Epoch 071; Train loss: 0.0060; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0049; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0042; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0035; Time: 00:00:01
Fold 1 Epoch 075; Train loss: 0.0028; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.0023; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0018; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0011; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0010; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.395484   0.897351   0.515271  
Loss: 0.0010
Fold 1 Epoch 081; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0018; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0024; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.316053   0.892384   0.434166  
Loss: 0.0049
Fold 1 Epoch 091; Train loss: 0.0035; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0042; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0034; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.0027; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0019; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0011; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0003; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.316053   0.899007   0.430059  
Loss: 0.0004
[eps candidate 0.0001] Fold 1: HR@10 = [np.float64(0.5927152317880795), np.float64(0.49503311258278143), np.float64(0.6208609271523179), np.float64(0.5943708609271523), np.float64(0.8079470198675497), np.float64(0.7847682119205298), np.float64(0.8195364238410596), np.float64(0.8973509933774835), np.float64(0.8923841059602649), np.float64(0.8990066225165563)]
Tuning eps:  80%|████████  | 4/5 [07:54<01:59, 119.70s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 21.8246; Time: 00:00:01
Fold 1 Epoch 002; Train loss: 0.5413; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 0.2635; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.2038; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 0.1806; Time: 00:00:01
Fold 1 Epoch 006; Train loss: 0.2558; Time: 00:00:01
Fold 1 Epoch 007; Train loss: 0.1704; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1296; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.1238; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.1190; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.451987   0.322266   0.574503   0.361889  
Loss: 0.1188
Fold 1 Epoch 011; Train loss: 0.1088; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.0989; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.0954; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.1239; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.1867; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.1033; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.0698; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.0636; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.0590; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0531; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.346026   0.271671   0.675497   0.375428  
Loss: 0.0506
Fold 1 Epoch 021; Train loss: 0.0488; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.0457; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0409; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.0400; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0383; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0346; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0341; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0325; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0408; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.0792; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.299669   0.249169   0.360927   0.268812  
Loss: 0.0999
Fold 1 Epoch 031; Train loss: 0.0751; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.0336; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.0241; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.0225; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.0208; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.0191; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.0190; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0168; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0153; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0141; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.741722   0.504428   0.864238   0.545219  
Loss: 0.0113
Fold 1 Epoch 041; Train loss: 0.0135; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.0136; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0131; Time: 00:00:01
Fold 1 Epoch 044; Train loss: 0.0138; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.0136; Time: 00:00:01
Fold 1 Epoch 046; Train loss: 0.0111; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.0085; Time: 00:00:01
Fold 1 Epoch 048; Train loss: 0.0062; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.0046; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.0035; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.424420   0.899007   0.538425  
Loss: 0.0022
Fold 1 Epoch 051; Train loss: 0.0029; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.0030; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0031; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.0036; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0041; Time: 00:00:01
Fold 1 Epoch 056; Train loss: 0.0039; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.0044; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.0042; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.0039; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.0033; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.899007   0.533569  
Loss: 0.0023
Fold 1 Epoch 061; Train loss: 0.0025; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0022; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.0018; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0017; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.0015; Time: 00:00:01
Fold 1 Epoch 066; Train loss: 0.0015; Time: 00:00:01
Fold 1 Epoch 067; Train loss: 0.0018; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.0024; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.0033; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0041; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.525755   0.899007   0.552337  
Loss: 0.0038
Fold 1 Epoch 071; Train loss: 0.0038; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0032; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0024; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 075; Train loss: 0.0011; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.0010; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0013; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.788079   0.470030   0.899007   0.505117  
Loss: 0.0014
Fold 1 Epoch 081; Train loss: 0.0017; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0019; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0026; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0032; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0035; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0035; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0023; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0004; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.412381   0.892384   0.530685  
Loss: 0.0003
Fold 1 Epoch 091; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0011; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0019; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0032; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0038; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0034; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.304298   0.884106   0.419990  
Loss: 0.0026
[eps candidate 1e-05] Fold 1: HR@10 = [np.float64(0.5745033112582781), np.float64(0.6754966887417219), np.float64(0.3609271523178808), np.float64(0.8642384105960265), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8923841059602649), np.float64(0.8841059602649006)]
Tuning eps: 100%|██████████| 5/5 [09:50<00:00, 118.34s/it]Tuning eps: 100%|██████████| 5/5 [09:50<00:00, 118.14s/it]

Best eps found: 0.0001
Tuning data for lr saved to ./category/tuning_lr.json
Tuning data for optimizer saved to ./category/tuning_optimizer.json
Tuning data for timesteps saved to ./category/tuning_timesteps.json
Tuning data for dropout_rate saved to ./category/tuning_dropout.json
Tuning data for l2_decay saved to ./category/tuning_l2.json
Tuning data for eps saved to ./category/tuning_eps.json

========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 47.3570; Time: 00:00:01
Fold 1 Epoch 002; Train loss: 0.9508; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 2.6796; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.5956; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 0.3012; Time: 00:00:01
Fold 1 Epoch 006; Train loss: 0.2679; Time: 00:00:01
Fold 1 Epoch 007; Train loss: 0.2293; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1974; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.1869; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.1674; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.456954   0.311255   0.561258   0.343880  
Loss: 0.1722
Fold 1 Epoch 011; Train loss: 0.1537; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.1440; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.1364; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.1426; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.3465; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.3107; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.1135; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.1016; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.0967; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0897; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.453642   0.338673   0.538079   0.365495  
Loss: 0.0933
Fold 1 Epoch 021; Train loss: 0.0873; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.0824; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0777; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.0746; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0718; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0670; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0660; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0624; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0573; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.0568; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.322848   0.238204   0.420530   0.269607  
Loss: 0.0554
Fold 1 Epoch 031; Train loss: 0.0527; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.0506; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.0484; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.0470; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.0444; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.0412; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.0413; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0383; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0383; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0373; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.326159   0.252888   0.473510   0.300661  
Loss: 0.0432
Fold 1 Epoch 041; Train loss: 0.0383; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.0427; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0531; Time: 00:00:01
Fold 1 Epoch 044; Train loss: 0.0567; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.0441; Time: 00:00:01
Fold 1 Epoch 046; Train loss: 0.0294; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.0269; Time: 00:00:01
Fold 1 Epoch 048; Train loss: 0.0246; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.0228; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.0230; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.256623   0.182719   0.665563   0.313359  
Loss: 0.0196
Fold 1 Epoch 051; Train loss: 0.0210; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.0193; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0184; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.0173; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0163; Time: 00:00:01
Fold 1 Epoch 056; Train loss: 0.0150; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.0144; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.0129; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.0121; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.0119; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.559603   0.427421   0.892384   0.542585  
Loss: 0.0131
Fold 1 Epoch 061; Train loss: 0.0120; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0112; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.0116; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0111; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.0099; Time: 00:00:01
Fold 1 Epoch 066; Train loss: 0.0086; Time: 00:00:01
Fold 1 Epoch 067; Train loss: 0.0079; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.0063; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.0046; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0041; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.537924   0.892384   0.562266  
Loss: 0.0059
Fold 1 Epoch 071; Train loss: 0.0033; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0024; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0023; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0023; Time: 00:00:01
Fold 1 Epoch 075; Train loss: 0.0022; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.0022; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0023; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0027; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0037; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0038; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.899007   0.533569  
Loss: 0.0066
Fold 1 Epoch 081; Train loss: 0.0032; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0024; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0010; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0012; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.892384   0.531655  
Loss: 0.0033
Fold 1 Epoch 091; Train loss: 0.0021; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0040; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0046; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.0037; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0020; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0004; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.899007   0.533569  
Loss: 0.0008
Tuning fold metrics saved to ./category/fold_metrics_tune.txt
Best candidates saved to ./category/best_candidates.json

========== Running Experimental Folds for Genre Model ==========

========== Experiment p1 ==========
Experiment p1 Epoch 001; Train loss: 36.7113; Time: 00:00:00
Experiment p1 Epoch 002; Train loss: 6.4916; Time: 00:00:00
Experiment p1 Epoch 003; Train loss: 0.5125; Time: 00:00:00
Experiment p1 Epoch 004; Train loss: 0.1566; Time: 00:00:00
Experiment p1 Epoch 005; Train loss: 0.1111; Time: 00:00:00
Experiment p1 Epoch 006; Train loss: 0.0932; Time: 00:00:00
Experiment p1 Epoch 007; Train loss: 0.0766; Time: 00:00:00
Experiment p1 Epoch 008; Train loss: 0.0666; Time: 00:00:00
Experiment p1 Epoch 009; Train loss: 0.0674; Time: 00:00:00
Experiment p1 Epoch 010; Train loss: 0.0440; Time: 00:00:00
Experiment p1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.450331   0.347546   0.612583   0.399406  
Loss: 0.0395
Experiment p1 Epoch 011; Train loss: 0.0346; Time: 00:00:00
Experiment p1 Epoch 012; Train loss: 0.0290; Time: 00:00:00
Experiment p1 Epoch 013; Train loss: 0.0232; Time: 00:00:00
Experiment p1 Epoch 014; Train loss: 0.0201; Time: 00:00:00
Experiment p1 Epoch 015; Train loss: 0.0161; Time: 00:00:00
Experiment p1 Epoch 016; Train loss: 0.0097; Time: 00:00:00
Experiment p1 Epoch 017; Train loss: 0.0053; Time: 00:00:00
Experiment p1 Epoch 018; Train loss: 0.0025; Time: 00:00:00
Experiment p1 Epoch 019; Train loss: 0.0024; Time: 00:00:00
Experiment p1 Epoch 020; Train loss: 0.0014; Time: 00:00:00
Experiment p1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.564570   0.411704   0.916391   0.522649  
Loss: 0.0004
Experiment p1 Epoch 021; Train loss: 0.0004; Time: 00:00:00
Experiment p1 Epoch 022; Train loss: 0.0003; Time: 00:00:00
Experiment p1 Epoch 023; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 024; Train loss: 0.0003; Time: 00:00:00
Experiment p1 Epoch 025; Train loss: 0.0015; Time: 00:00:00
Experiment p1 Epoch 026; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 027; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 028; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 029; Train loss: 0.0005; Time: 00:00:00
Experiment p1 Epoch 030; Train loss: 0.0012; Time: 00:00:00
Experiment p1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.564570   0.411704   0.916391   0.527308  
Loss: 0.0001
Experiment p1 Epoch 031; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 032; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 033; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 034; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 035; Train loss: 0.0009; Time: 00:00:00
Experiment p1 Epoch 036; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 037; Train loss: 0.0003; Time: 00:00:00
Experiment p1 Epoch 038; Train loss: 0.0003; Time: 00:00:00
Experiment p1 Epoch 039; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 040; Train loss: 0.0001; Time: 00:00:00
Experiment p1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.564570   0.432479   0.916391   0.548084  
Loss: 0.0001
Experiment p1 Epoch 041; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 042; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 043; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 044; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 045; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 046; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 047; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 048; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 049; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 050; Train loss: 0.0000; Time: 00:00:00
Experiment p1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.564570   0.411704   0.916391   0.533065  
Loss: 0.0001
Experiment p1 Epoch 051; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 052; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 053; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 054; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 055; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 056; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 057; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 058; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 059; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 060; Train loss: 0.0000; Time: 00:00:00
Experiment p1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.539735   0.402097   0.916391   0.526547  
Loss: 0.0000
Experiment p1 Epoch 061; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 062; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 063; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 064; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 065; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 066; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 067; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 068; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 069; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 070; Train loss: 0.0000; Time: 00:00:00
Experiment p1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.791391   0.520226   0.916391   0.560494  
Loss: 0.0000
Experiment p1 Epoch 071; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 072; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 073; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 074; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 075; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 076; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 077; Train loss: 0.0000; Time: 00:00:00
Experiment p1 Epoch 078; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 079; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 080; Train loss: 0.0001; Time: 00:00:00
Experiment p1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.564570   0.412756   0.916391   0.523644  
Loss: 0.0001
Experiment p1 Epoch 081; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 082; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 083; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 084; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 085; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 086; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 087; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 088; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 089; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 090; Train loss: 0.0001; Time: 00:00:00
Experiment p1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.731788   0.462895   0.939570   0.531468  
Loss: 0.0001
Experiment p1 Epoch 091; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 092; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 093; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 094; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 095; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 097; Train loss: 0.0003; Time: 00:00:00
Experiment p1 Epoch 098; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 099; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Experiment p1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.322848   0.138372   0.615894   0.238008  
Loss: 0.0002

========== Experiment p2 ==========
Experiment p2 Epoch 001; Train loss: 23.9265; Time: 00:00:00
Experiment p2 Epoch 002; Train loss: 5.9589; Time: 00:00:01
Experiment p2 Epoch 003; Train loss: 0.6011; Time: 00:00:00
Experiment p2 Epoch 004; Train loss: 0.2266; Time: 00:00:00
Experiment p2 Epoch 005; Train loss: 0.1283; Time: 00:00:00
Experiment p2 Epoch 006; Train loss: 0.1051; Time: 00:00:01
Experiment p2 Epoch 007; Train loss: 0.0872; Time: 00:00:00
Experiment p2 Epoch 008; Train loss: 0.0713; Time: 00:00:00
Experiment p2 Epoch 009; Train loss: 0.0585; Time: 00:00:00
Experiment p2 Epoch 010; Train loss: 0.0468; Time: 00:00:00
Experiment p2: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.113411   0.069071   0.374172   0.149651  
Loss: 0.0425
Experiment p2 Epoch 011; Train loss: 0.0423; Time: 00:00:00
Experiment p2 Epoch 012; Train loss: 0.0374; Time: 00:00:00
Experiment p2 Epoch 013; Train loss: 0.0268; Time: 00:00:00
Experiment p2 Epoch 014; Train loss: 0.0225; Time: 00:00:00
Experiment p2 Epoch 015; Train loss: 0.0179; Time: 00:00:00
Experiment p2 Epoch 016; Train loss: 0.0146; Time: 00:00:00
Experiment p2 Epoch 017; Train loss: 0.0097; Time: 00:00:01
Experiment p2 Epoch 018; Train loss: 0.0066; Time: 00:00:01
Experiment p2 Epoch 019; Train loss: 0.0051; Time: 00:00:00
Experiment p2 Epoch 020; Train loss: 0.0053; Time: 00:00:00
Experiment p2: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.376656   0.190122   0.893212   0.360690  
Loss: 0.0017
Experiment p2 Epoch 021; Train loss: 0.0013; Time: 00:00:00
Experiment p2 Epoch 022; Train loss: 0.0006; Time: 00:00:01
Experiment p2 Epoch 023; Train loss: 0.0003; Time: 00:00:00
Experiment p2 Epoch 024; Train loss: 0.0003; Time: 00:00:00
Experiment p2 Epoch 025; Train loss: 0.0005; Time: 00:00:00
Experiment p2 Epoch 026; Train loss: 0.0023; Time: 00:00:00
Experiment p2 Epoch 027; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 028; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 029; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 030; Train loss: 0.0001; Time: 00:00:00
Experiment p2: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.529801   0.254019   0.875000   0.364771  
Loss: 0.0002
Experiment p2 Epoch 031; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 032; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 033; Train loss: 0.0001; Time: 00:00:00
Experiment p2 Epoch 034; Train loss: 0.0008; Time: 00:00:00
Experiment p2 Epoch 035; Train loss: 0.0008; Time: 00:00:00
Experiment p2 Epoch 036; Train loss: 0.0003; Time: 00:00:01
Experiment p2 Epoch 037; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 038; Train loss: 0.0001; Time: 00:00:00
Experiment p2 Epoch 039; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 040; Train loss: 0.0001; Time: 00:00:00
Experiment p2: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.529801   0.258602   0.875000   0.369353  
Loss: 0.0001
Experiment p2 Epoch 041; Train loss: 0.0001; Time: 00:00:00
Experiment p2 Epoch 042; Train loss: 0.0000; Time: 00:00:00
Experiment p2 Epoch 043; Train loss: 0.0000; Time: 00:00:00
Experiment p2 Epoch 044; Train loss: 0.0000; Time: 00:00:00
Experiment p2 Epoch 045; Train loss: 0.0001; Time: 00:00:00
Experiment p2 Epoch 046; Train loss: 0.0001; Time: 00:00:00
Experiment p2 Epoch 047; Train loss: 0.0000; Time: 00:00:00
Experiment p2 Epoch 048; Train loss: 0.0000; Time: 00:00:00
Experiment p2 Epoch 049; Train loss: 0.0000; Time: 00:00:00
Experiment p2 Epoch 050; Train loss: 0.0000; Time: 00:00:01
Experiment p2: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.529801   0.258602   0.875000   0.365888  
Loss: 0.0000
Experiment p2 Epoch 051; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 052; Train loss: 0.0001; Time: 00:00:00
Experiment p2 Epoch 053; Train loss: 0.0001; Time: 00:00:00
Experiment p2 Epoch 054; Train loss: 0.0000; Time: 00:00:00
Experiment p2 Epoch 055; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 056; Train loss: 0.0000; Time: 00:00:00
Experiment p2 Epoch 057; Train loss: 0.0000; Time: 00:00:00
Experiment p2 Epoch 058; Train loss: 0.0000; Time: 00:00:00
Experiment p2 Epoch 059; Train loss: 0.0000; Time: 00:00:00
Experiment p2 Epoch 060; Train loss: 0.0000; Time: 00:00:00
Experiment p2: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.529801   0.258602   0.875000   0.369353  
Loss: 0.0000
Experiment p2 Epoch 061; Train loss: 0.0000; Time: 00:00:00
Experiment p2 Epoch 062; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 063; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 064; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 065; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 066; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 067; Train loss: 0.0000; Time: 00:00:00
Experiment p2 Epoch 068; Train loss: 0.0001; Time: 00:00:00
Experiment p2 Epoch 069; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 070; Train loss: 0.0001; Time: 00:00:01
Experiment p2: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.529801   0.258602   0.875000   0.369297  
Loss: 0.0001
Experiment p2 Epoch 071; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 072; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 073; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 074; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 075; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 076; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 077; Train loss: 0.0004; Time: 00:00:01
Experiment p2 Epoch 078; Train loss: 0.0005; Time: 00:00:01
Experiment p2 Epoch 079; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 080; Train loss: 0.0000; Time: 00:00:01
Experiment p2: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.361755   0.182226   0.875000   0.341595  
Loss: 0.0000
Experiment p2 Epoch 081; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 082; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 083; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 084; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 085; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 086; Train loss: 0.0000; Time: 00:00:01
Experiment p2 Epoch 087; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 088; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 089; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 090; Train loss: 0.0001; Time: 00:00:01
Experiment p2: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.048013   0.027981   0.436258   0.145971  
Loss: 0.0001
Experiment p2 Epoch 091; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 092; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 093; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 094; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 095; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 096; Train loss: 0.0003; Time: 00:00:01
Experiment p2 Epoch 097; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 098; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 099; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 100; Train loss: 0.0000; Time: 00:00:01
Experiment p2: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.528146   0.294264   0.893212   0.403662  
Loss: 0.0000
Experimental fold metrics saved to category/genre_exp_p1_metrics.txt and category/genre_exp_p2_metrics.txt

========== Running Experimental Fold p3 for Genre Model ==========

========== Experiment p3 ==========
Experiment p3 Epoch 001; Train loss: 33.4464; Time: 00:00:02
Experiment p3 Epoch 002; Train loss: 7.1656; Time: 00:00:02
Experiment p3 Epoch 003; Train loss: 0.3833; Time: 00:00:02
Experiment p3 Epoch 004; Train loss: 0.3255; Time: 00:00:02
Experiment p3 Epoch 005; Train loss: 1.4152; Time: 00:00:02
Experiment p3 Epoch 006; Train loss: 0.2330; Time: 00:00:02
Experiment p3 Epoch 007; Train loss: 0.2032; Time: 00:00:02
Experiment p3 Epoch 008; Train loss: 0.1840; Time: 00:00:02
Experiment p3 Epoch 009; Train loss: 0.1672; Time: 00:00:02
Experiment p3 Epoch 010; Train loss: 0.1599; Time: 00:00:02
Experiment p3: Validation Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.382450   0.259502   0.541391   0.310758  
Loss: 0.1936
Experiment p3 Epoch 011; Train loss: 0.1555; Time: 00:00:02
Experiment p3 Epoch 012; Train loss: 0.1440; Time: 00:00:02
Experiment p3 Epoch 013; Train loss: 0.1377; Time: 00:00:02
Experiment p3 Epoch 014; Train loss: 0.1351; Time: 00:00:02
Experiment p3 Epoch 015; Train loss: 0.1330; Time: 00:00:02
Experiment p3 Epoch 016; Train loss: 0.1229; Time: 00:00:02
Experiment p3 Epoch 017; Train loss: 0.1219; Time: 00:00:01
Experiment p3 Epoch 018; Train loss: 0.1201; Time: 00:00:02
Experiment p3 Epoch 019; Train loss: 0.1178; Time: 00:00:02
Experiment p3 Epoch 020; Train loss: 0.1094; Time: 00:00:01
Experiment p3: Validation Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.402318   0.274699   0.518212   0.312983  
Loss: 0.1056
Experiment p3 Epoch 021; Train loss: 0.1051; Time: 00:00:02
Experiment p3 Epoch 022; Train loss: 0.1010; Time: 00:00:03
Experiment p3 Epoch 023; Train loss: 0.0910; Time: 00:00:02
Experiment p3 Epoch 024; Train loss: 0.0890; Time: 00:00:02
Experiment p3 Epoch 025; Train loss: 0.0871; Time: 00:00:02
Experiment p3 Epoch 026; Train loss: 0.0841; Time: 00:00:02
Experiment p3 Epoch 027; Train loss: 0.0778; Time: 00:00:02
Experiment p3 Epoch 028; Train loss: 0.0748; Time: 00:00:01
Experiment p3 Epoch 029; Train loss: 0.0757; Time: 00:00:02
Experiment p3 Epoch 030; Train loss: 0.0820; Time: 00:00:01
Experiment p3: Validation Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.465232   0.332841   0.599338   0.376830  
Loss: 0.0659
Experiment p3 Epoch 031; Train loss: 0.0915; Time: 00:00:02
Experiment p3 Epoch 032; Train loss: 0.1020; Time: 00:00:02
Experiment p3 Epoch 033; Train loss: 0.0889; Time: 00:00:01
Experiment p3 Epoch 034; Train loss: 0.0660; Time: 00:00:02
Experiment p3 Epoch 035; Train loss: 0.0628; Time: 00:00:02
Experiment p3 Epoch 036; Train loss: 0.0576; Time: 00:00:02
Experiment p3 Epoch 037; Train loss: 0.0545; Time: 00:00:01
Experiment p3 Epoch 038; Train loss: 0.0524; Time: 00:00:02
Experiment p3 Epoch 039; Train loss: 0.0503; Time: 00:00:02
Experiment p3 Epoch 040; Train loss: 0.0501; Time: 00:00:01
Experiment p3: Validation Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.493377   0.341488   0.635762   0.387403  
Loss: 0.0373
Experiment p3 Epoch 041; Train loss: 0.0498; Time: 00:00:02
Experiment p3 Epoch 042; Train loss: 0.0499; Time: 00:00:02
Experiment p3 Epoch 043; Train loss: 0.0481; Time: 00:00:02
Experiment p3 Epoch 044; Train loss: 0.0448; Time: 00:00:02
Experiment p3 Epoch 045; Train loss: 0.0449; Time: 00:00:02
Experiment p3 Epoch 046; Train loss: 0.0432; Time: 00:00:02
Experiment p3 Epoch 047; Train loss: 0.0412; Time: 00:00:02
Experiment p3 Epoch 048; Train loss: 0.0386; Time: 00:00:02
Experiment p3 Epoch 049; Train loss: 0.0377; Time: 00:00:01
Experiment p3 Epoch 050; Train loss: 0.0369; Time: 00:00:02
Experiment p3: Validation Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.539735   0.380201   0.710265   0.435066  
Loss: 0.0288
Experiment p3 Epoch 051; Train loss: 0.0356; Time: 00:00:01
Experiment p3 Epoch 052; Train loss: 0.0360; Time: 00:00:02
Experiment p3 Epoch 053; Train loss: 0.0348; Time: 00:00:02
Experiment p3 Epoch 054; Train loss: 0.0375; Time: 00:00:01
Experiment p3 Epoch 055; Train loss: 0.0359; Time: 00:00:02
Experiment p3 Epoch 056; Train loss: 0.0324; Time: 00:00:02
Experiment p3 Epoch 057; Train loss: 0.0308; Time: 00:00:02
Experiment p3 Epoch 058; Train loss: 0.0287; Time: 00:00:02
Experiment p3 Epoch 059; Train loss: 0.0269; Time: 00:00:02
Experiment p3 Epoch 060; Train loss: 0.0257; Time: 00:00:02
Experiment p3: Validation Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.488411   0.332569   0.748344   0.416774  
Loss: 0.0178
Experiment p3 Epoch 061; Train loss: 0.0244; Time: 00:00:02
Experiment p3 Epoch 062; Train loss: 0.0239; Time: 00:00:02
Experiment p3 Epoch 063; Train loss: 0.0236; Time: 00:00:01
Experiment p3 Epoch 064; Train loss: 0.0229; Time: 00:00:02
Experiment p3 Epoch 065; Train loss: 0.0238; Time: 00:00:02
Experiment p3 Epoch 066; Train loss: 0.0222; Time: 00:00:02
Experiment p3 Epoch 067; Train loss: 0.0218; Time: 00:00:02
Experiment p3 Epoch 068; Train loss: 0.0201; Time: 00:00:02
Experiment p3 Epoch 069; Train loss: 0.0195; Time: 00:00:02
Experiment p3 Epoch 070; Train loss: 0.0184; Time: 00:00:02
Experiment p3: Validation Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.488411   0.357940   0.875828   0.486993  
Loss: 0.0135
Experiment p3 Epoch 071; Train loss: 0.0171; Time: 00:00:01
Experiment p3 Epoch 072; Train loss: 0.0156; Time: 00:00:02
Experiment p3 Epoch 073; Train loss: 0.0139; Time: 00:00:02
Experiment p3 Epoch 074; Train loss: 0.0129; Time: 00:00:02
Experiment p3 Epoch 075; Train loss: 0.0121; Time: 00:00:02
Experiment p3 Epoch 076; Train loss: 0.0117; Time: 00:00:02
Experiment p3 Epoch 077; Train loss: 0.0114; Time: 00:00:02
Experiment p3 Epoch 078; Train loss: 0.0105; Time: 00:00:02
Experiment p3 Epoch 079; Train loss: 0.0100; Time: 00:00:02
Experiment p3 Epoch 080; Train loss: 0.0094; Time: 00:00:02
Experiment p3: Validation Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.380795   0.305664   0.855960   0.464423  
Loss: 0.0072
Experiment p3 Epoch 081; Train loss: 0.0084; Time: 00:00:02
Experiment p3 Epoch 082; Train loss: 0.0081; Time: 00:00:02
Experiment p3 Epoch 083; Train loss: 0.0076; Time: 00:00:02
Experiment p3 Epoch 084; Train loss: 0.0067; Time: 00:00:02
Experiment p3 Epoch 085; Train loss: 0.0062; Time: 00:00:02
Experiment p3 Epoch 086; Train loss: 0.0055; Time: 00:00:02
Experiment p3 Epoch 087; Train loss: 0.0051; Time: 00:00:02
Experiment p3 Epoch 088; Train loss: 0.0044; Time: 00:00:01
Experiment p3 Epoch 089; Train loss: 0.0037; Time: 00:00:01
Experiment p3 Epoch 090; Train loss: 0.0031; Time: 00:00:02
Experiment p3: Validation Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.359272   0.287352   0.894040   0.462669  
Loss: 0.0021
Experiment p3 Epoch 091; Train loss: 0.0026; Time: 00:00:02
Experiment p3 Epoch 092; Train loss: 0.0025; Time: 00:00:01
Experiment p3 Epoch 093; Train loss: 0.0022; Time: 00:00:02
Experiment p3 Epoch 094; Train loss: 0.0019; Time: 00:00:01
Experiment p3 Epoch 095; Train loss: 0.0016; Time: 00:00:02
Experiment p3 Epoch 096; Train loss: 0.0013; Time: 00:00:02
Experiment p3 Epoch 097; Train loss: 0.0011; Time: 00:00:01
Experiment p3 Epoch 098; Train loss: 0.0011; Time: 00:00:02
Experiment p3 Epoch 099; Train loss: 0.0012; Time: 00:00:02
Experiment p3 Epoch 100; Train loss: 0.0013; Time: 00:00:02
Experiment p3: Validation Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.394040   0.315314   0.895695   0.477770  
Loss: 0.0011
Final Evaluation on p3 test set:
HR@5       NDCG@5     HR@10      NDCG@10   
0.336093   0.190721   0.660596   0.298264  
Loss: 0.0012
Experimental fold metrics saved to category/genre_exp_p3_metrics.txt
Tuning lr:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 53.3455; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.7644; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.3038; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.2507; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.2123; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.1857; Time: 00:00:01
Fold 3 Epoch 007; Train loss: 0.1585; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.1412; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.1224; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.1111; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.362583   0.262551   0.683775   0.364848  
Loss: 0.1200
Fold 3 Epoch 011; Train loss: 0.0993; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0912; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0837; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0801; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0739; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0702; Time: 00:00:01
Fold 3 Epoch 017; Train loss: 0.0667; Time: 00:00:01
Fold 3 Epoch 018; Train loss: 0.0631; Time: 00:00:01
Fold 3 Epoch 019; Train loss: 0.0607; Time: 00:00:01
Fold 3 Epoch 020; Train loss: 0.0610; Time: 00:00:01
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.399007   0.289719   0.632450   0.365714  
Loss: 0.0725
Fold 3 Epoch 021; Train loss: 0.0586; Time: 00:00:01
Fold 3 Epoch 022; Train loss: 0.0628; Time: 00:00:01
Fold 3 Epoch 023; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0570; Time: 00:00:01
Fold 3 Epoch 025; Train loss: 0.0518; Time: 00:00:01
Fold 3 Epoch 026; Train loss: 0.0510; Time: 00:00:01
Fold 3 Epoch 027; Train loss: 0.0490; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0468; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0460; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0447; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.314570   0.196349   0.528146   0.263919  
Loss: 0.0585
Fold 3 Epoch 031; Train loss: 0.0451; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0454; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0477; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0516; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0475; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0432; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0423; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0392; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0396; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0396; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.329470   0.223625   0.519868   0.283636  
Loss: 0.0489
Fold 3 Epoch 041; Train loss: 0.0384; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0376; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0365; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0355; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0350; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0359; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0361; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0409; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0466; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0390; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.321192   0.211398   0.407285   0.239382  
Loss: 0.0492
Fold 3 Epoch 051; Train loss: 0.0339; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0323; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0305; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0294; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0303; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0290; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0285; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0280; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0269; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0266; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.352649   0.303415   0.584437   0.377999  
Loss: 0.0363
Fold 3 Epoch 061; Train loss: 0.0276; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0253; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0263; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0249; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0254; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0257; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0285; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0276; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0271; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0255; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.354305   0.245958   0.549669   0.307818  
Loss: 0.0248
Fold 3 Epoch 071; Train loss: 0.0229; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0220; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0220; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0213; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0208; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0207; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0197; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0203; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0194; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0198; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.360927   0.271893   0.529801   0.326331  
Loss: 0.0224
Fold 3 Epoch 081; Train loss: 0.0193; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0186; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0183; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0185; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0185; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0195; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0242; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0238; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0191; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0177; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.296358   0.228858   0.438742   0.274540  
Loss: 0.0168
Fold 3 Epoch 091; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0165; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0167; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0162; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0148; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0151; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0154; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0153; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0148; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.599338   0.422317   0.690397   0.451522  
Loss: 0.0195
[lr candidate 0.05] Fold 3: HR@10 = [np.float64(0.6837748344370861), np.float64(0.6324503311258278), np.float64(0.5281456953642384), np.float64(0.5198675496688742), np.float64(0.40728476821192056), np.float64(0.5844370860927153), np.float64(0.5496688741721855), np.float64(0.5298013245033113), np.float64(0.43874172185430466), np.float64(0.6903973509933775)]
Tuning lr:  25%|██▌       | 1/4 [01:34<04:43, 94.66s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.6668; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2270; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1519; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1159; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.1009; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0946; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0906; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0830; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0818; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0779; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.614238   0.410479   0.774834   0.462108  
Loss: 0.0991
Fold 3 Epoch 011; Train loss: 0.0769; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0759; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0733; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0716; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0691; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0664; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0685; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0628; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0628; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0632; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.531457   0.351225   0.705298   0.407466  
Loss: 0.0748
Fold 3 Epoch 021; Train loss: 0.0614; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0607; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0592; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0571; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0575; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0559; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0542; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0522; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0534; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0514; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.597682   0.454950   0.710265   0.492063  
Loss: 0.0610
Fold 3 Epoch 031; Train loss: 0.0515; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0494; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0477; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0481; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0457; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0455; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0444; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0433; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0422; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0410; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.445364   0.337134   0.567881   0.376266  
Loss: 0.0510
Fold 3 Epoch 041; Train loss: 0.0395; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0396; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0372; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0366; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0361; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0349; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0341; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0331; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0320; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0311; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.485099   0.360223   0.605960   0.399302  
Loss: 0.0344
Fold 3 Epoch 051; Train loss: 0.0302; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0283; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0276; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0269; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0263; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0249; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0255; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0248; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0238; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0237; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.552980   0.383514   0.673841   0.423018  
Loss: 0.0250
Fold 3 Epoch 061; Train loss: 0.0225; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0219; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0215; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0210; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0197; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0199; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0200; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0202; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0190; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0185; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.513245   0.361303   0.649007   0.405161  
Loss: 0.0189
Fold 3 Epoch 071; Train loss: 0.0184; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0183; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0180; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0184; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0174; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0176; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0170; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0167; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.414351   0.637417   0.450696  
Loss: 0.0156
Fold 3 Epoch 081; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0160; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0161; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0150; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0156; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0152; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0154; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0149; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0139; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.514901   0.351893   0.652318   0.396474  
Loss: 0.0135
Fold 3 Epoch 091; Train loss: 0.0136; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0129; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0127; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0127; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0119; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0115; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0107; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0109; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0098; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.511589   0.317161   0.784768   0.404445  
Loss: 0.0091
[lr candidate 0.01] Fold 3: HR@10 = [np.float64(0.7748344370860927), np.float64(0.7052980132450332), np.float64(0.7102649006622517), np.float64(0.5678807947019867), np.float64(0.6059602649006622), np.float64(0.6738410596026491), np.float64(0.6490066225165563), np.float64(0.6374172185430463), np.float64(0.652317880794702), np.float64(0.7847682119205298)]
Tuning lr:  50%|█████     | 2/4 [03:03<03:02, 91.19s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.7855; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.3544; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.2256; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1655; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.1315; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.1126; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.1026; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0977; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0942; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0886; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.649007   0.490190   0.763245   0.526907  
Loss: 0.1221
Fold 3 Epoch 011; Train loss: 0.0854; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0822; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0809; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0790; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0782; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0742; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0741; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0728; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0725; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0710; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.493377   0.372464   0.644040   0.420438  
Loss: 0.0962
Fold 3 Epoch 021; Train loss: 0.0690; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0683; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0682; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0674; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0666; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0654; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0634; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0636; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0623; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.591060   0.467486   0.756623   0.520962  
Loss: 0.0812
Fold 3 Epoch 031; Train loss: 0.0616; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0608; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0621; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0622; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0593; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0593; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0588; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0583; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0567; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0573; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.607616   0.463659   0.768212   0.516083  
Loss: 0.0721
Fold 3 Epoch 041; Train loss: 0.0566; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0563; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0577; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0549; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0544; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0537; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0532; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0519; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0521; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0510; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.619205   0.484605   0.774834   0.535020  
Loss: 0.0648
Fold 3 Epoch 051; Train loss: 0.0517; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0509; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0492; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0491; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0490; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0479; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0475; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0467; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0464; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0448; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.526490   0.421897   0.653974   0.462845  
Loss: 0.0533
Fold 3 Epoch 061; Train loss: 0.0466; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0451; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0446; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0451; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0438; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0433; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0426; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0422; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0418; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0405; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.544702   0.368859   0.693709   0.417584  
Loss: 0.0531
Fold 3 Epoch 071; Train loss: 0.0418; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0401; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0408; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0394; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0387; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0380; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0375; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0372; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0367; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0352; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.476821   0.355594   0.619205   0.402035  
Loss: 0.0464
Fold 3 Epoch 081; Train loss: 0.0351; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0345; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0344; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0340; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0348; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0335; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0330; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0318; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0320; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0313; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.634106   0.482442   0.758278   0.522657  
Loss: 0.0391
Fold 3 Epoch 091; Train loss: 0.0313; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0311; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0316; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0306; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0307; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0291; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0294; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0284; Time: 00:00:01
Fold 3 Epoch 099; Train loss: 0.0289; Time: 00:00:01
Fold 3 Epoch 100; Train loss: 0.0282; Time: 00:00:01
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.584437   0.439848   0.745033   0.491606  
Loss: 0.0352
[lr candidate 0.005] Fold 3: HR@10 = [np.float64(0.7632450331125827), np.float64(0.6440397350993378), np.float64(0.7566225165562914), np.float64(0.7682119205298014), np.float64(0.7748344370860927), np.float64(0.6539735099337748), np.float64(0.6937086092715232), np.float64(0.6192052980132451), np.float64(0.7582781456953642), np.float64(0.7450331125827815)]
Tuning lr:  75%|███████▌  | 3/4 [04:33<01:30, 90.69s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 1.0811; Time: 00:00:01
Fold 3 Epoch 002; Train loss: 0.7940; Time: 00:00:01
Fold 3 Epoch 003; Train loss: 0.6209; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.5226; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.4421; Time: 00:00:01
Fold 3 Epoch 006; Train loss: 0.3818; Time: 00:00:01
Fold 3 Epoch 007; Train loss: 0.3359; Time: 00:00:01
Fold 3 Epoch 008; Train loss: 0.2949; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.2653; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.2401; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.758278   0.596220   0.834437   0.620963  
Loss: 0.3897
Fold 3 Epoch 011; Train loss: 0.2223; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.2018; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.1889; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.1763; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.1652; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.1552; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.1485; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.1439; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.1377; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.1314; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.726821   0.580559   0.816225   0.609545  
Loss: 0.2140
Fold 3 Epoch 021; Train loss: 0.1287; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.1236; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.1220; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.1167; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.1140; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.1105; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.1091; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.1075; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.1053; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.1047; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.703642   0.565010   0.794702   0.594127  
Loss: 0.1602
Fold 3 Epoch 031; Train loss: 0.1002; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.1009; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0990; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0976; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0972; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0967; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0956; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0933; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0941; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0905; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.701987   0.570176   0.786424   0.597349  
Loss: 0.1345
Fold 3 Epoch 041; Train loss: 0.0905; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0878; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0891; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0891; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0877; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0848; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0857; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0836; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0829; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0830; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.751656   0.596690   0.826159   0.620601  
Loss: 0.1237
Fold 3 Epoch 051; Train loss: 0.0833; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0832; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0829; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0812; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0821; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0809; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0803; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0794; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0801; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0793; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.678808   0.534506   0.771523   0.564359  
Loss: 0.1133
Fold 3 Epoch 061; Train loss: 0.0774; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0772; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0784; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0789; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0772; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0757; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0762; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0754; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0748; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0762; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.612583   0.463471   0.758278   0.510216  
Loss: 0.1094
Fold 3 Epoch 071; Train loss: 0.0746; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0749; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0753; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0761; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0742; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0736; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0732; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0718; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0748; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0732; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.733444   0.579628   0.819536   0.607186  
Loss: 0.1002
Fold 3 Epoch 081; Train loss: 0.0735; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0719; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0711; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0717; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0717; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0701; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0709; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0716; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0717; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0705; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.708609   0.557797   0.786424   0.582583  
Loss: 0.0932
Fold 3 Epoch 091; Train loss: 0.0707; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0688; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0704; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0712; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0671; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0688; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0688; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0680; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0697; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0679; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.682119   0.530064   0.766556   0.557627  
Loss: 0.0962
[lr candidate 0.001] Fold 3: HR@10 = [np.float64(0.8344370860927153), np.float64(0.8162251655629139), np.float64(0.7947019867549668), np.float64(0.7864238410596026), np.float64(0.8261589403973509), np.float64(0.7715231788079471), np.float64(0.7582781456953642), np.float64(0.8195364238410596), np.float64(0.7864238410596026), np.float64(0.7665562913907285)]
Tuning lr: 100%|██████████| 4/4 [06:03<00:00, 90.48s/it]Tuning lr: 100%|██████████| 4/4 [06:03<00:00, 90.92s/it]

Best learning rate found: 0.01
Tuning optimizer:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.6039; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2145; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1402; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1123; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.0995; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0917; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0810; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0786; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0750; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0723; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.501656   0.389069   0.687086   0.448412  
Loss: 0.0933
Fold 3 Epoch 011; Train loss: 0.0692; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0701; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0678; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0663; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0634; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0634; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0608; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0612; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0575; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.473510   0.336624   0.624172   0.385027  
Loss: 0.0681
Fold 3 Epoch 021; Train loss: 0.0568; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0561; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0556; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0527; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0535; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0519; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0508; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0493; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0485; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0478; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.604305   0.463912   0.738411   0.507082  
Loss: 0.0562
Fold 3 Epoch 031; Train loss: 0.0467; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0457; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0447; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0426; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0419; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0408; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0398; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0397; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0387; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0365; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.466887   0.321537   0.644040   0.378019  
Loss: 0.0409
Fold 3 Epoch 041; Train loss: 0.0355; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0347; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0337; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0338; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0327; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0313; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0297; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0295; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0289; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0283; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.511589   0.372715   0.692053   0.430830  
Loss: 0.0325
Fold 3 Epoch 051; Train loss: 0.0281; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0267; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0257; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0251; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0251; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0245; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0228; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0229; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0216; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0210; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.642384   0.474393   0.802980   0.526269  
Loss: 0.0238
Fold 3 Epoch 061; Train loss: 0.0212; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0206; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0198; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0188; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0181; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0176; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0174; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0170; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0156; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.677152   0.484612   0.832781   0.534680  
Loss: 0.0150
Fold 3 Epoch 071; Train loss: 0.0155; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0148; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0146; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0148; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0136; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0128; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0133; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0121; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0116; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.653974   0.451645   0.855960   0.516901  
Loss: 0.0109
Fold 3 Epoch 081; Train loss: 0.0112; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0108; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0104; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0098; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0095; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0092; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0092; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0087; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0086; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0082; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.645695   0.444242   0.827815   0.503155  
Loss: 0.0073
Fold 3 Epoch 091; Train loss: 0.0081; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0076; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0071; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0068; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0063; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0063; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0060; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0056; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0055; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0053; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.501656   0.313783   0.687086   0.372435  
Loss: 0.0056
[optimizer candidate nadam] Fold 3: HR@10 = [np.float64(0.6870860927152318), np.float64(0.6241721854304636), np.float64(0.7384105960264901), np.float64(0.6440397350993378), np.float64(0.6920529801324503), np.float64(0.8029801324503312), np.float64(0.8327814569536424), np.float64(0.8559602649006622), np.float64(0.8278145695364238), np.float64(0.6870860927152318)]
Tuning optimizer:  25%|██▌       | 1/4 [01:28<04:26, 88.69s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.9766; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.7170; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.5687; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.4653; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.3760; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.3067; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.2511; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.2050; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.1738; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.1485; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.548013   0.442876   0.716887   0.497923  
Loss: 0.2282
Fold 3 Epoch 011; Train loss: 0.1275; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.1134; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.1012; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0935; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0837; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0780; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0727; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0693; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0644; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0645; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.617550   0.478693   0.769868   0.528192  
Loss: 0.0829
Fold 3 Epoch 021; Train loss: 0.0605; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0595; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0565; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0550; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0533; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0519; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0496; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0495; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0471; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0463; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.538079   0.420003   0.692053   0.468981  
Loss: 0.0616
Fold 3 Epoch 031; Train loss: 0.0447; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0426; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0430; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0417; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0402; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0390; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0390; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0365; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0362; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0356; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.612583   0.456559   0.759934   0.503832  
Loss: 0.0448
Fold 3 Epoch 041; Train loss: 0.0341; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0339; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0328; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0310; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0299; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0295; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0284; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0289; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0269; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0265; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.594371   0.443666   0.710265   0.481070  
Loss: 0.0325
Fold 3 Epoch 051; Train loss: 0.0258; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0255; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0245; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0235; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0226; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0222; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0212; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0199; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0198; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0189; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.493377   0.353710   0.632450   0.398298  
Loss: 0.0237
Fold 3 Epoch 061; Train loss: 0.0188; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0166; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0163; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0159; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0152; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0131; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0126; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0118; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0105; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.582781   0.320484   0.771523   0.381806  
Loss: 0.0102
Fold 3 Epoch 071; Train loss: 0.0101; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0095; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0080; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0073; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0066; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0062; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0055; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0048; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0046; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0044; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.508278   0.263746   0.822848   0.363371  
Loss: 0.0036
Fold 3 Epoch 081; Train loss: 0.0037; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0032; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0026; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0019; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0015; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0009; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0007; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0006; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0004; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.339404   0.158396   0.675497   0.257363  
Loss: 0.0005
Fold 3 Epoch 091; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.321192   0.174605   0.403974   0.200377  
Loss: 0.0001
[optimizer candidate lamb] Fold 3: HR@10 = [np.float64(0.7168874172185431), np.float64(0.7698675496688742), np.float64(0.6920529801324503), np.float64(0.7599337748344371), np.float64(0.7102649006622517), np.float64(0.6324503311258278), np.float64(0.7715231788079471), np.float64(0.8228476821192053), np.float64(0.6754966887417219), np.float64(0.40397350993377484)]
Tuning optimizer:  50%|█████     | 2/4 [02:58<02:58, 89.26s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.5271; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2108; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1440; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1131; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.0945; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0828; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0771; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0720; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0723; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0666; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.486755   0.368656   0.649007   0.420442  
Loss: 0.0935
Fold 3 Epoch 011; Train loss: 0.0660; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0639; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0623; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0622; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0603; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0613; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0604; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0571; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0578; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0569; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.503311   0.393270   0.640728   0.436771  
Loss: 0.0740
Fold 3 Epoch 021; Train loss: 0.0562; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0556; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0549; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0541; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0529; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0535; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0501; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0494; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0503; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0481; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.430464   0.323114   0.567881   0.366524  
Loss: 0.0608
Fold 3 Epoch 031; Train loss: 0.0472; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0464; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0457; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0455; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0437; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0437; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0428; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0409; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0417; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0409; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.432119   0.341927   0.579470   0.389548  
Loss: 0.0549
Fold 3 Epoch 041; Train loss: 0.0393; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0395; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0375; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0384; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0365; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0357; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0360; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0336; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0334; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0327; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.475166   0.376820   0.645695   0.431085  
Loss: 0.0422
Fold 3 Epoch 051; Train loss: 0.0324; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0314; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0315; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0297; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0286; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0277; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0277; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0263; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0257; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0249; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.427152   0.324851   0.591060   0.377639  
Loss: 0.0360
Fold 3 Epoch 061; Train loss: 0.0237; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0233; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0231; Time: 00:00:01
Fold 3 Epoch 064; Train loss: 0.0226; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0217; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0222; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0204; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0202; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0201; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0189; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.480132   0.383090   0.600993   0.421703  
Loss: 0.0254
Fold 3 Epoch 071; Train loss: 0.0189; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0186; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0180; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0174; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0176; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0157; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0150; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0147; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0147; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.624172   0.491174   0.748344   0.531350  
Loss: 0.0171
Fold 3 Epoch 081; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0137; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0129; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0123; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0117; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0116; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0112; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0103; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0097; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0095; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.632450   0.462538   0.738411   0.496175  
Loss: 0.0132
Fold 3 Epoch 091; Train loss: 0.0090; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0088; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0081; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0078; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0074; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0072; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0069; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0067; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0060; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0057; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.614238   0.442998   0.690397   0.466242  
Loss: 0.0098
[optimizer candidate adamw] Fold 3: HR@10 = [np.float64(0.6490066225165563), np.float64(0.640728476821192), np.float64(0.5678807947019867), np.float64(0.5794701986754967), np.float64(0.6456953642384106), np.float64(0.5910596026490066), np.float64(0.6009933774834437), np.float64(0.7483443708609272), np.float64(0.7384105960264901), np.float64(0.6903973509933775)]
Tuning optimizer:  75%|███████▌  | 3/4 [04:27<01:29, 89.28s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Fold 3 Epoch 001; Train loss: 1.0926; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 1.0661; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 1.0540; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 1.0335; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 1.0160; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.9947; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.9706; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.9477; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.9232; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.9008; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.327815   0.185820   0.745033   0.316494  
Loss: 1.0491
Fold 3 Epoch 011; Train loss: 0.8765; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.8455; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.8267; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.7998; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.7770; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.7507; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.7321; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.7061; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.6879; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.6633; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.385762   0.279128   0.764901   0.398342  
Loss: 0.9019
Fold 3 Epoch 021; Train loss: 0.6479; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.6307; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.6116; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.5938; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.5761; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.5620; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.5482; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.5313; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.5183; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.5070; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.478477   0.320430   0.763245   0.413492  
Loss: 0.7879
Fold 3 Epoch 031; Train loss: 0.4954; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.4817; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.4720; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.4568; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.4454; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.4389; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.4338; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.4218; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.4157; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.4062; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.521523   0.340471   0.776490   0.423526  
Loss: 0.6941
Fold 3 Epoch 041; Train loss: 0.3925; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.3952; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.3820; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.3767; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.3688; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.3599; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.3602; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.3517; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.3473; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.3336; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.546358   0.366127   0.773179   0.441134  
Loss: 0.6144
Fold 3 Epoch 051; Train loss: 0.3341; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.3235; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.3252; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.3213; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.3138; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.3117; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.3086; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.3008; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.2977; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.2960; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.577815   0.393451   0.764901   0.453424  
Loss: 0.5398
Fold 3 Epoch 061; Train loss: 0.2899; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.2896; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.2812; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.2807; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.2763; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.2732; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.2714; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.2673; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.2636; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.2585; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.584437   0.411659   0.746689   0.462756  
Loss: 0.4779
Fold 3 Epoch 071; Train loss: 0.2580; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.2561; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.2558; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.2494; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.2479; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.2465; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.2435; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.2407; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.2392; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.2379; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.576159   0.415641   0.743377   0.468503  
Loss: 0.4335
Fold 3 Epoch 081; Train loss: 0.2332; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.2303; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.2316; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.2254; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.2238; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.2240; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.2202; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.2173; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.2180; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.2153; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.564570   0.415926   0.700331   0.459526  
Loss: 0.3962
Fold 3 Epoch 091; Train loss: 0.2122; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.2118; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.2125; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.2079; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.2062; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.2079; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.2083; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.2031; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.1997; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.2021; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.572848   0.425129   0.721854   0.472461  
Loss: 0.3490
[optimizer candidate adabelief] Fold 3: HR@10 = [np.float64(0.7450331125827815), np.float64(0.7649006622516556), np.float64(0.7632450331125827), np.float64(0.7764900662251656), np.float64(0.7731788079470199), np.float64(0.7649006622516556), np.float64(0.7466887417218543), np.float64(0.7433774834437086), np.float64(0.7003311258278145), np.float64(0.7218543046357616)]
Tuning optimizer: 100%|██████████| 4/4 [05:56<00:00, 89.23s/it]Tuning optimizer: 100%|██████████| 4/4 [05:56<00:00, 89.20s/it]

Best optimizer found: adabelief
Tuning timesteps:   0%|          | 0/5 [00:00<?, ?it/s]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Fold 3 Epoch 001; Train loss: 1.2727; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 1.2340; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 1.2158; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 1.1903; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 1.1624; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 1.1303; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 1.0943; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 1.0561; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 1.0231; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.9851; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.357616   0.189964   0.678808   0.292610  
Loss: 1.0983
Fold 3 Epoch 011; Train loss: 0.9483; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.9136; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.8770; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.8502; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.8139; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.7894; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.7551; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.7283; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.7033; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.6806; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.394040   0.215289   0.736755   0.323812  
Loss: 0.9118
Fold 3 Epoch 021; Train loss: 0.6586; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.6366; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.6135; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.5967; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.5785; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.5590; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.5451; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.5285; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.5147; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.5006; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.403974   0.221310   0.735099   0.327492  
Loss: 0.7793
Fold 3 Epoch 031; Train loss: 0.4869; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.4739; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.4649; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.4493; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.4437; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.4307; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.4249; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.4130; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.4075; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.4009; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.382450   0.215415   0.759934   0.338135  
Loss: 0.6837
Fold 3 Epoch 041; Train loss: 0.3912; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.3835; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.3702; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.3724; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.3642; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.3569; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.3490; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.3463; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.3410; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.3366; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.397351   0.259347   0.746689   0.375026  
Loss: 0.5990
Fold 3 Epoch 051; Train loss: 0.3274; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.3218; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.3179; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.3117; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.3059; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.3094; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.2990; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.2992; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.2921; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.2879; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.417219   0.276369   0.740066   0.381758  
Loss: 0.5359
Fold 3 Epoch 061; Train loss: 0.2886; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.2811; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.2777; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.2818; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.2699; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.2682; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.2677; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.2673; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.2618; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.2579; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.432119   0.288290   0.740066   0.388534  
Loss: 0.4734
Fold 3 Epoch 071; Train loss: 0.2582; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.2583; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.2505; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.2471; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.2498; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.2448; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.2449; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.2383; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.2357; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.2363; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.410596   0.279966   0.708609   0.375840  
Loss: 0.4273
Fold 3 Epoch 081; Train loss: 0.2337; Time: 00:00:01
Fold 3 Epoch 082; Train loss: 0.2314; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.2264; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.2259; Time: 00:00:01
Fold 3 Epoch 085; Train loss: 0.2226; Time: 00:00:01
Fold 3 Epoch 086; Train loss: 0.2222; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.2181; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.2201; Time: 00:00:01
Fold 3 Epoch 089; Train loss: 0.2193; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.2177; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.402318   0.282795   0.718543   0.384150  
Loss: 0.3718
Fold 3 Epoch 091; Train loss: 0.2169; Time: 00:00:01
Fold 3 Epoch 092; Train loss: 0.2136; Time: 00:00:01
Fold 3 Epoch 093; Train loss: 0.2139; Time: 00:00:01
Fold 3 Epoch 094; Train loss: 0.2082; Time: 00:00:01
Fold 3 Epoch 095; Train loss: 0.2105; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.2072; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.2053; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.2025; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.2043; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.1987; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.408940   0.286203   0.711921   0.383381  
Loss: 0.3461
[timesteps candidate 100] Fold 3: HR@10 = [np.float64(0.6788079470198676), np.float64(0.7367549668874173), np.float64(0.7350993377483444), np.float64(0.7599337748344371), np.float64(0.7466887417218543), np.float64(0.7400662251655629), np.float64(0.7400662251655629), np.float64(0.7086092715231788), np.float64(0.7185430463576159), np.float64(0.7119205298013245)]
Tuning timesteps:  20%|██        | 1/5 [01:31<06:06, 91.58s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Fold 3 Epoch 001; Train loss: 1.1642; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 1.1344; Time: 00:00:01
Tuning timesteps:  20%|██        | 1/5 [01:34<06:17, 94.43s/it]
Traceback (most recent call last):
  File "/home/amir/Desktop/2PDreamRec/DreamRec_Gen.py", line 527, in <module>
    main()
  File "/home/amir/Desktop/2PDreamRec/DreamRec_Gen.py", line 399, in main
    fm = train_fold(tuning_fold)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/DreamRec_Gen.py", line 190, in train_fold
    loss.backward()
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/_tensor.py", line 626, in backward
    torch.autograd.backward(
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/autograd/graph.py", line 823, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Tuning lr:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 53.3455; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.7644; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.3038; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.2507; Time: 00:00:01
Fold 3 Epoch 005; Train loss: 0.2123; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.1857; Time: 00:00:01
Fold 3 Epoch 007; Train loss: 0.1585; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.1412; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.1224; Time: 00:00:01
Fold 3 Epoch 010; Train loss: 0.1111; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.362583   0.262551   0.683775   0.364848  
Loss: 0.1200
Fold 3 Epoch 011; Train loss: 0.0993; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0912; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0837; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0801; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0739; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0702; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0667; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0631; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0607; Time: 00:00:01
Fold 3 Epoch 020; Train loss: 0.0610; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.399007   0.289719   0.632450   0.365714  
Loss: 0.0725
Fold 3 Epoch 021; Train loss: 0.0586; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0628; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0570; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0518; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0510; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0490; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0468; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0460; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0447; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.314570   0.196349   0.528146   0.263919  
Loss: 0.0585
Fold 3 Epoch 031; Train loss: 0.0451; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0454; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0477; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0516; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0475; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0432; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0423; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0392; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0396; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0396; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.329470   0.223625   0.519868   0.283636  
Loss: 0.0489
Fold 3 Epoch 041; Train loss: 0.0384; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0376; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0365; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0355; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0350; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0359; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0361; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0409; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0466; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0390; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.321192   0.211398   0.407285   0.239382  
Loss: 0.0492
Fold 3 Epoch 051; Train loss: 0.0339; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0323; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0305; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0294; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0303; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0290; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0285; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0280; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0269; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0266; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.352649   0.303415   0.584437   0.377999  
Loss: 0.0363
Fold 3 Epoch 061; Train loss: 0.0276; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0253; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0263; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0249; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0254; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0257; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0285; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0276; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0271; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0255; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.354305   0.245958   0.549669   0.307818  
Loss: 0.0248
Fold 3 Epoch 071; Train loss: 0.0229; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0220; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0220; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0213; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0208; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0207; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0197; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0203; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0194; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0198; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.360927   0.271893   0.529801   0.326331  
Loss: 0.0224
Fold 3 Epoch 081; Train loss: 0.0193; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0186; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0183; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0185; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0185; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0195; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0242; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0238; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0191; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0177; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.296358   0.228858   0.438742   0.274540  
Loss: 0.0168
Fold 3 Epoch 091; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0165; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0167; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0162; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0148; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0151; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0154; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0153; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0148; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.599338   0.422317   0.690397   0.451522  
Loss: 0.0195
[lr candidate 0.05] Fold 3: HR@10 = [np.float64(0.6837748344370861), np.float64(0.6324503311258278), np.float64(0.5281456953642384), np.float64(0.5198675496688742), np.float64(0.40728476821192056), np.float64(0.5844370860927153), np.float64(0.5496688741721855), np.float64(0.5298013245033113), np.float64(0.43874172185430466), np.float64(0.6903973509933775)]
Tuning lr:  25%|██▌       | 1/4 [01:31<04:35, 91.84s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.6668; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2270; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1519; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1159; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.1009; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0946; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0906; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0830; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0818; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0779; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.614238   0.410479   0.774834   0.462108  
Loss: 0.0991
Fold 3 Epoch 011; Train loss: 0.0769; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0759; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0733; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0716; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0691; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0664; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0685; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0628; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0628; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0632; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.531457   0.351225   0.705298   0.407466  
Loss: 0.0748
Fold 3 Epoch 021; Train loss: 0.0614; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0607; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0592; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0571; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0575; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0559; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0542; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0522; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0534; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0514; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.597682   0.454950   0.710265   0.492063  
Loss: 0.0610
Fold 3 Epoch 031; Train loss: 0.0515; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0494; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0477; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0481; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0457; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0455; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0444; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0433; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0422; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0410; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.445364   0.337134   0.567881   0.376266  
Loss: 0.0510
Fold 3 Epoch 041; Train loss: 0.0395; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0396; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0372; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0366; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0361; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0349; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0341; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0331; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0320; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0311; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.485099   0.360223   0.605960   0.399302  
Loss: 0.0344
Fold 3 Epoch 051; Train loss: 0.0302; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0283; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0276; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0269; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0263; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0249; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0255; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0248; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0238; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0237; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.552980   0.383514   0.673841   0.423018  
Loss: 0.0250
Fold 3 Epoch 061; Train loss: 0.0225; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0219; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0215; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0210; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0197; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0199; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0200; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0202; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0190; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0185; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.513245   0.361303   0.649007   0.405161  
Loss: 0.0189
Fold 3 Epoch 071; Train loss: 0.0184; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0183; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0180; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0184; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0174; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0176; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0170; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0167; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.414351   0.637417   0.450696  
Loss: 0.0156
Fold 3 Epoch 081; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0160; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0161; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0150; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0156; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0152; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0154; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0149; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0139; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.514901   0.351893   0.652318   0.396474  
Loss: 0.0135
Fold 3 Epoch 091; Train loss: 0.0136; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0129; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0127; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0127; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0119; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0115; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0107; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0109; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0098; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.511589   0.317161   0.784768   0.404445  
Loss: 0.0091
[lr candidate 0.01] Fold 3: HR@10 = [np.float64(0.7748344370860927), np.float64(0.7052980132450332), np.float64(0.7102649006622517), np.float64(0.5678807947019867), np.float64(0.6059602649006622), np.float64(0.6738410596026491), np.float64(0.6490066225165563), np.float64(0.6374172185430463), np.float64(0.652317880794702), np.float64(0.7847682119205298)]
Tuning lr:  50%|█████     | 2/4 [03:00<03:00, 90.04s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.7855; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.3544; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.2256; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1655; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.1315; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.1126; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.1026; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0977; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0942; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0886; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.649007   0.490190   0.763245   0.526907  
Loss: 0.1221
Fold 3 Epoch 011; Train loss: 0.0854; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0822; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0809; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0790; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0782; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0742; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0741; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0728; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0725; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0710; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.493377   0.372464   0.644040   0.420438  
Loss: 0.0962
Fold 3 Epoch 021; Train loss: 0.0690; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0683; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0682; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0674; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0666; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0654; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0634; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0636; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0623; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.591060   0.467486   0.756623   0.520962  
Loss: 0.0812
Fold 3 Epoch 031; Train loss: 0.0616; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0608; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0621; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0622; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0593; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0593; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0588; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0583; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0567; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0573; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.607616   0.463659   0.768212   0.516083  
Loss: 0.0721
Fold 3 Epoch 041; Train loss: 0.0566; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0563; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0577; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0549; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0544; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0537; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0532; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0519; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0521; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0510; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.619205   0.484605   0.774834   0.535020  
Loss: 0.0648
Fold 3 Epoch 051; Train loss: 0.0517; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0509; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0492; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0491; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0490; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0479; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0475; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0467; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0464; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0448; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.526490   0.421897   0.653974   0.462845  
Loss: 0.0533
Fold 3 Epoch 061; Train loss: 0.0466; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0451; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0446; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0451; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0438; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0433; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0426; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0422; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0418; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0405; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.544702   0.368859   0.693709   0.417584  
Loss: 0.0531
Fold 3 Epoch 071; Train loss: 0.0418; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0401; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0408; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0394; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0387; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0380; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0375; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0372; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0367; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0352; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.476821   0.355594   0.619205   0.402035  
Loss: 0.0464
Fold 3 Epoch 081; Train loss: 0.0351; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0345; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0344; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0340; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0348; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0335; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0330; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0318; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0320; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0313; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.634106   0.482442   0.758278   0.522657  
Loss: 0.0391
Fold 3 Epoch 091; Train loss: 0.0313; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0311; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0316; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0306; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0307; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0291; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0294; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0284; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0289; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0282; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.584437   0.439848   0.745033   0.491606  
Loss: 0.0352
[lr candidate 0.005] Fold 3: HR@10 = [np.float64(0.7632450331125827), np.float64(0.6440397350993378), np.float64(0.7566225165562914), np.float64(0.7682119205298014), np.float64(0.7748344370860927), np.float64(0.6539735099337748), np.float64(0.6937086092715232), np.float64(0.6192052980132451), np.float64(0.7582781456953642), np.float64(0.7450331125827815)]
Tuning lr:  75%|███████▌  | 3/4 [04:29<01:29, 89.49s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 1.0811; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.7940; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.6209; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.5226; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.4421; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.3818; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.3359; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.2949; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.2653; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.2401; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.758278   0.596220   0.834437   0.620963  
Loss: 0.3897
Fold 3 Epoch 011; Train loss: 0.2223; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.2018; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.1889; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.1763; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.1652; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.1552; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.1485; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.1439; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.1377; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.1314; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.726821   0.580559   0.816225   0.609545  
Loss: 0.2140
Fold 3 Epoch 021; Train loss: 0.1287; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.1236; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.1220; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.1167; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.1140; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.1105; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.1091; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.1075; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.1053; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.1047; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.703642   0.565010   0.794702   0.594127  
Loss: 0.1602
Fold 3 Epoch 031; Train loss: 0.1002; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.1009; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0990; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0976; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0972; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0967; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0956; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0933; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0941; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0905; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.701987   0.570176   0.786424   0.597349  
Loss: 0.1345
Fold 3 Epoch 041; Train loss: 0.0905; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0878; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0891; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0891; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0877; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0848; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0857; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0836; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0829; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0830; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.751656   0.596690   0.826159   0.620601  
Loss: 0.1237
Fold 3 Epoch 051; Train loss: 0.0833; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0832; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0829; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0812; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0821; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0809; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0803; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0794; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0801; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0793; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.678808   0.534506   0.771523   0.564359  
Loss: 0.1133
Fold 3 Epoch 061; Train loss: 0.0774; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0772; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0784; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0789; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0772; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0757; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0762; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0754; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0748; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0762; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.612583   0.463471   0.758278   0.510216  
Loss: 0.1094
Fold 3 Epoch 071; Train loss: 0.0746; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0749; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0753; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0761; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0742; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0736; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0732; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0718; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0748; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0732; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.733444   0.579628   0.819536   0.607186  
Loss: 0.1002
Fold 3 Epoch 081; Train loss: 0.0735; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0719; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0711; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0717; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0717; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0701; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0709; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0716; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0717; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0705; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.708609   0.557797   0.786424   0.582583  
Loss: 0.0932
Fold 3 Epoch 091; Train loss: 0.0707; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0688; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0704; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0712; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0671; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0688; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0688; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0680; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0697; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0679; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.682119   0.530064   0.766556   0.557627  
Loss: 0.0962
[lr candidate 0.001] Fold 3: HR@10 = [np.float64(0.8344370860927153), np.float64(0.8162251655629139), np.float64(0.7947019867549668), np.float64(0.7864238410596026), np.float64(0.8261589403973509), np.float64(0.7715231788079471), np.float64(0.7582781456953642), np.float64(0.8195364238410596), np.float64(0.7864238410596026), np.float64(0.7665562913907285)]
Tuning lr: 100%|██████████| 4/4 [05:58<00:00, 89.39s/it]Tuning lr: 100%|██████████| 4/4 [05:58<00:00, 89.67s/it]

Best learning rate found: 0.01
Tuning data for lr saved to ./category/tuning_lr.json
Tuning optimizer:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.6039; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2145; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1402; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1123; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.0995; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0917; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0810; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0786; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0750; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0723; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.501656   0.389069   0.687086   0.448412  
Loss: 0.0933
Fold 3 Epoch 011; Train loss: 0.0692; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0701; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0678; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0663; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0634; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0634; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0608; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0612; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0575; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.473510   0.336624   0.624172   0.385027  
Loss: 0.0681
Fold 3 Epoch 021; Train loss: 0.0568; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0561; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0556; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0527; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0535; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0519; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0508; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0493; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0485; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0478; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.604305   0.463912   0.738411   0.507082  
Loss: 0.0562
Fold 3 Epoch 031; Train loss: 0.0467; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0457; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0447; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0426; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0419; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0408; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0398; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0397; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0387; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0365; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.466887   0.321537   0.644040   0.378019  
Loss: 0.0409
Fold 3 Epoch 041; Train loss: 0.0355; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0347; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0337; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0338; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0327; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0313; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0297; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0295; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0289; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0283; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.511589   0.372715   0.692053   0.430830  
Loss: 0.0325
Fold 3 Epoch 051; Train loss: 0.0281; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0267; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0257; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0251; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0251; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0245; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0228; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0229; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0216; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0210; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.642384   0.474393   0.802980   0.526269  
Loss: 0.0238
Fold 3 Epoch 061; Train loss: 0.0212; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0206; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0198; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0188; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0181; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0176; Time: 00:00:01
Fold 3 Epoch 067; Train loss: 0.0174; Time: 00:00:01
Fold 3 Epoch 068; Train loss: 0.0171; Time: 00:00:01
Fold 3 Epoch 069; Train loss: 0.0170; Time: 00:00:01
Fold 3 Epoch 070; Train loss: 0.0156; Time: 00:00:01
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.677152   0.484612   0.832781   0.534680  
Loss: 0.0150
Fold 3 Epoch 071; Train loss: 0.0155; Time: 00:00:01
Fold 3 Epoch 072; Train loss: 0.0148; Time: 00:00:01
Fold 3 Epoch 073; Train loss: 0.0146; Time: 00:00:01
Fold 3 Epoch 074; Train loss: 0.0148; Time: 00:00:01
Fold 3 Epoch 075; Train loss: 0.0139; Time: 00:00:01
Fold 3 Epoch 076; Train loss: 0.0136; Time: 00:00:01
Fold 3 Epoch 077; Train loss: 0.0128; Time: 00:00:01
Fold 3 Epoch 078; Train loss: 0.0133; Time: 00:00:01
Fold 3 Epoch 079; Train loss: 0.0121; Time: 00:00:01
Fold 3 Epoch 080; Train loss: 0.0116; Time: 00:00:01
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.653974   0.451645   0.855960   0.516901  
Loss: 0.0109
Fold 3 Epoch 081; Train loss: 0.0112; Time: 00:00:01
Fold 3 Epoch 082; Train loss: 0.0108; Time: 00:00:01
Fold 3 Epoch 083; Train loss: 0.0104; Time: 00:00:01
Fold 3 Epoch 084; Train loss: 0.0098; Time: 00:00:01
Fold 3 Epoch 085; Train loss: 0.0095; Time: 00:00:01
Fold 3 Epoch 086; Train loss: 0.0092; Time: 00:00:01
Fold 3 Epoch 087; Train loss: 0.0092; Time: 00:00:01
Fold 3 Epoch 088; Train loss: 0.0087; Time: 00:00:01
Fold 3 Epoch 089; Train loss: 0.0086; Time: 00:00:01
Fold 3 Epoch 090; Train loss: 0.0082; Time: 00:00:01
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.645695   0.444242   0.827815   0.503155  
Loss: 0.0073
Fold 3 Epoch 091; Train loss: 0.0081; Time: 00:00:01
Fold 3 Epoch 092; Train loss: 0.0076; Time: 00:00:01
Fold 3 Epoch 093; Train loss: 0.0071; Time: 00:00:01
Fold 3 Epoch 094; Train loss: 0.0068; Time: 00:00:01
Fold 3 Epoch 095; Train loss: 0.0063; Time: 00:00:01
Fold 3 Epoch 096; Train loss: 0.0063; Time: 00:00:01
Fold 3 Epoch 097; Train loss: 0.0060; Time: 00:00:01
Fold 3 Epoch 098; Train loss: 0.0056; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0055; Time: 00:00:01
Fold 3 Epoch 100; Train loss: 0.0053; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.501656   0.313783   0.687086   0.372435  
Loss: 0.0056
[optimizer candidate nadam] Fold 3: HR@10 = [np.float64(0.6870860927152318), np.float64(0.6241721854304636), np.float64(0.7384105960264901), np.float64(0.6440397350993378), np.float64(0.6920529801324503), np.float64(0.8029801324503312), np.float64(0.8327814569536424), np.float64(0.8559602649006622), np.float64(0.8278145695364238), np.float64(0.6870860927152318)]
Tuning optimizer:  25%|██▌       | 1/4 [01:41<05:03, 101.25s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.9766; Time: 00:00:01
Fold 3 Epoch 002; Train loss: 0.7170; Time: 00:00:01
Fold 3 Epoch 003; Train loss: 0.5687; Time: 00:00:01
Fold 3 Epoch 004; Train loss: 0.4653; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.3760; Time: 00:00:01
Fold 3 Epoch 006; Train loss: 0.3067; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.2511; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.2050; Time: 00:00:01
Fold 3 Epoch 009; Train loss: 0.1738; Time: 00:00:01
Fold 3 Epoch 010; Train loss: 0.1485; Time: 00:00:01
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.548013   0.442876   0.716887   0.497923  
Loss: 0.2282
Fold 3 Epoch 011; Train loss: 0.1275; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.1134; Time: 00:00:01
Fold 3 Epoch 013; Train loss: 0.1012; Time: 00:00:01
Fold 3 Epoch 014; Train loss: 0.0935; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0837; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0780; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0727; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0693; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0644; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0645; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.617550   0.478693   0.769868   0.528192  
Loss: 0.0829
Fold 3 Epoch 021; Train loss: 0.0605; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0595; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0565; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0550; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0533; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0519; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0496; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0495; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0471; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0463; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.538079   0.420003   0.692053   0.468981  
Loss: 0.0616
Fold 3 Epoch 031; Train loss: 0.0447; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0426; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0430; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0417; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0402; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0390; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0390; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0365; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0362; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0356; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.612583   0.456559   0.759934   0.503832  
Loss: 0.0448
Fold 3 Epoch 041; Train loss: 0.0341; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0339; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0328; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0310; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0299; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0295; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0284; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0289; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0269; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0265; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.594371   0.443666   0.710265   0.481070  
Loss: 0.0325
Fold 3 Epoch 051; Train loss: 0.0258; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0255; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0245; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0235; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0226; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0222; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0212; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0199; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0198; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0189; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.493377   0.353710   0.632450   0.398298  
Loss: 0.0237
Fold 3 Epoch 061; Train loss: 0.0188; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0166; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0163; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0159; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0152; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0131; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0126; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0118; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0105; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.582781   0.320484   0.771523   0.381806  
Loss: 0.0102
Fold 3 Epoch 071; Train loss: 0.0101; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0095; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0080; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0073; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0066; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0062; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0055; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0048; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0046; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0044; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.508278   0.263746   0.822848   0.363371  
Loss: 0.0036
Fold 3 Epoch 081; Train loss: 0.0037; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0032; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0026; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0019; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0015; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0009; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0007; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0006; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0004; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.339404   0.158396   0.675497   0.257363  
Loss: 0.0005
Fold 3 Epoch 091; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.321192   0.174605   0.403974   0.200377  
Loss: 0.0001
[optimizer candidate lamb] Fold 3: HR@10 = [np.float64(0.7168874172185431), np.float64(0.7698675496688742), np.float64(0.6920529801324503), np.float64(0.7599337748344371), np.float64(0.7102649006622517), np.float64(0.6324503311258278), np.float64(0.7715231788079471), np.float64(0.8228476821192053), np.float64(0.6754966887417219), np.float64(0.40397350993377484)]
Tuning optimizer:  50%|█████     | 2/4 [03:13<03:11, 95.99s/it] 
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.5271; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2108; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1440; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1131; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.0945; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0828; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0771; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0720; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0723; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0666; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.486755   0.368656   0.649007   0.420442  
Loss: 0.0935
Fold 3 Epoch 011; Train loss: 0.0660; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0639; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0623; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0622; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0603; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0613; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0604; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0571; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0578; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0569; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.503311   0.393270   0.640728   0.436771  
Loss: 0.0740
Fold 3 Epoch 021; Train loss: 0.0562; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0556; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0549; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0541; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0529; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0535; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0501; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0494; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0503; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0481; Time: 00:00:01
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.430464   0.323114   0.567881   0.366524  
Loss: 0.0608
Fold 3 Epoch 031; Train loss: 0.0472; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0464; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0457; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0455; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0437; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0437; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0428; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0409; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0417; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0409; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.432119   0.341927   0.579470   0.389548  
Loss: 0.0549
Fold 3 Epoch 041; Train loss: 0.0393; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0395; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0375; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0384; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0365; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0357; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0360; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0336; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0334; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0327; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.475166   0.376820   0.645695   0.431085  
Loss: 0.0422
Fold 3 Epoch 051; Train loss: 0.0324; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0314; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0315; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0297; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0286; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0277; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0277; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0263; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0257; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0249; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.427152   0.324851   0.591060   0.377639  
Loss: 0.0360
Fold 3 Epoch 061; Train loss: 0.0237; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0233; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0231; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0226; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0217; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0222; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0204; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0202; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0201; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0189; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.480132   0.383090   0.600993   0.421703  
Loss: 0.0254
Fold 3 Epoch 071; Train loss: 0.0189; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0186; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0180; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0174; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0176; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0157; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0150; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0147; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0147; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.624172   0.491174   0.748344   0.531350  
Loss: 0.0171
Fold 3 Epoch 081; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0137; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0129; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0123; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0117; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0116; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0112; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0103; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0097; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0095; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.632450   0.462538   0.738411   0.496175  
Loss: 0.0132
Fold 3 Epoch 091; Train loss: 0.0090; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0088; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0081; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0078; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0074; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0072; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0069; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0067; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0060; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0057; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.614238   0.442998   0.690397   0.466242  
Loss: 0.0098
[optimizer candidate adamw] Fold 3: HR@10 = [np.float64(0.6490066225165563), np.float64(0.640728476821192), np.float64(0.5678807947019867), np.float64(0.5794701986754967), np.float64(0.6456953642384106), np.float64(0.5910596026490066), np.float64(0.6009933774834437), np.float64(0.7483443708609272), np.float64(0.7384105960264901), np.float64(0.6903973509933775)]
Tuning optimizer:  75%|███████▌  | 3/4 [04:42<01:32, 92.93s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Fold 3 Epoch 001; Train loss: 1.0926; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 1.0661; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 1.0540; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 1.0335; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 1.0160; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.9947; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.9706; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.9477; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.9232; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.9008; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.327815   0.185820   0.745033   0.316494  
Loss: 1.0491
Fold 3 Epoch 011; Train loss: 0.8765; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.8455; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.8267; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.7998; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.7770; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.7507; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.7321; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.7061; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.6879; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.6633; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.385762   0.279128   0.764901   0.398342  
Loss: 0.9019
Fold 3 Epoch 021; Train loss: 0.6479; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.6307; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.6116; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.5938; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.5761; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.5620; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.5482; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.5313; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.5183; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.5070; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.478477   0.320430   0.763245   0.413492  
Loss: 0.7879
Fold 3 Epoch 031; Train loss: 0.4954; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.4817; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.4720; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.4568; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.4454; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.4389; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.4338; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.4218; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.4157; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.4062; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.521523   0.340471   0.776490   0.423526  
Loss: 0.6941
Fold 3 Epoch 041; Train loss: 0.3925; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.3952; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.3820; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.3767; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.3688; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.3599; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.3602; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.3517; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.3473; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.3336; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.546358   0.366127   0.773179   0.441134  
Loss: 0.6144
Fold 3 Epoch 051; Train loss: 0.3341; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.3235; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.3252; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.3213; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.3138; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.3117; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.3086; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.3008; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.2977; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.2960; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.577815   0.393451   0.764901   0.453424  
Loss: 0.5398
Fold 3 Epoch 061; Train loss: 0.2899; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.2896; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.2812; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.2807; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.2763; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.2732; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.2714; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.2673; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.2636; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.2585; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.584437   0.411659   0.746689   0.462756  
Loss: 0.4779
Fold 3 Epoch 071; Train loss: 0.2580; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.2561; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.2558; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.2494; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.2479; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.2465; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.2435; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.2407; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.2392; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.2379; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.576159   0.415641   0.743377   0.468503  
Loss: 0.4335
Fold 3 Epoch 081; Train loss: 0.2332; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.2303; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.2316; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.2254; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.2238; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.2240; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.2202; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.2173; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.2180; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.2153; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.564570   0.415926   0.700331   0.459526  
Loss: 0.3962
Fold 3 Epoch 091; Train loss: 0.2122; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.2118; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.2125; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.2079; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.2062; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.2079; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.2083; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.2031; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.1997; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.2021; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.572848   0.425129   0.721854   0.472461  
Loss: 0.3490
[optimizer candidate adabelief] Fold 3: HR@10 = [np.float64(0.7450331125827815), np.float64(0.7649006622516556), np.float64(0.7632450331125827), np.float64(0.7764900662251656), np.float64(0.7731788079470199), np.float64(0.7649006622516556), np.float64(0.7466887417218543), np.float64(0.7433774834437086), np.float64(0.7003311258278145), np.float64(0.7218543046357616)]
Tuning optimizer: 100%|██████████| 4/4 [06:12<00:00, 91.49s/it]Tuning optimizer: 100%|██████████| 4/4 [06:12<00:00, 93.03s/it]

Best optimizer found: adabelief
Tuning data for optimizer saved to ./category/tuning_optimizer.json
Tuning timesteps:   0%|          | 0/5 [00:00<?, ?it/s]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Fold 3 Epoch 001; Train loss: 1.2727; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 1.2340; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 1.2158; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 1.1903; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 1.1624; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 1.1303; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 1.0943; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 1.0561; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 1.0231; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.9851; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.357616   0.189964   0.678808   0.292610  
Loss: 1.0983
Fold 3 Epoch 011; Train loss: 0.9483; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.9136; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.8770; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.8502; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.8139; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.7894; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.7551; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.7283; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.7033; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.6806; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.394040   0.215289   0.736755   0.323812  
Loss: 0.9118
Fold 3 Epoch 021; Train loss: 0.6586; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.6366; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.6135; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.5967; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.5785; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.5590; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.5451; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.5285; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.5147; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.5006; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.403974   0.221310   0.735099   0.327492  
Loss: 0.7793
Fold 3 Epoch 031; Train loss: 0.4869; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.4739; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.4649; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.4493; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.4437; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.4307; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.4249; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.4130; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.4075; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.4009; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.382450   0.215415   0.759934   0.338135  
Loss: 0.6837
Fold 3 Epoch 041; Train loss: 0.3912; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.3835; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.3702; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.3724; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.3642; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.3569; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.3490; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.3463; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.3410; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.3366; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.397351   0.259347   0.746689   0.375026  
Loss: 0.5990
Fold 3 Epoch 051; Train loss: 0.3274; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.3218; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.3179; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.3117; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.3059; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.3094; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.2990; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.2992; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.2921; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.2879; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.417219   0.276369   0.740066   0.381758  
Loss: 0.5359
Fold 3 Epoch 061; Train loss: 0.2886; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.2811; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.2777; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.2818; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.2699; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.2682; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.2677; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.2673; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.2618; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.2579; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.432119   0.288290   0.740066   0.388534  
Loss: 0.4734
Fold 3 Epoch 071; Train loss: 0.2582; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.2583; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.2505; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.2471; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.2498; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.2448; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.2449; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.2383; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.2357; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.2363; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.410596   0.279966   0.708609   0.375840  
Loss: 0.4273
Fold 3 Epoch 081; Train loss: 0.2337; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.2314; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.2264; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.2259; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.2226; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.2222; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.2181; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.2201; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.2193; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.2177; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.402318   0.282795   0.718543   0.384150  
Loss: 0.3718
Fold 3 Epoch 091; Train loss: 0.2169; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.2136; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.2139; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.2082; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.2105; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.2072; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.2053; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.2025; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.2043; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.1987; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.408940   0.286203   0.711921   0.383381  
Loss: 0.3461
[timesteps candidate 100] Fold 3: HR@10 = [np.float64(0.6788079470198676), np.float64(0.7367549668874173), np.float64(0.7350993377483444), np.float64(0.7599337748344371), np.float64(0.7466887417218543), np.float64(0.7400662251655629), np.float64(0.7400662251655629), np.float64(0.7086092715231788), np.float64(0.7185430463576159), np.float64(0.7119205298013245)]
Tuning timesteps:  20%|██        | 1/5 [01:29<05:56, 89.22s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Fold 3 Epoch 001; Train loss: 1.1642; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 1.1344; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 1.1239; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 1.1041; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 1.0821; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 1.0606; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 1.0349; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 1.0134; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.9830; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.9560; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.554636   0.296805   0.837748   0.387696  
Loss: 0.9565
Fold 3 Epoch 011; Train loss: 0.9324; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.9063; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.8782; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.8533; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.8321; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.8081; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.7820; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.7658; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.7405; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.7225; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.521523   0.282964   0.837748   0.385906  
Loss: 0.8400
Fold 3 Epoch 021; Train loss: 0.7097; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.6842; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.6675; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.6508; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.6411; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.6218; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.6156; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.5933; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.5836; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.5717; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.427152   0.247478   0.842715   0.386310  
Loss: 0.7591
Fold 3 Epoch 031; Train loss: 0.5611; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.5485; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.5396; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.5251; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.5157; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.5062; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.4971; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.4878; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.4817; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.4704; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.425497   0.250339   0.847682   0.390630  
Loss: 0.6889
Fold 3 Epoch 041; Train loss: 0.4614; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.4539; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.4488; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.4368; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.4357; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.4201; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.4149; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.4136; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.4057; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.4003; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.538079   0.299307   0.850993   0.401822  
Loss: 0.6148
Fold 3 Epoch 051; Train loss: 0.3926; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.3859; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.3844; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.3774; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.3680; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.3658; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.3605; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.3569; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.3509; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.3446; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.615894   0.342957   0.862583   0.423394  
Loss: 0.5550
Fold 3 Epoch 061; Train loss: 0.3427; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.3448; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.3365; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.3348; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.3301; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.3221; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.3234; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.3174; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.3138; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.3079; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.642384   0.367539   0.867550   0.440471  
Loss: 0.5084
Fold 3 Epoch 071; Train loss: 0.3083; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.3035; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.3002; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.2971; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.2966; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.2944; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.2881; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.2841; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.2797; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.2831; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.670530   0.403311   0.857616   0.462812  
Loss: 0.4487
Fold 3 Epoch 081; Train loss: 0.2797; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.2785; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.2775; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.2728; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.2712; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.2699; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.2673; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.2658; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.2599; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.2615; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.655629   0.444556   0.841060   0.503094  
Loss: 0.4258
Fold 3 Epoch 091; Train loss: 0.2589; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.2571; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.2553; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.2505; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.2514; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.2469; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.2493; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.2457; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.2454; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.2426; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.639073   0.449656   0.807947   0.503609  
Loss: 0.3827
[timesteps candidate 150] Fold 3: HR@10 = [np.float64(0.8377483443708609), np.float64(0.8377483443708609), np.float64(0.8427152317880795), np.float64(0.847682119205298), np.float64(0.8509933774834437), np.float64(0.8625827814569537), np.float64(0.8675496688741722), np.float64(0.8576158940397351), np.float64(0.8410596026490066), np.float64(0.8079470198675497)]
Tuning timesteps:  40%|████      | 2/5 [02:58<04:28, 89.55s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Fold 3 Epoch 001; Train loss: 1.1631; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 1.1311; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 1.1177; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 1.0992; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 1.0821; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 1.0533; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 1.0277; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.9994; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.9735; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.9485; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.301325   0.239859   0.495033   0.301240  
Loss: 1.0517
Fold 3 Epoch 011; Train loss: 0.9183; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.8943; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.8674; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.8439; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.8178; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.7964; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.7721; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.7575; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.7356; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.7168; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.347682   0.302869   0.506623   0.353026  
Loss: 0.9106
Fold 3 Epoch 021; Train loss: 0.6944; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.6827; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.6625; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.6482; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.6406; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.6188; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.6079; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.6005; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.5873; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.5736; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.354305   0.315076   0.554636   0.376477  
Loss: 0.8324
Fold 3 Epoch 031; Train loss: 0.5570; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.5516; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.5362; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.5341; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.5219; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.5135; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.5047; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.4960; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.4907; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.4770; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.355960   0.312724   0.637417   0.397916  
Loss: 0.7548
Fold 3 Epoch 041; Train loss: 0.4709; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.4665; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.4598; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.4488; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.4450; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.4408; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.4356; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.4251; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.4242; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.4167; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.349338   0.300697   0.647351   0.394130  
Loss: 0.6995
Fold 3 Epoch 051; Train loss: 0.4131; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.4026; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.3986; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.4009; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.3946; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.3855; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.3801; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.3793; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.3784; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.3704; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.364238   0.298203   0.650662   0.389846  
Loss: 0.6334
Fold 3 Epoch 061; Train loss: 0.3719; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.3648; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.3603; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.3577; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.3536; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.3483; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.3505; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.3449; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.3389; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.3350; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.407285   0.303994   0.680464   0.389146  
Loss: 0.5811
Fold 3 Epoch 071; Train loss: 0.3368; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.3324; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.3343; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.3236; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.3280; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.3191; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.3199; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.3138; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.3124; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.3150; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.410596   0.313239   0.685430   0.398619  
Loss: 0.5325
Fold 3 Epoch 081; Train loss: 0.3140; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.3031; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.2991; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.3068; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.3028; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.3004; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.2956; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.2983; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.2964; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.2892; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.402318   0.300696   0.678808   0.386353  
Loss: 0.4839
Fold 3 Epoch 091; Train loss: 0.2906; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.2854; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.2856; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.2879; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.2818; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.2814; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.2799; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.2820; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.2772; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.2796; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.399007   0.307887   0.665563   0.391395  
Loss: 0.4676
[timesteps candidate 200] Fold 3: HR@10 = [np.float64(0.49503311258278143), np.float64(0.5066225165562914), np.float64(0.554635761589404), np.float64(0.6374172185430463), np.float64(0.6473509933774835), np.float64(0.6506622516556292), np.float64(0.6804635761589404), np.float64(0.6854304635761589), np.float64(0.6788079470198676), np.float64(0.6655629139072847)]
Tuning timesteps:  60%|██████    | 3/5 [04:29<02:59, 89.84s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Fold 3 Epoch 001; Train loss: 1.3972; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 1.3622; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 1.3475; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 1.3206; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 1.2963; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 1.2653; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 1.2293; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 1.1974; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 1.1611; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 1.1321; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.286424   0.142400   0.582781   0.240316  
Loss: 1.0560
Fold 3 Epoch 011; Train loss: 1.0975; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 1.0701; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 1.0283; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.9952; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.9766; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.9432; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.9149; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.8884; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.8629; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.8362; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.427152   0.234643   0.655629   0.307279  
Loss: 0.9327
Fold 3 Epoch 021; Train loss: 0.8068; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.7923; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.7732; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.7528; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.7347; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.7167; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.7012; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.6879; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.6686; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.6520; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.435430   0.244770   0.599338   0.295952  
Loss: 0.8437
Fold 3 Epoch 031; Train loss: 0.6378; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.6191; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.6190; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.5995; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.5969; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.5867; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.5762; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.5715; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.5580; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.5463; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.435430   0.255129   0.577815   0.299992  
Loss: 0.7527
Fold 3 Epoch 041; Train loss: 0.5369; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.5283; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.5218; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.5158; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.5009; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.5031; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.4918; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.4820; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.4767; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.4722; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.445364   0.260706   0.594371   0.308895  
Loss: 0.6838
Fold 3 Epoch 051; Train loss: 0.4684; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.4714; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.4530; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.4505; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.4415; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.4432; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.4430; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.4274; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.4318; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.4281; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.473510   0.301799   0.620861   0.349569  
Loss: 0.6258
Fold 3 Epoch 061; Train loss: 0.4224; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.4228; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.4093; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.4095; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.4125; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.4088; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.3958; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.3995; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.3882; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.3942; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.516556   0.344257   0.660596   0.390231  
Loss: 0.5691
Fold 3 Epoch 071; Train loss: 0.3891; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.3879; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.3931; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.3783; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.3778; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.3780; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.3747; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.3699; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.3721; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.3660; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.557947   0.379125   0.700331   0.424209  
Loss: 0.5254
Fold 3 Epoch 081; Train loss: 0.3633; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.3644; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.3565; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.3572; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.3537; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.3514; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.3497; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.3477; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.3501; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.3472; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.582781   0.402392   0.715232   0.444662  
Loss: 0.4778
Fold 3 Epoch 091; Train loss: 0.3443; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.3461; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.3453; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.3433; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.3416; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.3381; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.3307; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.3330; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.3335; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.3307; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.584437   0.414156   0.710265   0.454506  
Loss: 0.4683
[timesteps candidate 250] Fold 3: HR@10 = [np.float64(0.5827814569536424), np.float64(0.6556291390728477), np.float64(0.5993377483443708), np.float64(0.5778145695364238), np.float64(0.5943708609271523), np.float64(0.6208609271523179), np.float64(0.6605960264900662), np.float64(0.7003311258278145), np.float64(0.7152317880794702), np.float64(0.7102649006622517)]
Tuning timesteps:  80%|████████  | 4/5 [06:00<01:30, 90.36s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Fold 3 Epoch 001; Train loss: 1.2599; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 1.2344; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 1.2234; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 1.2077; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 1.1849; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 1.1659; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 1.1389; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 1.1196; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 1.0935; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 1.0651; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.226821   0.115859   0.493377   0.200961  
Loss: 1.2527
Fold 3 Epoch 011; Train loss: 1.0389; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 1.0132; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.9907; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.9659; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.9375; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.9190; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.8896; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.8686; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.8495; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.8317; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.390728   0.292923   0.645695   0.373407  
Loss: 1.0458
Fold 3 Epoch 021; Train loss: 0.8097; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.7882; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.7739; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.7575; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.7382; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.7257; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.7072; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.6973; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.6802; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.6682; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.486755   0.341980   0.791391   0.436635  
Loss: 0.9081
Fold 3 Epoch 031; Train loss: 0.6575; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.6435; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.6373; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.6220; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.6112; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.6025; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.5916; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.5904; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.5759; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.5692; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.559603   0.382655   0.789735   0.458356  
Loss: 0.8157
Fold 3 Epoch 041; Train loss: 0.5611; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.5540; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.5455; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.5355; Time: 00:00:01
Fold 3 Epoch 045; Train loss: 0.5303; Time: 00:00:01
Fold 3 Epoch 046; Train loss: 0.5322; Time: 00:00:01
Fold 3 Epoch 047; Train loss: 0.5164; Time: 00:00:01
Fold 3 Epoch 048; Train loss: 0.5109; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.5080; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.5013; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.653974   0.425101   0.801325   0.472082  
Loss: 0.7523
Fold 3 Epoch 051; Train loss: 0.4980; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.4846; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.4813; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.4748; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.4768; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.4732; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.4653; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.4647; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.4548; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.4506; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.627483   0.422955   0.791391   0.476209  
Loss: 0.6901
Fold 3 Epoch 061; Train loss: 0.4512; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.4429; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.4386; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.4338; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.4271; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.4274; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.4225; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.4278; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.4184; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.4077; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.624172   0.435291   0.783113   0.486809  
Loss: 0.6335
Fold 3 Epoch 071; Train loss: 0.4053; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.4036; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.4054; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.3996; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.3992; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.3934; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.3891; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.3963; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.3814; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.3863; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.624172   0.435491   0.778146   0.484563  
Loss: 0.6006
Fold 3 Epoch 081; Train loss: 0.3852; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.3836; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.3719; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.3781; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.3764; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.3738; Time: 00:00:01
Fold 3 Epoch 087; Train loss: 0.3672; Time: 00:00:01
Fold 3 Epoch 088; Train loss: 0.3629; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.3618; Time: 00:00:01
Fold 3 Epoch 090; Train loss: 0.3683; Time: 00:00:01
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.624172   0.441800   0.761589   0.485467  
Loss: 0.5409
Fold 3 Epoch 091; Train loss: 0.3652; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.3601; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.3601; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.3554; Time: 00:00:01
Fold 3 Epoch 095; Train loss: 0.3544; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.3526; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.3516; Time: 00:00:01
Fold 3 Epoch 098; Train loss: 0.3518; Time: 00:00:01
Fold 3 Epoch 099; Train loss: 0.3471; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.3513; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.610927   0.443145   0.733444   0.482908  
Loss: 0.5178
[timesteps candidate 300] Fold 3: HR@10 = [np.float64(0.49337748344370863), np.float64(0.6456953642384106), np.float64(0.7913907284768212), np.float64(0.7897350993377483), np.float64(0.8013245033112583), np.float64(0.7913907284768212), np.float64(0.7831125827814569), np.float64(0.7781456953642384), np.float64(0.7615894039735099), np.float64(0.7334437086092715)]
Tuning timesteps: 100%|██████████| 5/5 [07:36<00:00, 92.51s/it]Tuning timesteps: 100%|██████████| 5/5 [07:36<00:00, 91.34s/it]

Best timesteps found: 150
Tuning data for timesteps saved to ./category/tuning_timesteps.json
Tuning data for dropout_rate saved to ./category/tuning_dropout.json
Tuning data for l2_decay saved to ./category/tuning_l2.json
Tuning data for eps saved to ./category/tuning_eps.json

========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Fold 3 Epoch 001; Train loss: 1.3000; Time: 00:00:01
Fold 3 Epoch 002; Train loss: 1.2591; Time: 00:00:01
Fold 3 Epoch 003; Train loss: 1.2395; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 1.2164; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 1.1849; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 1.1549; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 1.1181; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 1.0823; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 1.0507; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 1.0102; Time: 00:00:01
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.390728   0.328767   0.581126   0.389711  
Loss: 0.9714
Fold 3 Epoch 011; Train loss: 0.9770; Time: 00:00:01
Fold 3 Epoch 012; Train loss: 0.9416; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.9086; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.8767; Time: 00:00:01
Fold 3 Epoch 015; Train loss: 0.8483; Time: 00:00:01
Fold 3 Epoch 016; Train loss: 0.8214; Time: 00:00:01
Fold 3 Epoch 017; Train loss: 0.7906; Time: 00:00:01
Fold 3 Epoch 018; Train loss: 0.7610; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.7390; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.7235; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.437086   0.350182   0.605960   0.405259  
Loss: 0.7909
Fold 3 Epoch 021; Train loss: 0.6939; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.6760; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.6557; Time: 00:00:01
Fold 3 Epoch 024; Train loss: 0.6362; Time: 00:00:01
Fold 3 Epoch 025; Train loss: 0.6188; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.6014; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.5912; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.5706; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.5578; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.5451; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.466887   0.363202   0.610927   0.409259  
Loss: 0.6889
Fold 3 Epoch 031; Train loss: 0.5286; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.5241; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.5050; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.4937; Time: 00:00:01
Fold 3 Epoch 035; Train loss: 0.4870; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.4742; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.4657; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.4549; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.4489; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.4360; Time: 00:00:01
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.473510   0.364693   0.668874   0.427169  
Loss: 0.6123
Fold 3 Epoch 041; Train loss: 0.4296; Time: 00:00:01
Fold 3 Epoch 042; Train loss: 0.4193; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.4168; Time: 00:00:01
Fold 3 Epoch 044; Train loss: 0.4057; Time: 00:00:00
Traceback (most recent call last):
  File "/home/amir/Desktop/2PDreamRec/DreamRec_Gen.py", line 529, in <module>
    main()
  File "/home/amir/Desktop/2PDreamRec/DreamRec_Gen.py", line 454, in main
    f.write(str(train_fold(tuning_fold)))
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/DreamRec_Gen.py", line 190, in train_fold
    loss.backward()
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/_tensor.py", line 626, in backward
    torch.autograd.backward(
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/autograd/graph.py", line 823, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Tuning lr:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 53.3455; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.7644; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.3038; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.2507; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.2123; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.1857; Time: 00:00:01
Fold 3 Epoch 007; Train loss: 0.1585; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.1412; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.1224; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.1111; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.362583   0.262551   0.683775   0.364848  
Loss: 0.1200
Fold 3 Epoch 011; Train loss: 0.0993; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0912; Time: 00:00:01
Fold 3 Epoch 013; Train loss: 0.0837; Time: 00:00:01
Fold 3 Epoch 014; Train loss: 0.0801; Time: 00:00:01
Fold 3 Epoch 015; Train loss: 0.0739; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0702; Time: 00:00:01
Fold 3 Epoch 017; Train loss: 0.0667; Time: 00:00:01
Fold 3 Epoch 018; Train loss: 0.0631; Time: 00:00:01
Fold 3 Epoch 019; Train loss: 0.0607; Time: 00:00:01
Fold 3 Epoch 020; Train loss: 0.0610; Time: 00:00:01
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.399007   0.289719   0.632450   0.365714  
Loss: 0.0725
Fold 3 Epoch 021; Train loss: 0.0586; Time: 00:00:01
Fold 3 Epoch 022; Train loss: 0.0628; Time: 00:00:01
Fold 3 Epoch 023; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0570; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0518; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0510; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0490; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0468; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0460; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0447; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.314570   0.196349   0.528146   0.263919  
Loss: 0.0585
Fold 3 Epoch 031; Train loss: 0.0451; Time: 00:00:01
Fold 3 Epoch 032; Train loss: 0.0454; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0477; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0516; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0475; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0432; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0423; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0392; Time: 00:00:01
Fold 3 Epoch 039; Train loss: 0.0396; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0396; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.329470   0.223625   0.519868   0.283636  
Loss: 0.0489
Fold 3 Epoch 041; Train loss: 0.0384; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0376; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0365; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0355; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0350; Time: 00:00:01
Fold 3 Epoch 046; Train loss: 0.0359; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0361; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0409; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0466; Time: 00:00:01
Fold 3 Epoch 050; Train loss: 0.0390; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.321192   0.211398   0.407285   0.239382  
Loss: 0.0492
Fold 3 Epoch 051; Train loss: 0.0339; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0323; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0305; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0294; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0303; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0290; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0285; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0280; Time: 00:00:01
Fold 3 Epoch 059; Train loss: 0.0269; Time: 00:00:01
Fold 3 Epoch 060; Train loss: 0.0266; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.352649   0.303415   0.584437   0.377999  
Loss: 0.0363
Fold 3 Epoch 061; Train loss: 0.0276; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0253; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0263; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0249; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0254; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0257; Time: 00:00:01
Fold 3 Epoch 067; Train loss: 0.0285; Time: 00:00:01
Fold 3 Epoch 068; Train loss: 0.0276; Time: 00:00:01
Fold 3 Epoch 069; Train loss: 0.0271; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0255; Time: 00:00:01
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.354305   0.245958   0.549669   0.307818  
Loss: 0.0248
Fold 3 Epoch 071; Train loss: 0.0229; Time: 00:00:01
Fold 3 Epoch 072; Train loss: 0.0220; Time: 00:00:01
Fold 3 Epoch 073; Train loss: 0.0220; Time: 00:00:01
Fold 3 Epoch 074; Train loss: 0.0213; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0208; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0207; Time: 00:00:01
Fold 3 Epoch 077; Train loss: 0.0197; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0203; Time: 00:00:01
Fold 3 Epoch 079; Train loss: 0.0194; Time: 00:00:01
Fold 3 Epoch 080; Train loss: 0.0198; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.360927   0.271893   0.529801   0.326331  
Loss: 0.0224
Fold 3 Epoch 081; Train loss: 0.0193; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0186; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0183; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0185; Time: 00:00:01
Fold 3 Epoch 085; Train loss: 0.0185; Time: 00:00:01
Fold 3 Epoch 086; Train loss: 0.0195; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0242; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0238; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0191; Time: 00:00:01
Fold 3 Epoch 090; Train loss: 0.0177; Time: 00:00:01
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.296358   0.228858   0.438742   0.274540  
Loss: 0.0168
Fold 3 Epoch 091; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0165; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0164; Time: 00:00:01
Fold 3 Epoch 094; Train loss: 0.0167; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0162; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0148; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0151; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0154; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0153; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0148; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.599338   0.422317   0.690397   0.451522  
Loss: 0.0195
[lr candidate 0.05] Fold 3: HR@10 = [np.float64(0.6837748344370861), np.float64(0.6324503311258278), np.float64(0.5281456953642384), np.float64(0.5198675496688742), np.float64(0.40728476821192056), np.float64(0.5844370860927153), np.float64(0.5496688741721855), np.float64(0.5298013245033113), np.float64(0.43874172185430466), np.float64(0.6903973509933775)]
Tuning lr:  25%|██▌       | 1/4 [01:40<05:00, 100.18s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.6668; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2270; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1519; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1159; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.1009; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0946; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0906; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0830; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0818; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0779; Time: 00:00:01
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.614238   0.410479   0.774834   0.462108  
Loss: 0.0991
Fold 3 Epoch 011; Train loss: 0.0769; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0759; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0733; Time: 00:00:01
Fold 3 Epoch 014; Train loss: 0.0716; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0691; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0664; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0685; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0628; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0628; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0632; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.531457   0.351225   0.705298   0.407466  
Loss: 0.0748
Fold 3 Epoch 021; Train loss: 0.0614; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0607; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0592; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0571; Time: 00:00:01
Fold 3 Epoch 025; Train loss: 0.0575; Time: 00:00:01
Fold 3 Epoch 026; Train loss: 0.0559; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0542; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0522; Time: 00:00:01
Fold 3 Epoch 029; Train loss: 0.0534; Time: 00:00:01
Fold 3 Epoch 030; Train loss: 0.0514; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
Tuning lr:  25%|██▌       | 1/4 [02:09<06:27, 129.19s/it]
Traceback (most recent call last):
  File "/home/amir/Desktop/2PDreamRec/DreamRec_Gen.py", line 529, in <module>
    main()
  File "/home/amir/Desktop/2PDreamRec/DreamRec_Gen.py", line 377, in main
    fm = train_fold(tuning_fold)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/DreamRec_Gen.py", line 201, in train_fold
    test_met = evaluate(model, diff, f"test_fold{fold}.df", device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/DreamRec_Gen.py", line 114, in evaluate
    prediction = model.predict(seq_batch, len_seq_batch, diff)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/Modules_ori.py", line 337, in predict
    x = diff.sample(self.forward, self.forward_uncon, h)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/Modules_ori.py", line 190, in sample
    x = self.p_sample(model_forward, model_forward_uncon, x, h,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/Modules_ori.py", line 169, in p_sample
    x_start = (1 + self.w) * model_forward(x, h, t) - self.w * model_forward_uncon(x, t)
                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/Modules_ori.py", line 269, in forward
    res = self.diffuser(torch.cat((x, h, t), dim=1))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/amir/Desktop/2PDreamRec/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Tuning lr:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 53.3455; Time: 00:00:01
Fold 3 Epoch 002; Train loss: 0.7644; Time: 00:00:01
Fold 3 Epoch 003; Train loss: 0.3038; Time: 00:00:01
Fold 3 Epoch 004; Train loss: 0.2507; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.2123; Time: 00:00:01
Fold 3 Epoch 006; Train loss: 0.1857; Time: 00:00:01
Fold 3 Epoch 007; Train loss: 0.1585; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.1412; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.1224; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.1111; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.362583   0.262551   0.683775   0.364848  
Loss: 0.1200
Fold 3 Epoch 011; Train loss: 0.0993; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0912; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0837; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0801; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0739; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0702; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0667; Time: 00:00:01
Fold 3 Epoch 018; Train loss: 0.0631; Time: 00:00:01
Fold 3 Epoch 019; Train loss: 0.0607; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0610; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.399007   0.289719   0.632450   0.365714  
Loss: 0.0725
Fold 3 Epoch 021; Train loss: 0.0586; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0628; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0570; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0518; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0510; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0490; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0468; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0460; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0447; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.314570   0.196349   0.528146   0.263919  
Loss: 0.0585
Fold 3 Epoch 031; Train loss: 0.0451; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0454; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0477; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0516; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0475; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0432; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0423; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0392; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0396; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0396; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.329470   0.223625   0.519868   0.283636  
Loss: 0.0489
Fold 3 Epoch 041; Train loss: 0.0384; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0376; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0365; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0355; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0350; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0359; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0361; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0409; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0466; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0390; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.321192   0.211398   0.407285   0.239382  
Loss: 0.0492
Fold 3 Epoch 051; Train loss: 0.0339; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0323; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0305; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0294; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0303; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0290; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0285; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0280; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0269; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0266; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.352649   0.303415   0.584437   0.377999  
Loss: 0.0363
Fold 3 Epoch 061; Train loss: 0.0276; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0253; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0263; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0249; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0254; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0257; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0285; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0276; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0271; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0255; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.354305   0.245958   0.549669   0.307818  
Loss: 0.0248
Fold 3 Epoch 071; Train loss: 0.0229; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0220; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0220; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0213; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0208; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0207; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0197; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0203; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0194; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0198; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.360927   0.271893   0.529801   0.326331  
Loss: 0.0224
Fold 3 Epoch 081; Train loss: 0.0193; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0186; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0183; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0185; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0185; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0195; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0242; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0238; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0191; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0177; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.296358   0.228858   0.438742   0.274540  
Loss: 0.0168
Fold 3 Epoch 091; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0165; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0167; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0162; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0148; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0151; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0154; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0153; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0148; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.599338   0.422317   0.690397   0.451522  
Loss: 0.0195
[lr candidate 0.05] Fold 3: loss = [np.float64(0.11995784193277359), np.float64(0.07250799238681793), np.float64(0.058483757078647614), np.float64(0.04891933500766754), np.float64(0.04919802397489548), np.float64(0.03630226477980614), np.float64(0.02478320151567459), np.float64(0.02241729572415352), np.float64(0.016756927594542503), np.float64(0.019492756575345993)]
Tuning lr:  25%|██▌       | 1/4 [01:31<04:35, 91.91s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.6668; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2270; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1519; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1159; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.1009; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0946; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0906; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0830; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0818; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0779; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.614238   0.410479   0.774834   0.462108  
Loss: 0.0991
Fold 3 Epoch 011; Train loss: 0.0769; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0759; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0733; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0716; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0691; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0664; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0685; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0628; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0628; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0632; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.531457   0.351225   0.705298   0.407466  
Loss: 0.0748
Fold 3 Epoch 021; Train loss: 0.0614; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0607; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0592; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0571; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0575; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0559; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0542; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0522; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0534; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0514; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.597682   0.454950   0.710265   0.492063  
Loss: 0.0610
Fold 3 Epoch 031; Train loss: 0.0515; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0494; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0477; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0481; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0457; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0455; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0444; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0433; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0422; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0410; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.445364   0.337134   0.567881   0.376266  
Loss: 0.0510
Fold 3 Epoch 041; Train loss: 0.0395; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0396; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0372; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0366; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0361; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0349; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0341; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0331; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0320; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0311; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.485099   0.360223   0.605960   0.399302  
Loss: 0.0344
Fold 3 Epoch 051; Train loss: 0.0302; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0283; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0276; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0269; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0263; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0249; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0255; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0248; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0238; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0237; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.552980   0.383514   0.673841   0.423018  
Loss: 0.0250
Fold 3 Epoch 061; Train loss: 0.0225; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0219; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0215; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0210; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0197; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0199; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0200; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0202; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0190; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0185; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.513245   0.361303   0.649007   0.405161  
Loss: 0.0189
Fold 3 Epoch 071; Train loss: 0.0184; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0183; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0180; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0184; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0174; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0176; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0170; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0167; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.414351   0.637417   0.450696  
Loss: 0.0156
Fold 3 Epoch 081; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0160; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0161; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0150; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0156; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0152; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0154; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0149; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0139; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.514901   0.351893   0.652318   0.396474  
Loss: 0.0135
Fold 3 Epoch 091; Train loss: 0.0136; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0129; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0127; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0127; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0119; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0115; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0107; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0109; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0098; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.511589   0.317161   0.784768   0.404445  
Loss: 0.0091
[lr candidate 0.01] Fold 3: loss = [np.float64(0.09910187870264053), np.float64(0.07477156072854996), np.float64(0.06098494678735733), np.float64(0.050964001566171646), np.float64(0.034426722675561905), np.float64(0.024991275742650032), np.float64(0.01890677399933338), np.float64(0.01563570462167263), np.float64(0.013466347008943558), np.float64(0.009144144132733345)]
Tuning lr:  50%|█████     | 2/4 [02:59<02:59, 89.55s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.7855; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.3544; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.2256; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1655; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.1315; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.1126; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.1026; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0977; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0942; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0886; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.649007   0.490190   0.763245   0.526907  
Loss: 0.1221
Fold 3 Epoch 011; Train loss: 0.0854; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0822; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0809; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0790; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0782; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0742; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0741; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0728; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0725; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0710; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.493377   0.372464   0.644040   0.420438  
Loss: 0.0962
Fold 3 Epoch 021; Train loss: 0.0690; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0683; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0682; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0674; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0666; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0654; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0634; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0636; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0623; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.591060   0.467486   0.756623   0.520962  
Loss: 0.0812
Fold 3 Epoch 031; Train loss: 0.0616; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0608; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0621; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0622; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0593; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0593; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0588; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0583; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0567; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0573; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.607616   0.463659   0.768212   0.516083  
Loss: 0.0721
Fold 3 Epoch 041; Train loss: 0.0566; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0563; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0577; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0549; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0544; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0537; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0532; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0519; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0521; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0510; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.619205   0.484605   0.774834   0.535020  
Loss: 0.0648
Fold 3 Epoch 051; Train loss: 0.0517; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0509; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0492; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0491; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0490; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0479; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0475; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0467; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0464; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0448; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.526490   0.421897   0.653974   0.462845  
Loss: 0.0533
Fold 3 Epoch 061; Train loss: 0.0466; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0451; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0446; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0451; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0438; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0433; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0426; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0422; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0418; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0405; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.544702   0.368859   0.693709   0.417584  
Loss: 0.0531
Fold 3 Epoch 071; Train loss: 0.0418; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0401; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0408; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0394; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0387; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0380; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0375; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0372; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0367; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0352; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.476821   0.355594   0.619205   0.402035  
Loss: 0.0464
Fold 3 Epoch 081; Train loss: 0.0351; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0345; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0344; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0340; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0348; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0335; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0330; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0318; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0320; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0313; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.634106   0.482442   0.758278   0.522657  
Loss: 0.0391
Fold 3 Epoch 091; Train loss: 0.0313; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0311; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0316; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0306; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0307; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0291; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0294; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0284; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0289; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0282; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.584437   0.439848   0.745033   0.491606  
Loss: 0.0352
[lr candidate 0.005] Fold 3: loss = [np.float64(0.12205846607685089), np.float64(0.09624721109867096), np.float64(0.08115662634372711), np.float64(0.07205230742692947), np.float64(0.06483150273561478), np.float64(0.05325639620423317), np.float64(0.05310078337788582), np.float64(0.04643130302429199), np.float64(0.039068400859832764), np.float64(0.03524244949221611)]
Tuning lr:  75%|███████▌  | 3/4 [04:27<01:28, 88.79s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 1.0811; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.7940; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.6209; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.5226; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.4421; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.3818; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.3359; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.2949; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.2653; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.2401; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.758278   0.596220   0.834437   0.620963  
Loss: 0.3897
Fold 3 Epoch 011; Train loss: 0.2223; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.2018; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.1889; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.1763; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.1652; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.1552; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.1485; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.1439; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.1377; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.1314; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.726821   0.580559   0.816225   0.609545  
Loss: 0.2140
Fold 3 Epoch 021; Train loss: 0.1287; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.1236; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.1220; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.1167; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.1140; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.1105; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.1091; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.1075; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.1053; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.1047; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.703642   0.565010   0.794702   0.594127  
Loss: 0.1602
Fold 3 Epoch 031; Train loss: 0.1002; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.1009; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0990; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0976; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0972; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0967; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0956; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0933; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0941; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0905; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.701987   0.570176   0.786424   0.597349  
Loss: 0.1345
Fold 3 Epoch 041; Train loss: 0.0905; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0878; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0891; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0891; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0877; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0848; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0857; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0836; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0829; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0830; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.751656   0.596690   0.826159   0.620601  
Loss: 0.1237
Fold 3 Epoch 051; Train loss: 0.0833; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0832; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0829; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0812; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0821; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0809; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0803; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0794; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0801; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0793; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.678808   0.534506   0.771523   0.564359  
Loss: 0.1133
Fold 3 Epoch 061; Train loss: 0.0774; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0772; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0784; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0789; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0772; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0757; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0762; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0754; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0748; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0762; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.612583   0.463471   0.758278   0.510216  
Loss: 0.1094
Fold 3 Epoch 071; Train loss: 0.0746; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0749; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0753; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0761; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0742; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0736; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0732; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0718; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0748; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0732; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.733444   0.579628   0.819536   0.607186  
Loss: 0.1002
Fold 3 Epoch 081; Train loss: 0.0735; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0719; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0711; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0717; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0717; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0701; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0709; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0716; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0717; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0705; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.708609   0.557797   0.786424   0.582583  
Loss: 0.0932
Fold 3 Epoch 091; Train loss: 0.0707; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0688; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0704; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0712; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0671; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0688; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0688; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0680; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0697; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0679; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.682119   0.530064   0.766556   0.557627  
Loss: 0.0962
[lr candidate 0.001] Fold 3: loss = [np.float64(0.3897291123867035), np.float64(0.2140294462442398), np.float64(0.16020627319812775), np.float64(0.13454125821590424), np.float64(0.12372612208127975), np.float64(0.11327983438968658), np.float64(0.1093505471944809), np.float64(0.10020139068365097), np.float64(0.09321650862693787), np.float64(0.09622456133365631)]
Tuning lr: 100%|██████████| 4/4 [05:55<00:00, 88.42s/it]Tuning lr: 100%|██████████| 4/4 [05:55<00:00, 88.89s/it]

Best learning rate found: 0.01
Tuning data for lr (loss) saved to ./category/tuning_lr.json
Tuning optimizer:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.6039; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2145; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1402; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1123; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.0995; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0917; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0810; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0786; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0750; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0723; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.501656   0.389069   0.687086   0.448412  
Loss: 0.0933
Fold 3 Epoch 011; Train loss: 0.0692; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0701; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0678; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0663; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0634; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0634; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0608; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0612; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0575; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.473510   0.336624   0.624172   0.385027  
Loss: 0.0681
Fold 3 Epoch 021; Train loss: 0.0568; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0561; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0556; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0527; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0535; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0519; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0508; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0493; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0485; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0478; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.604305   0.463912   0.738411   0.507082  
Loss: 0.0562
Fold 3 Epoch 031; Train loss: 0.0467; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0457; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0447; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0426; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0419; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0408; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0398; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0397; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0387; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0365; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.466887   0.321537   0.644040   0.378019  
Loss: 0.0409
Fold 3 Epoch 041; Train loss: 0.0355; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0347; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0337; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0338; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0327; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0313; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0297; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0295; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0289; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0283; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.511589   0.372715   0.692053   0.430830  
Loss: 0.0325
Fold 3 Epoch 051; Train loss: 0.0281; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0267; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0257; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0251; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0251; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0245; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0228; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0229; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0216; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0210; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.642384   0.474393   0.802980   0.526269  
Loss: 0.0238
Fold 3 Epoch 061; Train loss: 0.0212; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0206; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0198; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0188; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0181; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0176; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0174; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0170; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0156; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.677152   0.484612   0.832781   0.534680  
Loss: 0.0150
Fold 3 Epoch 071; Train loss: 0.0155; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0148; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0146; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0148; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0136; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0128; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0133; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0121; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0116; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.653974   0.451645   0.855960   0.516901  
Loss: 0.0109
Fold 3 Epoch 081; Train loss: 0.0112; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0108; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0104; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0098; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0095; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0092; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0092; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0087; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0086; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0082; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.645695   0.444242   0.827815   0.503155  
Loss: 0.0073
Fold 3 Epoch 091; Train loss: 0.0081; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0076; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0071; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0068; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0063; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0063; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0060; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0056; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0055; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0053; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.501656   0.313783   0.687086   0.372435  
Loss: 0.0056
[optimizer candidate nadam] Fold 3: loss = [np.float64(0.0932777151465416), np.float64(0.06806247681379318), np.float64(0.05620218813419342), np.float64(0.04093455150723457), np.float64(0.03247695416212082), np.float64(0.02377208136022091), np.float64(0.014951169490814209), np.float64(0.010882250033318996), np.float64(0.007275278214365244), np.float64(0.005628183484077454)]
Tuning optimizer:  25%|██▌       | 1/4 [01:27<04:23, 87.79s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.9766; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.7170; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.5687; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.4653; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.3760; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.3067; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.2511; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.2050; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.1738; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.1485; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.548013   0.442876   0.716887   0.497923  
Loss: 0.2282
Fold 3 Epoch 011; Train loss: 0.1275; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.1134; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.1012; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0935; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0837; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0780; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0727; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0693; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0644; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0645; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.617550   0.478693   0.769868   0.528192  
Loss: 0.0829
Fold 3 Epoch 021; Train loss: 0.0605; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0595; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0565; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0550; Time: 00:00:01
Fold 3 Epoch 025; Train loss: 0.0533; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0519; Time: 00:00:01
Fold 3 Epoch 027; Train loss: 0.0496; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0495; Time: 00:00:01
Fold 3 Epoch 029; Train loss: 0.0471; Time: 00:00:01
Fold 3 Epoch 030; Train loss: 0.0463; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.538079   0.420003   0.692053   0.468981  
Loss: 0.0616
Fold 3 Epoch 031; Train loss: 0.0447; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0426; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0430; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0417; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0402; Time: 00:00:01
Fold 3 Epoch 036; Train loss: 0.0390; Time: 00:00:01
Fold 3 Epoch 037; Train loss: 0.0390; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0365; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0362; Time: 00:00:01
Fold 3 Epoch 040; Train loss: 0.0356; Time: 00:00:01
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.612583   0.456559   0.759934   0.503832  
Loss: 0.0448
Fold 3 Epoch 041; Train loss: 0.0341; Time: 00:00:01
Fold 3 Epoch 042; Train loss: 0.0339; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0328; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0310; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0299; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0295; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0284; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0289; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0269; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0265; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.594371   0.443666   0.710265   0.481070  
Loss: 0.0325
Fold 3 Epoch 051; Train loss: 0.0258; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0255; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0245; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0235; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0226; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0222; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0212; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0199; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0198; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0189; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.493377   0.353710   0.632450   0.398298  
Loss: 0.0237
Fold 3 Epoch 061; Train loss: 0.0188; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0166; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0163; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0159; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0152; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0131; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0126; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0118; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0105; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.582781   0.320484   0.771523   0.381806  
Loss: 0.0102
Fold 3 Epoch 071; Train loss: 0.0101; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0095; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0080; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0073; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0066; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0062; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0055; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0048; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0046; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0044; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.508278   0.263746   0.822848   0.363371  
Loss: 0.0036
Fold 3 Epoch 081; Train loss: 0.0037; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0032; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0026; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0019; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0015; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0009; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0007; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0006; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0004; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.339404   0.158396   0.675497   0.257363  
Loss: 0.0005
Fold 3 Epoch 091; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.321192   0.174605   0.403974   0.200377  
Loss: 0.0001
[optimizer candidate lamb] Fold 3: loss = [np.float64(0.2281842827796936), np.float64(0.08294201642274857), np.float64(0.06156033277511597), np.float64(0.044840794056653976), np.float64(0.032511018216609955), np.float64(0.02374851517379284), np.float64(0.01018130499869585), np.float64(0.0035923272371292114), np.float64(0.00047976261703297496), np.float64(0.00013507036783266813)]
Tuning optimizer:  50%|█████     | 2/4 [03:00<03:00, 90.44s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.5271; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2108; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1440; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1131; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.0945; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0828; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0771; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0720; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0723; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0666; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.486755   0.368656   0.649007   0.420442  
Loss: 0.0935
Fold 3 Epoch 011; Train loss: 0.0660; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0639; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0623; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0622; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0603; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0613; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0604; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0571; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0578; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0569; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.503311   0.393270   0.640728   0.436771  
Loss: 0.0740
Fold 3 Epoch 021; Train loss: 0.0562; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0556; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0549; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0541; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0529; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0535; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0501; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0494; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0503; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0481; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.430464   0.323114   0.567881   0.366524  
Loss: 0.0608
Fold 3 Epoch 031; Train loss: 0.0472; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0464; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0457; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0455; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0437; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0437; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0428; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0409; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0417; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0409; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.432119   0.341927   0.579470   0.389548  
Loss: 0.0549
Fold 3 Epoch 041; Train loss: 0.0393; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0395; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0375; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0384; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0365; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0357; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0360; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0336; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0334; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0327; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.475166   0.376820   0.645695   0.431085  
Loss: 0.0422
Fold 3 Epoch 051; Train loss: 0.0324; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0314; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0315; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0297; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0286; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0277; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0277; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0263; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0257; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0249; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.427152   0.324851   0.591060   0.377639  
Loss: 0.0360
Fold 3 Epoch 061; Train loss: 0.0237; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0233; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0231; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0226; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0217; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0222; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0204; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0202; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0201; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0189; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.480132   0.383090   0.600993   0.421703  
Loss: 0.0254
Fold 3 Epoch 071; Train loss: 0.0189; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0186; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0180; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0174; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0176; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0157; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0150; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0147; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0147; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.624172   0.491174   0.748344   0.531350  
Loss: 0.0171
Fold 3 Epoch 081; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0137; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0129; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0123; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0117; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0116; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0112; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0103; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0097; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0095; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.632450   0.462538   0.738411   0.496175  
Loss: 0.0132
Fold 3 Epoch 091; Train loss: 0.0090; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0088; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0081; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0078; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0074; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0072; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0069; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0067; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0060; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0057; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.614238   0.442998   0.690397   0.466242  
Loss: 0.0098
[optimizer candidate adamw] Fold 3: loss = [np.float64(0.0935436338186264), np.float64(0.07396013289690018), np.float64(0.060804929584264755), np.float64(0.054936669766902924), np.float64(0.04217999428510666), np.float64(0.0360424742102623), np.float64(0.025401150807738304), np.float64(0.017088402062654495), np.float64(0.013207186944782734), np.float64(0.009809955954551697)]
Tuning optimizer:  75%|███████▌  | 3/4 [04:28<01:29, 89.36s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Fold 3 Epoch 001; Train loss: 1.0926; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 1.0661; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 1.0540; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 1.0335; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 1.0160; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.9947; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.9706; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.9477; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.9232; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.9008; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.327815   0.185820   0.745033   0.316494  
Loss: 1.0491
Fold 3 Epoch 011; Train loss: 0.8765; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.8455; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.8267; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.7998; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.7770; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.7507; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.7321; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.7061; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.6879; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.6633; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.385762   0.279128   0.764901   0.398342  
Loss: 0.9019
Fold 3 Epoch 021; Train loss: 0.6479; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.6307; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.6116; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.5938; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.5761; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.5620; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.5482; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.5313; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.5183; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.5070; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.478477   0.320430   0.763245   0.413492  
Loss: 0.7879
Fold 3 Epoch 031; Train loss: 0.4954; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.4817; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.4720; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.4568; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.4454; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.4389; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.4338; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.4218; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.4157; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.4062; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.521523   0.340471   0.776490   0.423526  
Loss: 0.6941
Fold 3 Epoch 041; Train loss: 0.3925; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.3952; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.3820; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.3767; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.3688; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.3599; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.3602; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.3517; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.3473; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.3336; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.546358   0.366127   0.773179   0.441134  
Loss: 0.6144
Fold 3 Epoch 051; Train loss: 0.3341; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.3235; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.3252; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.3213; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.3138; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.3117; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.3086; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.3008; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.2977; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.2960; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.577815   0.393451   0.764901   0.453424  
Loss: 0.5398
Fold 3 Epoch 061; Train loss: 0.2899; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.2896; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.2812; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.2807; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.2763; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.2732; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.2714; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.2673; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.2636; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.2585; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.584437   0.411659   0.746689   0.462756  
Loss: 0.4779
Fold 3 Epoch 071; Train loss: 0.2580; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.2561; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.2558; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.2494; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.2479; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.2465; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.2435; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.2407; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.2392; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.2379; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.576159   0.415641   0.743377   0.468503  
Loss: 0.4335
Fold 3 Epoch 081; Train loss: 0.2332; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.2303; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.2316; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.2254; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.2238; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.2240; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.2202; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.2173; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.2180; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.2153; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.564570   0.415926   0.700331   0.459526  
Loss: 0.3962
Fold 3 Epoch 091; Train loss: 0.2122; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.2118; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.2125; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.2079; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.2062; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.2079; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.2083; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.2031; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.1997; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.2021; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.572848   0.425129   0.721854   0.472461  
Loss: 0.3490
[optimizer candidate adabelief] Fold 3: loss = [np.float64(1.049083948135376), np.float64(0.9019185304641724), np.float64(0.7879472374916077), np.float64(0.694096565246582), np.float64(0.6143596768379211), np.float64(0.5397864580154419), np.float64(0.4779486656188965), np.float64(0.4334505498409271), np.float64(0.39624372124671936), np.float64(0.3489680886268616)]
Tuning optimizer: 100%|██████████| 4/4 [05:56<00:00, 89.06s/it]Tuning optimizer: 100%|██████████| 4/4 [05:56<00:00, 89.19s/it]

Best optimizer found: lamb
Tuning data for optimizer (loss) saved to ./category/tuning_optimizer.json
Tuning timesteps:   0%|          | 0/5 [00:00<?, ?it/s]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 1.1004; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.8023; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.6372; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.5236; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.4231; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.3435; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.2802; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.2300; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.1895; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.1592; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.579470   0.449415   0.754967   0.505603  
Loss: 0.2530
Fold 3 Epoch 011; Train loss: 0.1358; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.1173; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.1052; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0990; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0880; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0828; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0772; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0734; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0713; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0671; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.574503   0.454049   0.733444   0.504750  
Loss: 0.0941
Fold 3 Epoch 021; Train loss: 0.0656; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0617; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0612; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0593; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0566; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0535; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0533; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0527; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0506; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0489; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.500000   0.366511   0.726821   0.440051  
Loss: 0.0623
Fold 3 Epoch 031; Train loss: 0.0472; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0467; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0448; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0436; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0420; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0420; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0412; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0395; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0390; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0376; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.504967   0.418114   0.673841   0.471361  
Loss: 0.0485
Fold 3 Epoch 041; Train loss: 0.0376; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0355; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0340; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0344; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0335; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0322; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0322; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0311; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0307; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0298; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.500000   0.382723   0.660596   0.434198  
Loss: 0.0314
Fold 3 Epoch 051; Train loss: 0.0283; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0285; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0270; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0261; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0254; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0257; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0244; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0246; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0226; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0220; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.408940   0.276937   0.594371   0.336620  
Loss: 0.0254
Fold 3 Epoch 061; Train loss: 0.0215; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0211; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0193; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0209; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0187; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0180; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0177; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0163; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0158; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0151; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.538079   0.329602   0.698675   0.382312  
Loss: 0.0153
Fold 3 Epoch 071; Train loss: 0.0152; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0147; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0141; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0123; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0120; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0113; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0101; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0094; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0084; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0075; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.610927   0.327647   0.731788   0.366387  
Loss: 0.0075
Fold 3 Epoch 081; Train loss: 0.0067; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0059; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0049; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0041; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0035; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0027; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0019; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0013; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0008; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0005; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.291391   0.142806   0.596026   0.232498  
Loss: 0.0008
Fold 3 Epoch 091; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.250000   0.167138   0.326159   0.191919  
Loss: 0.0002
[timesteps candidate 100] Fold 3: loss = [np.float64(0.25304731726646423), np.float64(0.09405092895030975), np.float64(0.062304604798555374), np.float64(0.0484653040766716), np.float64(0.0313703790307045), np.float64(0.025403881445527077), np.float64(0.015328186564147472), np.float64(0.007501583080738783), np.float64(0.0007615273934789002), np.float64(0.00018766181892715394)]
Tuning timesteps:  20%|██        | 1/5 [01:29<05:57, 89.33s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 1.0177; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.7677; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.6331; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.5236; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.4429; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.3702; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.3052; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.2666; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.2239; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.1934; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.640728   0.461219   0.804636   0.514093  
Loss: 0.2963
Fold 3 Epoch 011; Train loss: 0.1716; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.1498; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.1361; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.1249; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.1168; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.1093; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.1010; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0994; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0920; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0880; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.503311   0.359219   0.645695   0.404915  
Loss: 0.1154
Fold 3 Epoch 021; Train loss: 0.0869; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0828; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0808; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0754; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0762; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0707; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0746; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0695; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0676; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0670; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.491722   0.353869   0.637417   0.400441  
Loss: 0.0831
Fold 3 Epoch 031; Train loss: 0.0635; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0619; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0601; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0592; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0552; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0547; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0537; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0513; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0502; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0488; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.483444   0.361765   0.701987   0.433282  
Loss: 0.0563
Fold 3 Epoch 041; Train loss: 0.0469; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0454; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0439; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0419; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0413; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0395; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0380; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0367; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0353; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0336; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.460265   0.337495   0.645695   0.397195  
Loss: 0.0387
Fold 3 Epoch 051; Train loss: 0.0330; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0312; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0300; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0282; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0274; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0264; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0242; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0233; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0223; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0203; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.576159   0.367524   0.798013   0.437859  
Loss: 0.0223
Fold 3 Epoch 061; Train loss: 0.0199; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0191; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0177; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0167; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0152; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0130; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0121; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0106; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0098; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.574503   0.362086   0.733444   0.412622  
Loss: 0.0098
Fold 3 Epoch 071; Train loss: 0.0086; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0072; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0062; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0051; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0046; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0035; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0026; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0019; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0013; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0009; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.279801   0.251093   0.895695   0.449733  
Loss: 0.0007
Fold 3 Epoch 081; Train loss: 0.0006; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.100993   0.050750   0.438742   0.154814  
Loss: 0.0001
Fold 3 Epoch 091; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.357616   0.211128   0.427152   0.232706  
Loss: 0.0002
[timesteps candidate 150] Fold 3: loss = [np.float64(0.29630371928215027), np.float64(0.11541537195444107), np.float64(0.08309628069400787), np.float64(0.05627800151705742), np.float64(0.03866680711507797), np.float64(0.022254880517721176), np.float64(0.009844009764492512), np.float64(0.000720278243534267), np.float64(0.00013685297744814306), np.float64(0.00015558229642920196)]
Tuning timesteps:  40%|████      | 2/5 [02:59<04:28, 89.62s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 1.0225; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.7577; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.6262; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.5310; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.4470; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.3752; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.3196; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.2734; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.2379; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.2098; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.478477   0.390164   0.672185   0.450322  
Loss: 0.3131
Fold 3 Epoch 011; Train loss: 0.1863; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.1706; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.1584; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.1432; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.1343; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.1260; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.1209; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.1162; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.1116; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.1071; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.382450   0.308493   0.627483   0.384275  
Loss: 0.1454
Fold 3 Epoch 021; Train loss: 0.1021; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0998; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0952; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0945; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0928; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0875; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0854; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0833; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0802; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0785; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.562914   0.439358   0.705298   0.485074  
Loss: 0.1009
Fold 3 Epoch 031; Train loss: 0.0730; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0708; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0691; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0682; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0648; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0622; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0599; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0574; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0553; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0531; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.451987   0.330831   0.680464   0.404843  
Loss: 0.0688
Fold 3 Epoch 041; Train loss: 0.0502; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0482; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0471; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0435; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0419; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0403; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0377; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0359; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0353; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0321; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.385762   0.257463   0.672185   0.350217  
Loss: 0.0414
Fold 3 Epoch 051; Train loss: 0.0309; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0279; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0261; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0247; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0229; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0205; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0184; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0170; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0153; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0135; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.591060   0.329249   0.895695   0.430708  
Loss: 0.0154
Fold 3 Epoch 061; Train loss: 0.0120; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0100; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0088; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0073; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0062; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0051; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0041; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0033; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0026; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0020; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.500000   0.269412   0.890728   0.392962  
Loss: 0.0022
Fold 3 Epoch 071; Train loss: 0.0014; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0011; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0009; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0007; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0006; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0005; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0005; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0005; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0004; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.329470   0.179610   0.647351   0.281057  
Loss: 0.0001
Fold 3 Epoch 081; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.061258   0.037542   0.579470   0.205628  
Loss: 0.0001
Fold 3 Epoch 091; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.539735   0.310755   0.619205   0.336028  
Loss: 0.0002
[timesteps candidate 200] Fold 3: loss = [np.float64(0.31306272745132446), np.float64(0.14541411399841309), np.float64(0.1009388118982315), np.float64(0.06879059970378876), np.float64(0.04135613888502121), np.float64(0.01538625918328762), np.float64(0.0022239002864807844), np.float64(0.0001228577020810917), np.float64(0.00014954025391489267), np.float64(0.00015827584138605744)]
Tuning timesteps:  60%|██████    | 3/5 [04:29<03:00, 90.07s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 1.2460; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.9482; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.7788; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.6630; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.5545; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.4705; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.4014; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.3448; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.3006; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.2655; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.655629   0.475487   0.753311   0.506763  
Loss: 0.3612
Fold 3 Epoch 011; Train loss: 0.2410; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.2227; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.1977; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.1856; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.1840; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.1720; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.1612; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.1550; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.1505; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.1422; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.658940   0.484456   0.824503   0.536950  
Loss: 0.1868
Fold 3 Epoch 021; Train loss: 0.1336; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.1296; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.1282; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.1238; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.1208; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.1145; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.1117; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.1065; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.1022; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0989; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.639073   0.443181   0.733444   0.474198  
Loss: 0.1278
Fold 3 Epoch 031; Train loss: 0.0965; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0895; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0919; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0868; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0836; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0824; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0771; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0759; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0734; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0684; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.635762   0.435596   0.771523   0.479688  
Loss: 0.0789
Fold 3 Epoch 041; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0622; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0611; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0579; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0546; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0531; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0500; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0468; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0445; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0419; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.301988   0.695364   0.358963  
Loss: 0.0489
Fold 3 Epoch 051; Train loss: 0.0390; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0372; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0344; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0323; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0294; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0269; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0250; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0227; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0211; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0187; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.394040   0.219159   0.695364   0.314417  
Loss: 0.0196
Fold 3 Epoch 061; Train loss: 0.0168; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0152; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0124; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0115; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0099; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0083; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0068; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0054; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0039; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0028; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.354305   0.195416   0.862583   0.356977  
Loss: 0.0028
Fold 3 Epoch 071; Train loss: 0.0018; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0013; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0011; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0009; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0008; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0006; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0006; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0005; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0005; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0005; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.059603   0.030864   0.394040   0.132786  
Loss: 0.0001
Fold 3 Epoch 081; Train loss: 0.0005; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0003; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.087748   0.054131   0.433775   0.157273  
Loss: 0.0001
Fold 3 Epoch 091; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.357616   0.171338   0.629139   0.253856  
Loss: 0.0002
[timesteps candidate 250] Fold 3: loss = [np.float64(0.3612459599971771), np.float64(0.18684040009975433), np.float64(0.1278410702943802), np.float64(0.07886544615030289), np.float64(0.04893477261066437), np.float64(0.019648702815175056), np.float64(0.00282256375066936), np.float64(0.00010981435480061918), np.float64(0.0001071742590283975), np.float64(0.0002218848530901596)]
Tuning timesteps:  80%|████████  | 4/5 [06:00<01:30, 90.51s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 1.1043; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.8377; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.6999; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.5983; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.5101; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.4412; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.3829; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.3360; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.3033; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.2649; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.639073   0.507695   0.774834   0.551936  
Loss: 0.3672
Fold 3 Epoch 011; Train loss: 0.2401; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.2153; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.2038; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.1910; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.1770; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.1719; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.1572; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.1495; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.1444; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.1422; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.640728   0.507817   0.796358   0.557775  
Loss: 0.1896
Fold 3 Epoch 021; Train loss: 0.1340; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.1266; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.1234; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.1190; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.1146; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.1127; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.1062; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.1034; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0981; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0954; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.634106   0.483949   0.751656   0.521939  
Loss: 0.1298
Fold 3 Epoch 031; Train loss: 0.0913; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0872; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0851; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0802; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0774; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0730; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0706; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0691; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0643; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0607; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.587748   0.496151   0.751656   0.549058  
Loss: 0.0822
Fold 3 Epoch 041; Train loss: 0.0574; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0552; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0514; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0475; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0454; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0438; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0392; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0362; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0342; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0308; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.567881   0.467139   0.753311   0.527175  
Loss: 0.0441
Fold 3 Epoch 051; Train loss: 0.0289; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0253; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0230; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0207; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0184; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0158; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0134; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0111; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0092; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0072; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.367550   0.319139   0.850993   0.474854  
Loss: 0.0112
Fold 3 Epoch 061; Train loss: 0.0057; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0041; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0029; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0019; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0012; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0009; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0006; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0005; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0003; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.039735   0.028451   0.311258   0.110176  
Loss: 0.0003
Fold 3 Epoch 071; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.079470   0.046474   0.390728   0.144125  
Loss: 0.0001
Fold 3 Epoch 081; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0001; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.081126   0.046223   0.649007   0.224319  
Loss: 0.0001
Fold 3 Epoch 091; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0001; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0001; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0001; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0001; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0001; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0001; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.519868   0.238145   0.822848   0.330006  
Loss: 0.0001
[timesteps candidate 300] Fold 3: loss = [np.float64(0.3671792149543762), np.float64(0.18957045674324036), np.float64(0.12983158230781555), np.float64(0.08224872499704361), np.float64(0.04408877715468407), np.float64(0.011238109320402145), np.float64(0.00027943027089349926), np.float64(0.00014601374277845025), np.float64(9.45084320846945e-05), np.float64(0.0001249842462129891)]
Tuning timesteps: 100%|██████████| 5/5 [07:32<00:00, 91.06s/it]Tuning timesteps: 100%|██████████| 5/5 [07:32<00:00, 90.59s/it]

Best timesteps found: 300
Tuning data for timesteps (loss) saved to ./category/tuning_timesteps.json
Tuning data for dropout_rate saved to ./category/tuning_dropout.json
Tuning data for l2_decay saved to ./category/tuning_l2.json
Tuning data for eps saved to ./category/tuning_eps.json

========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 1.1314; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.8377; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.6924; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.5829; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.4943; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.4179; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.3625; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.3160; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.2823; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.2503; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.539735   0.391688   0.814570   0.478991  
Loss: 0.3444
Fold 3 Epoch 011; Train loss: 0.2262; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.2109; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.1906; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.1804; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.1676; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.1633; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.1525; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.1460; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.1393; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.1312; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.485099   0.314660   0.665563   0.372355  
Loss: 0.1744
Fold 3 Epoch 021; Train loss: 0.1238; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.1197; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.1184; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.1116; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.1089; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.1021; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0978; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0958; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0925; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0888; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.561258   0.422366   0.773179   0.490834  
Loss: 0.1207
Fold 3 Epoch 031; Train loss: 0.0863; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0818; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0755; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0727; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0692; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0671; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0627; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0590; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0565; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0546; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.581126   0.419796   0.769868   0.479194  
Loss: 0.0738
Fold 3 Epoch 041; Train loss: 0.0503; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0466; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0445; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0408; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0385; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0352; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0316; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0285; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0268; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0239; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.577815   0.401124   0.885762   0.503448  
Loss: 0.0340
Fold 3 Epoch 051; Train loss: 0.0218; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0189; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0165; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0143; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0125; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0107; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0090; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0071; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0054; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0040; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.531457   0.292507   0.882450   0.411074  
Loss: 0.0073
Fold 3 Epoch 061; Train loss: 0.0029; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0020; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0013; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0009; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0006; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0005; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0003; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.062914   0.031854   0.403974   0.135591  
Loss: 0.0003
Fold 3 Epoch 071; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.298013   0.120483   0.584437   0.205796  
Loss: 0.0002
Fold 3 Epoch 081; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.302980   0.150286   0.913907   0.349993  
Loss: 0.0002
Fold 3 Epoch 091; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.092715   0.058502   0.660596   0.241220  
Loss: 0.0001
Tuning fold metrics saved to ./category/fold_metrics_tune.txt
Best candidates saved to ./category/best_candidates.json

========== Running Experimental Folds for Genre Model ==========

========== Experiment p1 ==========
Experiment p1 Epoch 001; Train loss: 1.0471; Time: 00:00:00
Experiment p1 Epoch 002; Train loss: 0.8434; Time: 00:00:00
Experiment p1 Epoch 003; Train loss: 0.7165; Time: 00:00:00
Experiment p1 Epoch 004; Train loss: 0.6275; Time: 00:00:00
Experiment p1 Epoch 005; Train loss: 0.5471; Time: 00:00:00
Experiment p1 Epoch 006; Train loss: 0.4839; Time: 00:00:00
Experiment p1 Epoch 007; Train loss: 0.4275; Time: 00:00:00
Experiment p1 Epoch 008; Train loss: 0.3826; Time: 00:00:00
Experiment p1 Epoch 009; Train loss: 0.3421; Time: 00:00:00
Experiment p1 Epoch 010; Train loss: 0.3062; Time: 00:00:00
Experiment p1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.484272   0.382355   0.702815   0.453018  
Loss: 0.4225
Experiment p1 Epoch 011; Train loss: 0.2816; Time: 00:00:00
Experiment p1 Epoch 012; Train loss: 0.2541; Time: 00:00:00
Experiment p1 Epoch 013; Train loss: 0.2384; Time: 00:00:00
Experiment p1 Epoch 014; Train loss: 0.2206; Time: 00:00:00
Experiment p1 Epoch 015; Train loss: 0.2044; Time: 00:00:00
Experiment p1 Epoch 016; Train loss: 0.1940; Time: 00:00:00
Experiment p1 Epoch 017; Train loss: 0.1886; Time: 00:00:00
Experiment p1 Epoch 018; Train loss: 0.1786; Time: 00:00:00
Experiment p1 Epoch 019; Train loss: 0.1703; Time: 00:00:00
Experiment p1 Epoch 020; Train loss: 0.1601; Time: 00:00:00
Experiment p1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.451987   0.370357   0.619205   0.423578  
Loss: 0.2021
Experiment p1 Epoch 021; Train loss: 0.1558; Time: 00:00:00
Experiment p1 Epoch 022; Train loss: 0.1519; Time: 00:00:00
Experiment p1 Epoch 023; Train loss: 0.1441; Time: 00:00:00
Experiment p1 Epoch 024; Train loss: 0.1382; Time: 00:00:00
Experiment p1 Epoch 025; Train loss: 0.1359; Time: 00:00:00
Experiment p1 Epoch 026; Train loss: 0.1337; Time: 00:00:00
Experiment p1 Epoch 027; Train loss: 0.1277; Time: 00:00:00
Experiment p1 Epoch 028; Train loss: 0.1217; Time: 00:00:00
Experiment p1 Epoch 029; Train loss: 0.1171; Time: 00:00:00
Experiment p1 Epoch 030; Train loss: 0.1171; Time: 00:00:00
Experiment p1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.471026   0.405129   0.596854   0.444985  
Loss: 0.1380
Experiment p1 Epoch 031; Train loss: 0.1114; Time: 00:00:00
Experiment p1 Epoch 032; Train loss: 0.1093; Time: 00:00:00
Experiment p1 Epoch 033; Train loss: 0.1053; Time: 00:00:00
Experiment p1 Epoch 034; Train loss: 0.1044; Time: 00:00:00
Experiment p1 Epoch 035; Train loss: 0.0981; Time: 00:00:00
Experiment p1 Epoch 036; Train loss: 0.0972; Time: 00:00:00
Experiment p1 Epoch 037; Train loss: 0.0922; Time: 00:00:00
Experiment p1 Epoch 038; Train loss: 0.0914; Time: 00:00:00
Experiment p1 Epoch 039; Train loss: 0.0871; Time: 00:00:00
Experiment p1 Epoch 040; Train loss: 0.0820; Time: 00:00:00
Experiment p1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.489238   0.389053   0.667219   0.445501  
Loss: 0.1009
Experiment p1 Epoch 041; Train loss: 0.0815; Time: 00:00:00
Experiment p1 Epoch 042; Train loss: 0.0779; Time: 00:00:00
Experiment p1 Epoch 043; Train loss: 0.0749; Time: 00:00:00
Experiment p1 Epoch 044; Train loss: 0.0738; Time: 00:00:00
Experiment p1 Epoch 045; Train loss: 0.0707; Time: 00:00:00
Experiment p1 Epoch 046; Train loss: 0.0660; Time: 00:00:00
Experiment p1 Epoch 047; Train loss: 0.0644; Time: 00:00:00
Experiment p1 Epoch 048; Train loss: 0.0608; Time: 00:00:00
Experiment p1 Epoch 049; Train loss: 0.0573; Time: 00:00:00
Experiment p1 Epoch 050; Train loss: 0.0553; Time: 00:00:00
Experiment p1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.495861   0.378116   0.639901   0.424461  
Loss: 0.0647
Experiment p1 Epoch 051; Train loss: 0.0542; Time: 00:00:00
Experiment p1 Epoch 052; Train loss: 0.0496; Time: 00:00:00
Experiment p1 Epoch 053; Train loss: 0.0490; Time: 00:00:00
Experiment p1 Epoch 054; Train loss: 0.0462; Time: 00:00:00
Experiment p1 Epoch 055; Train loss: 0.0422; Time: 00:00:00
Experiment p1 Epoch 056; Train loss: 0.0410; Time: 00:00:00
Experiment p1 Epoch 057; Train loss: 0.0385; Time: 00:00:00
Experiment p1 Epoch 058; Train loss: 0.0353; Time: 00:00:00
Experiment p1 Epoch 059; Train loss: 0.0337; Time: 00:00:00
Experiment p1 Epoch 060; Train loss: 0.0312; Time: 00:00:00
Experiment p1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.496689   0.363051   0.682119   0.421489  
Loss: 0.0323
Experiment p1 Epoch 061; Train loss: 0.0284; Time: 00:00:00
Experiment p1 Epoch 062; Train loss: 0.0266; Time: 00:00:00
Experiment p1 Epoch 063; Train loss: 0.0237; Time: 00:00:00
Experiment p1 Epoch 064; Train loss: 0.0220; Time: 00:00:00
Experiment p1 Epoch 065; Train loss: 0.0199; Time: 00:00:00
Experiment p1 Epoch 066; Train loss: 0.0174; Time: 00:00:00
Experiment p1 Epoch 067; Train loss: 0.0160; Time: 00:00:00
Experiment p1 Epoch 068; Train loss: 0.0138; Time: 00:00:00
Experiment p1 Epoch 069; Train loss: 0.0118; Time: 00:00:00
Experiment p1 Epoch 070; Train loss: 0.0098; Time: 00:00:00
Experiment p1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.565397   0.395631   0.881623   0.495688  
Loss: 0.0095
Experiment p1 Epoch 071; Train loss: 0.0081; Time: 00:00:00
Experiment p1 Epoch 072; Train loss: 0.0066; Time: 00:00:00
Experiment p1 Epoch 073; Train loss: 0.0050; Time: 00:00:00
Experiment p1 Epoch 074; Train loss: 0.0038; Time: 00:00:00
Experiment p1 Epoch 075; Train loss: 0.0027; Time: 00:00:00
Experiment p1 Epoch 076; Train loss: 0.0018; Time: 00:00:00
Experiment p1 Epoch 077; Train loss: 0.0011; Time: 00:00:00
Experiment p1 Epoch 078; Train loss: 0.0007; Time: 00:00:00
Experiment p1 Epoch 079; Train loss: 0.0005; Time: 00:00:00
Experiment p1 Epoch 080; Train loss: 0.0004; Time: 00:00:00
Experiment p1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.302152   0.124932   0.505795   0.186783  
Loss: 0.0003
Experiment p1 Epoch 081; Train loss: 0.0003; Time: 00:00:00
Experiment p1 Epoch 082; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 083; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 084; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 085; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 086; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 087; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 088; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 089; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 090; Train loss: 0.0002; Time: 00:00:00
Experiment p1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.332781   0.137662   0.408940   0.161238  
Loss: 0.0002
Experiment p1 Epoch 091; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 092; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 093; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 095; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 097; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 098; Train loss: 0.0001; Time: 00:00:00
Experiment p1 Epoch 099; Train loss: 0.0002; Time: 00:00:00
Experiment p1 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Experiment p1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.035596   0.016822   0.365894   0.118384  
Loss: 0.0002

========== Experiment p2 ==========
Experiment p2 Epoch 001; Train loss: 1.0143; Time: 00:00:00
Experiment p2 Epoch 002; Train loss: 0.8200; Time: 00:00:00
Experiment p2 Epoch 003; Train loss: 0.6989; Time: 00:00:00
Experiment p2 Epoch 004; Train loss: 0.6208; Time: 00:00:00
Experiment p2 Epoch 005; Train loss: 0.5446; Time: 00:00:00
Experiment p2 Epoch 006; Train loss: 0.4765; Time: 00:00:00
Experiment p2 Epoch 007; Train loss: 0.4232; Time: 00:00:00
Experiment p2 Epoch 008; Train loss: 0.3724; Time: 00:00:00
Experiment p2 Epoch 009; Train loss: 0.3355; Time: 00:00:00
Experiment p2 Epoch 010; Train loss: 0.3024; Time: 00:00:00
Experiment p2: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.487583   0.361853   0.668874   0.419663  
Loss: 0.4320
Experiment p2 Epoch 011; Train loss: 0.2773; Time: 00:00:00
Experiment p2 Epoch 012; Train loss: 0.2520; Time: 00:00:00
Experiment p2 Epoch 013; Train loss: 0.2329; Time: 00:00:00
Experiment p2 Epoch 014; Train loss: 0.2193; Time: 00:00:00
Experiment p2 Epoch 015; Train loss: 0.2063; Time: 00:00:00
Experiment p2 Epoch 016; Train loss: 0.1945; Time: 00:00:00
Experiment p2 Epoch 017; Train loss: 0.1846; Time: 00:00:00
Experiment p2 Epoch 018; Train loss: 0.1763; Time: 00:00:00
Experiment p2 Epoch 019; Train loss: 0.1689; Time: 00:00:00
Experiment p2 Epoch 020; Train loss: 0.1620; Time: 00:00:00
Experiment p2: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.596026   0.382360   0.737583   0.426722  
Loss: 0.2269
Experiment p2 Epoch 021; Train loss: 0.1547; Time: 00:00:00
Experiment p2 Epoch 022; Train loss: 0.1477; Time: 00:00:00
Experiment p2 Epoch 023; Train loss: 0.1440; Time: 00:00:00
Experiment p2 Epoch 024; Train loss: 0.1413; Time: 00:00:00
Experiment p2 Epoch 025; Train loss: 0.1331; Time: 00:00:00
Experiment p2 Epoch 026; Train loss: 0.1314; Time: 00:00:00
Experiment p2 Epoch 027; Train loss: 0.1270; Time: 00:00:00
Experiment p2 Epoch 028; Train loss: 0.1208; Time: 00:00:00
Experiment p2 Epoch 029; Train loss: 0.1196; Time: 00:00:00
Experiment p2 Epoch 030; Train loss: 0.1164; Time: 00:00:00
Experiment p2: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.534768   0.382464   0.664735   0.424147  
Loss: 0.1558
Experiment p2 Epoch 031; Train loss: 0.1147; Time: 00:00:00
Experiment p2 Epoch 032; Train loss: 0.1114; Time: 00:00:00
Experiment p2 Epoch 033; Train loss: 0.1040; Time: 00:00:00
Experiment p2 Epoch 034; Train loss: 0.1020; Time: 00:00:00
Experiment p2 Epoch 035; Train loss: 0.1013; Time: 00:00:00
Experiment p2 Epoch 036; Train loss: 0.0977; Time: 00:00:00
Experiment p2 Epoch 037; Train loss: 0.0933; Time: 00:00:00
Experiment p2 Epoch 038; Train loss: 0.0908; Time: 00:00:00
Experiment p2 Epoch 039; Train loss: 0.0886; Time: 00:00:00
Experiment p2 Epoch 040; Train loss: 0.0853; Time: 00:00:00
Experiment p2: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.579470   0.393561   0.703642   0.433370  
Loss: 0.1051
Experiment p2 Epoch 041; Train loss: 0.0850; Time: 00:00:00
Experiment p2 Epoch 042; Train loss: 0.0781; Time: 00:00:00
Experiment p2 Epoch 043; Train loss: 0.0780; Time: 00:00:00
Experiment p2 Epoch 044; Train loss: 0.0731; Time: 00:00:00
Experiment p2 Epoch 045; Train loss: 0.0690; Time: 00:00:00
Experiment p2 Epoch 046; Train loss: 0.0681; Time: 00:00:00
Experiment p2 Epoch 047; Train loss: 0.0659; Time: 00:00:00
Experiment p2 Epoch 048; Train loss: 0.0633; Time: 00:00:00
Experiment p2 Epoch 049; Train loss: 0.0597; Time: 00:00:00
Experiment p2 Epoch 050; Train loss: 0.0579; Time: 00:00:00
Experiment p2: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.586921   0.405142   0.706954   0.444638  
Loss: 0.0696
Experiment p2 Epoch 051; Train loss: 0.0544; Time: 00:00:00
Experiment p2 Epoch 052; Train loss: 0.0545; Time: 00:00:00
Experiment p2 Epoch 053; Train loss: 0.0492; Time: 00:00:00
Experiment p2 Epoch 054; Train loss: 0.0475; Time: 00:00:00
Experiment p2 Epoch 055; Train loss: 0.0447; Time: 00:00:00
Experiment p2 Epoch 056; Train loss: 0.0420; Time: 00:00:00
Experiment p2 Epoch 057; Train loss: 0.0398; Time: 00:00:00
Experiment p2 Epoch 058; Train loss: 0.0388; Time: 00:00:00
Experiment p2 Epoch 059; Train loss: 0.0354; Time: 00:00:00
Experiment p2 Epoch 060; Train loss: 0.0331; Time: 00:00:00
Experiment p2: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.565397   0.365394   0.746689   0.423232  
Loss: 0.0403
Experiment p2 Epoch 061; Train loss: 0.0306; Time: 00:00:00
Experiment p2 Epoch 062; Train loss: 0.0278; Time: 00:00:00
Experiment p2 Epoch 063; Train loss: 0.0264; Time: 00:00:00
Experiment p2 Epoch 064; Train loss: 0.0244; Time: 00:00:00
Experiment p2 Epoch 065; Train loss: 0.0216; Time: 00:00:00
Experiment p2 Epoch 066; Train loss: 0.0195; Time: 00:00:00
Experiment p2 Epoch 067; Train loss: 0.0174; Time: 00:00:00
Experiment p2 Epoch 068; Train loss: 0.0152; Time: 00:00:00
Experiment p2 Epoch 069; Train loss: 0.0136; Time: 00:00:00
Experiment p2 Epoch 070; Train loss: 0.0115; Time: 00:00:00
Experiment p2: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.589404   0.299826   0.859272   0.387916  
Loss: 0.0129
Experiment p2 Epoch 071; Train loss: 0.0100; Time: 00:00:00
Experiment p2 Epoch 072; Train loss: 0.0081; Time: 00:00:00
Experiment p2 Epoch 073; Train loss: 0.0067; Time: 00:00:00
Experiment p2 Epoch 074; Train loss: 0.0054; Time: 00:00:00
Experiment p2 Epoch 075; Train loss: 0.0044; Time: 00:00:00
Experiment p2 Epoch 076; Train loss: 0.0032; Time: 00:00:00
Experiment p2 Epoch 077; Train loss: 0.0026; Time: 00:00:00
Experiment p2 Epoch 078; Train loss: 0.0018; Time: 00:00:00
Experiment p2 Epoch 079; Train loss: 0.0014; Time: 00:00:00
Experiment p2 Epoch 080; Train loss: 0.0010; Time: 00:00:00
Experiment p2: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.057947   0.030348   0.824503   0.282106  
Loss: 0.0012
Experiment p2 Epoch 081; Train loss: 0.0008; Time: 00:00:00
Experiment p2 Epoch 082; Train loss: 0.0005; Time: 00:00:00
Experiment p2 Epoch 083; Train loss: 0.0006; Time: 00:00:00
Experiment p2 Epoch 084; Train loss: 0.0004; Time: 00:00:00
Experiment p2 Epoch 085; Train loss: 0.0005; Time: 00:00:00
Experiment p2 Epoch 086; Train loss: 0.0004; Time: 00:00:00
Experiment p2 Epoch 087; Train loss: 0.0005; Time: 00:00:00
Experiment p2 Epoch 088; Train loss: 0.0003; Time: 00:00:00
Experiment p2 Epoch 089; Train loss: 0.0004; Time: 00:00:00
Experiment p2 Epoch 090; Train loss: 0.0003; Time: 00:00:00
Experiment p2: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.124172   0.062111   0.471854   0.168152  
Loss: 0.0005
Experiment p2 Epoch 091; Train loss: 0.0003; Time: 00:00:00
Experiment p2 Epoch 092; Train loss: 0.0003; Time: 00:00:00
Experiment p2 Epoch 093; Train loss: 0.0002; Time: 00:00:00
Experiment p2 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Experiment p2 Epoch 095; Train loss: 0.0003; Time: 00:00:00
Experiment p2 Epoch 096; Train loss: 0.0003; Time: 00:00:00
Experiment p2 Epoch 097; Train loss: 0.0004; Time: 00:00:00
Experiment p2 Epoch 098; Train loss: 0.0003; Time: 00:00:00
Experiment p2 Epoch 099; Train loss: 0.0003; Time: 00:00:00
Experiment p2 Epoch 100; Train loss: 0.0003; Time: 00:00:00
Experiment p2: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.374172   0.169512   0.479305   0.203183  
Loss: 0.0002
Experimental fold metrics saved to category/genre_exp_p1_metrics.txt and category/genre_exp_p2_metrics.txt

========== Running Experimental Fold p3 for Genre Model ==========

========== Experiment p3 ==========
Experiment p3 Epoch 001; Train loss: 0.9841; Time: 00:00:01
Experiment p3 Epoch 002; Train loss: 0.7819; Time: 00:00:01
Experiment p3 Epoch 003; Train loss: 0.6711; Time: 00:00:01
Experiment p3 Epoch 004; Train loss: 0.5841; Time: 00:00:01
Experiment p3 Epoch 005; Train loss: 0.5110; Time: 00:00:01
Experiment p3 Epoch 006; Train loss: 0.4488; Time: 00:00:01
Experiment p3 Epoch 007; Train loss: 0.3977; Time: 00:00:01
Experiment p3 Epoch 008; Train loss: 0.3549; Time: 00:00:01
Experiment p3 Epoch 009; Train loss: 0.3152; Time: 00:00:01
Experiment p3 Epoch 010; Train loss: 0.2841; Time: 00:00:01
Experiment p3: Validation Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.591060   0.436647   0.736755   0.482722  
Loss: 0.4463
Experiment p3 Epoch 011; Train loss: 0.2619; Time: 00:00:01
Experiment p3 Epoch 012; Train loss: 0.2379; Time: 00:00:01
Experiment p3 Epoch 013; Train loss: 0.2198; Time: 00:00:01
Experiment p3 Epoch 014; Train loss: 0.2056; Time: 00:00:01
Experiment p3 Epoch 015; Train loss: 0.1950; Time: 00:00:01
Experiment p3 Epoch 016; Train loss: 0.1804; Time: 00:00:01
Experiment p3 Epoch 017; Train loss: 0.1745; Time: 00:00:01
Experiment p3 Epoch 018; Train loss: 0.1646; Time: 00:00:01
Experiment p3 Epoch 019; Train loss: 0.1564; Time: 00:00:01
Experiment p3 Epoch 020; Train loss: 0.1515; Time: 00:00:01
Experiment p3: Validation Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.531457   0.411734   0.718543   0.471488  
Loss: 0.2001
Experiment p3 Epoch 021; Train loss: 0.1458; Time: 00:00:01
Experiment p3 Epoch 022; Train loss: 0.1410; Time: 00:00:01
Experiment p3 Epoch 023; Train loss: 0.1367; Time: 00:00:01
Experiment p3 Epoch 024; Train loss: 0.1293; Time: 00:00:01
Experiment p3 Epoch 025; Train loss: 0.1258; Time: 00:00:01
Experiment p3 Epoch 026; Train loss: 0.1219; Time: 00:00:01
Experiment p3 Epoch 027; Train loss: 0.1157; Time: 00:00:01
Experiment p3 Epoch 028; Train loss: 0.1144; Time: 00:00:01
Experiment p3 Epoch 029; Train loss: 0.1143; Time: 00:00:01
Experiment p3 Epoch 030; Train loss: 0.1058; Time: 00:00:01
Experiment p3: Validation Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.597682   0.451857   0.766556   0.505879  
Loss: 0.1470
Experiment p3 Epoch 031; Train loss: 0.1045; Time: 00:00:01
Experiment p3 Epoch 032; Train loss: 0.0995; Time: 00:00:01
Experiment p3 Epoch 033; Train loss: 0.0966; Time: 00:00:01
Experiment p3 Epoch 034; Train loss: 0.0948; Time: 00:00:01
Experiment p3 Epoch 035; Train loss: 0.0943; Time: 00:00:01
Experiment p3 Epoch 036; Train loss: 0.0906; Time: 00:00:01
Experiment p3 Epoch 037; Train loss: 0.0852; Time: 00:00:01
Experiment p3 Epoch 038; Train loss: 0.0840; Time: 00:00:01
Experiment p3 Epoch 039; Train loss: 0.0806; Time: 00:00:01
Experiment p3 Epoch 040; Train loss: 0.0789; Time: 00:00:01
Experiment p3: Validation Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.581126   0.443382   0.731788   0.491606  
Loss: 0.1084
Experiment p3 Epoch 041; Train loss: 0.0751; Time: 00:00:01
Experiment p3 Epoch 042; Train loss: 0.0733; Time: 00:00:01
Experiment p3 Epoch 043; Train loss: 0.0692; Time: 00:00:01
Experiment p3 Epoch 044; Train loss: 0.0663; Time: 00:00:01
Experiment p3 Epoch 045; Train loss: 0.0643; Time: 00:00:01
Experiment p3 Epoch 046; Train loss: 0.0613; Time: 00:00:01
Experiment p3 Epoch 047; Train loss: 0.0587; Time: 00:00:01
Experiment p3 Epoch 048; Train loss: 0.0559; Time: 00:00:01
Experiment p3 Epoch 049; Train loss: 0.0539; Time: 00:00:01
Experiment p3 Epoch 050; Train loss: 0.0510; Time: 00:00:01
Experiment p3: Validation Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.625828   0.447894   0.798013   0.502975  
Loss: 0.0687
Experiment p3 Epoch 051; Train loss: 0.0484; Time: 00:00:01
Experiment p3 Epoch 052; Train loss: 0.0456; Time: 00:00:01
Experiment p3 Epoch 053; Train loss: 0.0414; Time: 00:00:01
Experiment p3 Epoch 054; Train loss: 0.0399; Time: 00:00:01
Experiment p3 Epoch 055; Train loss: 0.0375; Time: 00:00:01
Experiment p3 Epoch 056; Train loss: 0.0357; Time: 00:00:01
Experiment p3 Epoch 057; Train loss: 0.0332; Time: 00:00:01
Experiment p3 Epoch 058; Train loss: 0.0312; Time: 00:00:01
Experiment p3 Epoch 059; Train loss: 0.0283; Time: 00:00:01
Experiment p3 Epoch 060; Train loss: 0.0260; Time: 00:00:01
Experiment p3: Validation Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.647351   0.449909   0.779801   0.493090  
Loss: 0.0360
Experiment p3 Epoch 061; Train loss: 0.0241; Time: 00:00:01
Experiment p3 Epoch 062; Train loss: 0.0219; Time: 00:00:01
Experiment p3 Epoch 063; Train loss: 0.0195; Time: 00:00:01
Experiment p3 Epoch 064; Train loss: 0.0178; Time: 00:00:01
Experiment p3 Epoch 065; Train loss: 0.0153; Time: 00:00:01
Experiment p3 Epoch 066; Train loss: 0.0131; Time: 00:00:01
Experiment p3 Epoch 067; Train loss: 0.0113; Time: 00:00:01
Experiment p3 Epoch 068; Train loss: 0.0095; Time: 00:00:01
Experiment p3 Epoch 069; Train loss: 0.0078; Time: 00:00:01
Experiment p3 Epoch 070; Train loss: 0.0063; Time: 00:00:01
Experiment p3: Validation Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.614238   0.354397   0.761589   0.400477  
Loss: 0.0098
Experiment p3 Epoch 071; Train loss: 0.0049; Time: 00:00:01
Experiment p3 Epoch 072; Train loss: 0.0039; Time: 00:00:01
Experiment p3 Epoch 073; Train loss: 0.0030; Time: 00:00:01
Experiment p3 Epoch 074; Train loss: 0.0023; Time: 00:00:01
Experiment p3 Epoch 075; Train loss: 0.0017; Time: 00:00:01
Experiment p3 Epoch 076; Train loss: 0.0013; Time: 00:00:01
Experiment p3 Epoch 077; Train loss: 0.0009; Time: 00:00:01
Experiment p3 Epoch 078; Train loss: 0.0007; Time: 00:00:01
Experiment p3 Epoch 079; Train loss: 0.0005; Time: 00:00:01
Experiment p3 Epoch 080; Train loss: 0.0003; Time: 00:00:01
Experiment p3: Validation Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.370861   0.182582   0.582781   0.245135  
Loss: 0.0003
Experiment p3 Epoch 081; Train loss: 0.0002; Time: 00:00:01
Experiment p3 Epoch 082; Train loss: 0.0002; Time: 00:00:01
Experiment p3 Epoch 083; Train loss: 0.0002; Time: 00:00:01
Experiment p3 Epoch 084; Train loss: 0.0002; Time: 00:00:01
Experiment p3 Epoch 085; Train loss: 0.0002; Time: 00:00:01
Experiment p3 Epoch 086; Train loss: 0.0002; Time: 00:00:01
Experiment p3 Epoch 087; Train loss: 0.0001; Time: 00:00:01
Experiment p3 Epoch 088; Train loss: 0.0002; Time: 00:00:01
Experiment p3 Epoch 089; Train loss: 0.0001; Time: 00:00:01
Experiment p3 Epoch 090; Train loss: 0.0002; Time: 00:00:01
Experiment p3: Validation Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.230132   0.105009   0.577815   0.216566  
Loss: 0.0001
Experiment p3 Epoch 091; Train loss: 0.0001; Time: 00:00:01
Experiment p3 Epoch 092; Train loss: 0.0002; Time: 00:00:01
Experiment p3 Epoch 093; Train loss: 0.0001; Time: 00:00:01
Experiment p3 Epoch 094; Train loss: 0.0001; Time: 00:00:01
Experiment p3 Epoch 095; Train loss: 0.0001; Time: 00:00:01
Experiment p3 Epoch 096; Train loss: 0.0001; Time: 00:00:01
Experiment p3 Epoch 097; Train loss: 0.0001; Time: 00:00:01
Experiment p3 Epoch 098; Train loss: 0.0001; Time: 00:00:01
Experiment p3 Epoch 099; Train loss: 0.0001; Time: 00:00:01
Experiment p3 Epoch 100; Train loss: 0.0001; Time: 00:00:01
Experiment p3: Validation Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.079470   0.045807   0.311258   0.126515  
Loss: 0.0001
Final Evaluation on p3 test set:
HR@5       NDCG@5     HR@10      NDCG@10   
0.288079   0.176796   0.384106   0.207219  
Loss: 0.0001
Experimental fold metrics saved to category/genre_exp_p3_metrics.txt
Tuning lr:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 53.3455; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.7644; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.3038; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.2507; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.2123; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.1857; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.1585; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.1412; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.1224; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.1111; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.362583   0.262551   0.683775   0.364848  
Loss: 0.1200
Fold 3 Epoch 011; Train loss: 0.0993; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0912; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0837; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0801; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0739; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0702; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0667; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0631; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0607; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0610; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.399007   0.289719   0.632450   0.365714  
Loss: 0.0725
Fold 3 Epoch 021; Train loss: 0.0586; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0628; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0570; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0518; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0510; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0490; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0468; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0460; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0447; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.314570   0.196349   0.528146   0.263919  
Loss: 0.0585
Fold 3 Epoch 031; Train loss: 0.0451; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0454; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0477; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0516; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0475; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0432; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0423; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0392; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0396; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0396; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.329470   0.223625   0.519868   0.283636  
Loss: 0.0489
Fold 3 Epoch 041; Train loss: 0.0384; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0376; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0365; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0355; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0350; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0359; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0361; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0409; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0466; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0390; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.321192   0.211398   0.407285   0.239382  
Loss: 0.0492
Fold 3 Epoch 051; Train loss: 0.0339; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0323; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0305; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0294; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0303; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0290; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0285; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0280; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0269; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0266; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.352649   0.303415   0.584437   0.377999  
Loss: 0.0363
Fold 3 Epoch 061; Train loss: 0.0276; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0253; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0263; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0249; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0254; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0257; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0285; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0276; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0271; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0255; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.354305   0.245958   0.549669   0.307818  
Loss: 0.0248
Fold 3 Epoch 071; Train loss: 0.0229; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0220; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0220; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0213; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0208; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0207; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0197; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0203; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0194; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0198; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.360927   0.271893   0.529801   0.326331  
Loss: 0.0224
Fold 3 Epoch 081; Train loss: 0.0193; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0186; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0183; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0185; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0185; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0195; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0242; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0238; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0191; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0177; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.296358   0.228858   0.438742   0.274540  
Loss: 0.0168
Fold 3 Epoch 091; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0165; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0167; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0162; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0148; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0151; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0154; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0153; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0148; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.599338   0.422317   0.690397   0.451522  
Loss: 0.0195
[lr candidate 0.05] Fold 3: loss = [np.float64(0.11995784193277359), np.float64(0.07250799238681793), np.float64(0.058483757078647614), np.float64(0.04891933500766754), np.float64(0.04919802397489548), np.float64(0.03630226477980614), np.float64(0.02478320151567459), np.float64(0.02241729572415352), np.float64(0.016756927594542503), np.float64(0.019492756575345993)]
Tuning lr:  25%|██▌       | 1/4 [01:29<04:28, 89.55s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.6668; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2270; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1519; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1159; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.1009; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0946; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0906; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0830; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0818; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0779; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.614238   0.410479   0.774834   0.462108  
Loss: 0.0991
Fold 3 Epoch 011; Train loss: 0.0769; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0759; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0733; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0716; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0691; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0664; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0685; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0628; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0628; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0632; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.531457   0.351225   0.705298   0.407466  
Loss: 0.0748
Fold 3 Epoch 021; Train loss: 0.0614; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0607; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0592; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0571; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0575; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0559; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0542; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0522; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0534; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0514; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.597682   0.454950   0.710265   0.492063  
Loss: 0.0610
Fold 3 Epoch 031; Train loss: 0.0515; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0494; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0477; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0481; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0457; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0455; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0444; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0433; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0422; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0410; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.445364   0.337134   0.567881   0.376266  
Loss: 0.0510
Fold 3 Epoch 041; Train loss: 0.0395; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0396; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0372; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0366; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0361; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0349; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0341; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0331; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0320; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0311; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.485099   0.360223   0.605960   0.399302  
Loss: 0.0344
Fold 3 Epoch 051; Train loss: 0.0302; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0283; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0276; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0269; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0263; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0249; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0255; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0248; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0238; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0237; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.552980   0.383514   0.673841   0.423018  
Loss: 0.0250
Fold 3 Epoch 061; Train loss: 0.0225; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0219; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0215; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0210; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0197; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0199; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0200; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0202; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0190; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0185; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.513245   0.361303   0.649007   0.405161  
Loss: 0.0189
Fold 3 Epoch 071; Train loss: 0.0184; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0183; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0180; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0184; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0174; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0176; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0170; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0167; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.414351   0.637417   0.450696  
Loss: 0.0156
Fold 3 Epoch 081; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0160; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0161; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0150; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0156; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0152; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0154; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0149; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0139; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.514901   0.351893   0.652318   0.396474  
Loss: 0.0135
Fold 3 Epoch 091; Train loss: 0.0136; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0129; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0127; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0127; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0119; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0115; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0107; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0109; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0098; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.511589   0.317161   0.784768   0.404445  
Loss: 0.0091
[lr candidate 0.01] Fold 3: loss = [np.float64(0.09910187870264053), np.float64(0.07477156072854996), np.float64(0.06098494678735733), np.float64(0.050964001566171646), np.float64(0.034426722675561905), np.float64(0.024991275742650032), np.float64(0.01890677399933338), np.float64(0.01563570462167263), np.float64(0.013466347008943558), np.float64(0.009144144132733345)]
Tuning lr:  50%|█████     | 2/4 [02:58<02:58, 89.15s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.7855; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.3544; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.2256; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1655; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.1315; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.1126; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.1026; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0977; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0942; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0886; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.649007   0.490190   0.763245   0.526907  
Loss: 0.1221
Fold 3 Epoch 011; Train loss: 0.0854; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0822; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0809; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0790; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0782; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0742; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0741; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0728; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0725; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0710; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.493377   0.372464   0.644040   0.420438  
Loss: 0.0962
Fold 3 Epoch 021; Train loss: 0.0690; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0683; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0682; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0674; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0666; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0654; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0634; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0636; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0623; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.591060   0.467486   0.756623   0.520962  
Loss: 0.0812
Fold 3 Epoch 031; Train loss: 0.0616; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0608; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0621; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0622; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0593; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0593; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0588; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0583; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0567; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0573; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.607616   0.463659   0.768212   0.516083  
Loss: 0.0721
Fold 3 Epoch 041; Train loss: 0.0566; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0563; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0577; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0549; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0544; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0537; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0532; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0519; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0521; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0510; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.619205   0.484605   0.774834   0.535020  
Loss: 0.0648
Fold 3 Epoch 051; Train loss: 0.0517; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0509; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0492; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0491; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0490; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0479; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0475; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0467; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0464; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0448; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.526490   0.421897   0.653974   0.462845  
Loss: 0.0533
Fold 3 Epoch 061; Train loss: 0.0466; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0451; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0446; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0451; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0438; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0433; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0426; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0422; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0418; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0405; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.544702   0.368859   0.693709   0.417584  
Loss: 0.0531
Fold 3 Epoch 071; Train loss: 0.0418; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0401; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0408; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0394; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0387; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0380; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0375; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0372; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0367; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0352; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.476821   0.355594   0.619205   0.402035  
Loss: 0.0464
Fold 3 Epoch 081; Train loss: 0.0351; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0345; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0344; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0340; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0348; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0335; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0330; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0318; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0320; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0313; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.634106   0.482442   0.758278   0.522657  
Loss: 0.0391
Fold 3 Epoch 091; Train loss: 0.0313; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0311; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0316; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0306; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0307; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0291; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0294; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0284; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0289; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0282; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.584437   0.439848   0.745033   0.491606  
Loss: 0.0352
[lr candidate 0.005] Fold 3: loss = [np.float64(0.12205846607685089), np.float64(0.09624721109867096), np.float64(0.08115662634372711), np.float64(0.07205230742692947), np.float64(0.06483150273561478), np.float64(0.05325639620423317), np.float64(0.05310078337788582), np.float64(0.04643130302429199), np.float64(0.039068400859832764), np.float64(0.03524244949221611)]
Tuning lr:  75%|███████▌  | 3/4 [04:27<01:29, 89.14s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 1.0811; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.7940; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.6209; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.5226; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.4421; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.3818; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.3359; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.2949; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.2653; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.2401; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.758278   0.596220   0.834437   0.620963  
Loss: 0.3897
Fold 3 Epoch 011; Train loss: 0.2223; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.2018; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.1889; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.1763; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.1652; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.1552; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.1485; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.1439; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.1377; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.1314; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.726821   0.580559   0.816225   0.609545  
Loss: 0.2140
Fold 3 Epoch 021; Train loss: 0.1287; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.1236; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.1220; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.1167; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.1140; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.1105; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.1091; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.1075; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.1053; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.1047; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.703642   0.565010   0.794702   0.594127  
Loss: 0.1602
Fold 3 Epoch 031; Train loss: 0.1002; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.1009; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0990; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0976; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0972; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0967; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0956; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0933; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0941; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0905; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.701987   0.570176   0.786424   0.597349  
Loss: 0.1345
Fold 3 Epoch 041; Train loss: 0.0905; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0878; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0891; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0891; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0877; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0848; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0857; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0836; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0829; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0830; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.751656   0.596690   0.826159   0.620601  
Loss: 0.1237
Fold 3 Epoch 051; Train loss: 0.0833; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0832; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0829; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0812; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0821; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0809; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0803; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0794; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0801; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0793; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.678808   0.534506   0.771523   0.564359  
Loss: 0.1133
Fold 3 Epoch 061; Train loss: 0.0774; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0772; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0784; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0789; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0772; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0757; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0762; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0754; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0748; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0762; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.612583   0.463471   0.758278   0.510216  
Loss: 0.1094
Fold 3 Epoch 071; Train loss: 0.0746; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0749; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0753; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0761; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0742; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0736; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0732; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0718; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0748; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0732; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.733444   0.579628   0.819536   0.607186  
Loss: 0.1002
Fold 3 Epoch 081; Train loss: 0.0735; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0719; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0711; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0717; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0717; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0701; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0709; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0716; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0717; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0705; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.708609   0.557797   0.786424   0.582583  
Loss: 0.0932
Fold 3 Epoch 091; Train loss: 0.0707; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0688; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0704; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0712; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0671; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0688; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0688; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0680; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0697; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0679; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.682119   0.530064   0.766556   0.557627  
Loss: 0.0962
[lr candidate 0.001] Fold 3: loss = [np.float64(0.3897291123867035), np.float64(0.2140294462442398), np.float64(0.16020627319812775), np.float64(0.13454125821590424), np.float64(0.12372612208127975), np.float64(0.11327983438968658), np.float64(0.1093505471944809), np.float64(0.10020139068365097), np.float64(0.09321650862693787), np.float64(0.09622456133365631)]
Tuning lr: 100%|██████████| 4/4 [05:56<00:00, 89.13s/it]Tuning lr: 100%|██████████| 4/4 [05:56<00:00, 89.16s/it]

Best learning rate found: 0.01
Tuning data for lr (loss) saved to ./category/tuning_lr.json
Tuning optimizer:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.6039; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2145; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1402; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1123; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.0995; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0917; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0810; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0786; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0750; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0723; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.501656   0.389069   0.687086   0.448412  
Loss: 0.0933
Fold 3 Epoch 011; Train loss: 0.0692; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0701; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0678; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0663; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0668; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0634; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0634; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0608; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0612; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0575; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.473510   0.336624   0.624172   0.385027  
Loss: 0.0681
Fold 3 Epoch 021; Train loss: 0.0568; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0561; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0556; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0527; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0535; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0519; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0508; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0493; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0485; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0478; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.604305   0.463912   0.738411   0.507082  
Loss: 0.0562
Fold 3 Epoch 031; Train loss: 0.0467; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0457; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0447; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0426; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0419; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0408; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0398; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0397; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0387; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0365; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.466887   0.321537   0.644040   0.378019  
Loss: 0.0409
Fold 3 Epoch 041; Train loss: 0.0355; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0347; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0337; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0338; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0327; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0313; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0297; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0295; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0289; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0283; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.511589   0.372715   0.692053   0.430830  
Loss: 0.0325
Fold 3 Epoch 051; Train loss: 0.0281; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0267; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0257; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0251; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0251; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0245; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0228; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0229; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0216; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0210; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.642384   0.474393   0.802980   0.526269  
Loss: 0.0238
Fold 3 Epoch 061; Train loss: 0.0212; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0206; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0198; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0188; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0181; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0176; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0174; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0171; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0170; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0156; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.677152   0.484612   0.832781   0.534680  
Loss: 0.0150
Fold 3 Epoch 071; Train loss: 0.0155; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0148; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0146; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0148; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0136; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0128; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0133; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0121; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0116; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.653974   0.451645   0.855960   0.516901  
Loss: 0.0109
Fold 3 Epoch 081; Train loss: 0.0112; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0108; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0104; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0098; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0095; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0092; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0092; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0087; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0086; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0082; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.645695   0.444242   0.827815   0.503155  
Loss: 0.0073
Fold 3 Epoch 091; Train loss: 0.0081; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0076; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0071; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0068; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0063; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0063; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0060; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0056; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0055; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0053; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.501656   0.313783   0.687086   0.372435  
Loss: 0.0056
[optimizer candidate nadam] Fold 3: loss = [np.float64(0.0932777151465416), np.float64(0.06806247681379318), np.float64(0.05620218813419342), np.float64(0.04093455150723457), np.float64(0.03247695416212082), np.float64(0.02377208136022091), np.float64(0.014951169490814209), np.float64(0.010882250033318996), np.float64(0.007275278214365244), np.float64(0.005628183484077454)]
Tuning optimizer:  25%|██▌       | 1/4 [01:29<04:28, 89.34s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.9766; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.7170; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.5687; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.4653; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.3760; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.3067; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.2511; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.2050; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.1738; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.1485; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.548013   0.442876   0.716887   0.497923  
Loss: 0.2282
Fold 3 Epoch 011; Train loss: 0.1275; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.1134; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.1012; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0935; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0837; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0780; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0727; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0693; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0644; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0645; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.617550   0.478693   0.769868   0.528192  
Loss: 0.0829
Fold 3 Epoch 021; Train loss: 0.0605; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0595; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0565; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0550; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0533; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0519; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0496; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0495; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0471; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0463; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.538079   0.420003   0.692053   0.468981  
Loss: 0.0616
Fold 3 Epoch 031; Train loss: 0.0447; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0426; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0430; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0417; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0402; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0390; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0390; Time: 00:00:01
Fold 3 Epoch 038; Train loss: 0.0365; Time: 00:00:01
Fold 3 Epoch 039; Train loss: 0.0362; Time: 00:00:01
Fold 3 Epoch 040; Train loss: 0.0356; Time: 00:00:01
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.612583   0.456559   0.759934   0.503832  
Loss: 0.0448
Fold 3 Epoch 041; Train loss: 0.0341; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0339; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0328; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0310; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0299; Time: 00:00:01
Fold 3 Epoch 046; Train loss: 0.0295; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0284; Time: 00:00:01
Fold 3 Epoch 048; Train loss: 0.0289; Time: 00:00:01
Fold 3 Epoch 049; Train loss: 0.0269; Time: 00:00:01
Fold 3 Epoch 050; Train loss: 0.0265; Time: 00:00:01
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.594371   0.443666   0.710265   0.481070  
Loss: 0.0325
Fold 3 Epoch 051; Train loss: 0.0258; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0255; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0245; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0235; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0226; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0222; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0212; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0199; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0198; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0189; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.493377   0.353710   0.632450   0.398298  
Loss: 0.0237
Fold 3 Epoch 061; Train loss: 0.0188; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0166; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0163; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0159; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0152; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0131; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0126; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0118; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0105; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.582781   0.320484   0.771523   0.381806  
Loss: 0.0102
Fold 3 Epoch 071; Train loss: 0.0101; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0095; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0080; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0073; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0066; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0062; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0055; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0048; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0046; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0044; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.508278   0.263746   0.822848   0.363371  
Loss: 0.0036
Fold 3 Epoch 081; Train loss: 0.0037; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0032; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0026; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0019; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0015; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0009; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0007; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0006; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0004; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0004; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.339404   0.158396   0.675497   0.257363  
Loss: 0.0005
Fold 3 Epoch 091; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0003; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0002; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0002; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.321192   0.174605   0.403974   0.200377  
Loss: 0.0001
[optimizer candidate lamb] Fold 3: loss = [np.float64(0.2281842827796936), np.float64(0.08294201642274857), np.float64(0.06156033277511597), np.float64(0.044840794056653976), np.float64(0.032511018216609955), np.float64(0.02374851517379284), np.float64(0.01018130499869585), np.float64(0.0035923272371292114), np.float64(0.00047976261703297496), np.float64(0.00013507036783266813)]
Tuning optimizer:  50%|█████     | 2/4 [03:01<03:02, 91.28s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.5271; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2108; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1440; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1131; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.0945; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0828; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0771; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0720; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0723; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0666; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.486755   0.368656   0.649007   0.420442  
Loss: 0.0935
Fold 3 Epoch 011; Train loss: 0.0660; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0639; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0623; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0622; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0603; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0613; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0604; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0571; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0578; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0569; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.503311   0.393270   0.640728   0.436771  
Loss: 0.0740
Fold 3 Epoch 021; Train loss: 0.0562; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0556; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0549; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0541; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0529; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0535; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0501; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0494; Time: 00:00:01
Fold 3 Epoch 029; Train loss: 0.0503; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0481; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.430464   0.323114   0.567881   0.366524  
Loss: 0.0608
Fold 3 Epoch 031; Train loss: 0.0472; Time: 00:00:01
Fold 3 Epoch 032; Train loss: 0.0464; Time: 00:00:01
Fold 3 Epoch 033; Train loss: 0.0457; Time: 00:00:01
Fold 3 Epoch 034; Train loss: 0.0455; Time: 00:00:01
Fold 3 Epoch 035; Train loss: 0.0437; Time: 00:00:01
Fold 3 Epoch 036; Train loss: 0.0437; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0428; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0409; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0417; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0409; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.432119   0.341927   0.579470   0.389548  
Loss: 0.0549
Fold 3 Epoch 041; Train loss: 0.0393; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0395; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0375; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0384; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0365; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0357; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0360; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0336; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0334; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0327; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.475166   0.376820   0.645695   0.431085  
Loss: 0.0422
Fold 3 Epoch 051; Train loss: 0.0324; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0314; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0315; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0297; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0286; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0277; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0277; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0263; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0257; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0249; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.427152   0.324851   0.591060   0.377639  
Loss: 0.0360
Fold 3 Epoch 061; Train loss: 0.0237; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0233; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0231; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0226; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0217; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0222; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0204; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0202; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0201; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0189; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.480132   0.383090   0.600993   0.421703  
Loss: 0.0254
Fold 3 Epoch 071; Train loss: 0.0189; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0186; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0180; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0174; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0176; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0164; Time: 00:00:00
Fold 3 Epoch 077; Train loss: 0.0157; Time: 00:00:00
Fold 3 Epoch 078; Train loss: 0.0150; Time: 00:00:00
Fold 3 Epoch 079; Train loss: 0.0147; Time: 00:00:00
Fold 3 Epoch 080; Train loss: 0.0147; Time: 00:00:00
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.624172   0.491174   0.748344   0.531350  
Loss: 0.0171
Fold 3 Epoch 081; Train loss: 0.0139; Time: 00:00:00
Fold 3 Epoch 082; Train loss: 0.0137; Time: 00:00:00
Fold 3 Epoch 083; Train loss: 0.0129; Time: 00:00:00
Fold 3 Epoch 084; Train loss: 0.0123; Time: 00:00:00
Fold 3 Epoch 085; Train loss: 0.0117; Time: 00:00:00
Fold 3 Epoch 086; Train loss: 0.0116; Time: 00:00:00
Fold 3 Epoch 087; Train loss: 0.0112; Time: 00:00:00
Fold 3 Epoch 088; Train loss: 0.0103; Time: 00:00:00
Fold 3 Epoch 089; Train loss: 0.0097; Time: 00:00:00
Fold 3 Epoch 090; Train loss: 0.0095; Time: 00:00:00
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.632450   0.462538   0.738411   0.496175  
Loss: 0.0132
Fold 3 Epoch 091; Train loss: 0.0090; Time: 00:00:00
Fold 3 Epoch 092; Train loss: 0.0088; Time: 00:00:00
Fold 3 Epoch 093; Train loss: 0.0081; Time: 00:00:00
Fold 3 Epoch 094; Train loss: 0.0078; Time: 00:00:00
Fold 3 Epoch 095; Train loss: 0.0074; Time: 00:00:00
Fold 3 Epoch 096; Train loss: 0.0072; Time: 00:00:00
Fold 3 Epoch 097; Train loss: 0.0069; Time: 00:00:00
Fold 3 Epoch 098; Train loss: 0.0067; Time: 00:00:00
Fold 3 Epoch 099; Train loss: 0.0060; Time: 00:00:00
Fold 3 Epoch 100; Train loss: 0.0057; Time: 00:00:00
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.614238   0.442998   0.690397   0.466242  
Loss: 0.0098
[optimizer candidate adamw] Fold 3: loss = [np.float64(0.0935436338186264), np.float64(0.07396013289690018), np.float64(0.060804929584264755), np.float64(0.054936669766902924), np.float64(0.04217999428510666), np.float64(0.0360424742102623), np.float64(0.025401150807738304), np.float64(0.017088402062654495), np.float64(0.013207186944782734), np.float64(0.009809955954551697)]
Tuning optimizer:  75%|███████▌  | 3/4 [04:34<01:31, 91.82s/it]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 0.5348; Time: 00:00:00
Fold 3 Epoch 002; Train loss: 0.2049; Time: 00:00:00
Fold 3 Epoch 003; Train loss: 0.1421; Time: 00:00:00
Fold 3 Epoch 004; Train loss: 0.1135; Time: 00:00:00
Fold 3 Epoch 005; Train loss: 0.0953; Time: 00:00:00
Fold 3 Epoch 006; Train loss: 0.0847; Time: 00:00:00
Fold 3 Epoch 007; Train loss: 0.0772; Time: 00:00:00
Fold 3 Epoch 008; Train loss: 0.0712; Time: 00:00:00
Fold 3 Epoch 009; Train loss: 0.0705; Time: 00:00:00
Fold 3 Epoch 010; Train loss: 0.0655; Time: 00:00:00
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.460265   0.306478   0.615894   0.356928  
Loss: 0.0910
Fold 3 Epoch 011; Train loss: 0.0662; Time: 00:00:00
Fold 3 Epoch 012; Train loss: 0.0633; Time: 00:00:00
Fold 3 Epoch 013; Train loss: 0.0634; Time: 00:00:00
Fold 3 Epoch 014; Train loss: 0.0613; Time: 00:00:00
Fold 3 Epoch 015; Train loss: 0.0601; Time: 00:00:00
Fold 3 Epoch 016; Train loss: 0.0570; Time: 00:00:00
Fold 3 Epoch 017; Train loss: 0.0574; Time: 00:00:00
Fold 3 Epoch 018; Train loss: 0.0561; Time: 00:00:00
Fold 3 Epoch 019; Train loss: 0.0540; Time: 00:00:00
Fold 3 Epoch 020; Train loss: 0.0534; Time: 00:00:00
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.534768   0.398524   0.698675   0.450690  
Loss: 0.0735
Fold 3 Epoch 021; Train loss: 0.0539; Time: 00:00:00
Fold 3 Epoch 022; Train loss: 0.0527; Time: 00:00:00
Fold 3 Epoch 023; Train loss: 0.0513; Time: 00:00:00
Fold 3 Epoch 024; Train loss: 0.0497; Time: 00:00:00
Fold 3 Epoch 025; Train loss: 0.0492; Time: 00:00:00
Fold 3 Epoch 026; Train loss: 0.0478; Time: 00:00:00
Fold 3 Epoch 027; Train loss: 0.0468; Time: 00:00:00
Fold 3 Epoch 028; Train loss: 0.0451; Time: 00:00:00
Fold 3 Epoch 029; Train loss: 0.0449; Time: 00:00:00
Fold 3 Epoch 030; Train loss: 0.0432; Time: 00:00:00
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.589404   0.460201   0.733444   0.506849  
Loss: 0.0634
Fold 3 Epoch 031; Train loss: 0.0417; Time: 00:00:00
Fold 3 Epoch 032; Train loss: 0.0408; Time: 00:00:00
Fold 3 Epoch 033; Train loss: 0.0398; Time: 00:00:00
Fold 3 Epoch 034; Train loss: 0.0387; Time: 00:00:00
Fold 3 Epoch 035; Train loss: 0.0379; Time: 00:00:00
Fold 3 Epoch 036; Train loss: 0.0373; Time: 00:00:00
Fold 3 Epoch 037; Train loss: 0.0360; Time: 00:00:00
Fold 3 Epoch 038; Train loss: 0.0351; Time: 00:00:00
Fold 3 Epoch 039; Train loss: 0.0340; Time: 00:00:00
Fold 3 Epoch 040; Train loss: 0.0339; Time: 00:00:00
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.514901   0.415579   0.655629   0.461045  
Loss: 0.0458
Fold 3 Epoch 041; Train loss: 0.0314; Time: 00:00:00
Fold 3 Epoch 042; Train loss: 0.0316; Time: 00:00:00
Fold 3 Epoch 043; Train loss: 0.0296; Time: 00:00:00
Fold 3 Epoch 044; Train loss: 0.0302; Time: 00:00:00
Fold 3 Epoch 045; Train loss: 0.0286; Time: 00:00:00
Fold 3 Epoch 046; Train loss: 0.0274; Time: 00:00:00
Fold 3 Epoch 047; Train loss: 0.0270; Time: 00:00:00
Fold 3 Epoch 048; Train loss: 0.0260; Time: 00:00:00
Fold 3 Epoch 049; Train loss: 0.0258; Time: 00:00:00
Fold 3 Epoch 050; Train loss: 0.0244; Time: 00:00:00
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.559603   0.434900   0.672185   0.471191  
Loss: 0.0363
Fold 3 Epoch 051; Train loss: 0.0240; Time: 00:00:00
Fold 3 Epoch 052; Train loss: 0.0226; Time: 00:00:00
Fold 3 Epoch 053; Train loss: 0.0228; Time: 00:00:00
Fold 3 Epoch 054; Train loss: 0.0222; Time: 00:00:00
Fold 3 Epoch 055; Train loss: 0.0210; Time: 00:00:00
Fold 3 Epoch 056; Train loss: 0.0204; Time: 00:00:00
Fold 3 Epoch 057; Train loss: 0.0199; Time: 00:00:00
Fold 3 Epoch 058; Train loss: 0.0182; Time: 00:00:00
Fold 3 Epoch 059; Train loss: 0.0187; Time: 00:00:00
Fold 3 Epoch 060; Train loss: 0.0185; Time: 00:00:00
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.478477   0.389786   0.582781   0.423656  
Loss: 0.0215
Fold 3 Epoch 061; Train loss: 0.0175; Time: 00:00:00
Fold 3 Epoch 062; Train loss: 0.0172; Time: 00:00:00
Fold 3 Epoch 063; Train loss: 0.0167; Time: 00:00:00
Fold 3 Epoch 064; Train loss: 0.0167; Time: 00:00:00
Fold 3 Epoch 065; Train loss: 0.0157; Time: 00:00:00
Fold 3 Epoch 066; Train loss: 0.0148; Time: 00:00:00
Fold 3 Epoch 067; Train loss: 0.0150; Time: 00:00:00
Fold 3 Epoch 068; Train loss: 0.0145; Time: 00:00:00
Fold 3 Epoch 069; Train loss: 0.0144; Time: 00:00:00
Fold 3 Epoch 070; Train loss: 0.0136; Time: 00:00:00
Fold 3: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.634106   0.403101   0.750000   0.441427  
Loss: 0.0153
Fold 3 Epoch 071; Train loss: 0.0137; Time: 00:00:00
Fold 3 Epoch 072; Train loss: 0.0130; Time: 00:00:00
Fold 3 Epoch 073; Train loss: 0.0128; Time: 00:00:00
Fold 3 Epoch 074; Train loss: 0.0125; Time: 00:00:00
Fold 3 Epoch 075; Train loss: 0.0120; Time: 00:00:00
Fold 3 Epoch 076; Train loss: 0.0113; Time: 00:00:03
Fold 3 Epoch 077; Train loss: 0.0109; Time: 00:00:03
Fold 3 Epoch 078; Train loss: 0.0103; Time: 00:00:03
Fold 3 Epoch 079; Train loss: 0.0101; Time: 00:00:03
Fold 3 Epoch 080; Train loss: 0.0093; Time: 00:00:03
Fold 3: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.602649   0.404027   0.745033   0.450827  
Loss: 0.0108
Fold 3 Epoch 081; Train loss: 0.0086; Time: 00:00:02
Fold 3 Epoch 082; Train loss: 0.0085; Time: 00:00:02
Fold 3 Epoch 083; Train loss: 0.0078; Time: 00:00:02
Fold 3 Epoch 084; Train loss: 0.0074; Time: 00:00:02
Fold 3 Epoch 085; Train loss: 0.0074; Time: 00:00:02
Fold 3 Epoch 086; Train loss: 0.0067; Time: 00:00:02
Fold 3 Epoch 087; Train loss: 0.0060; Time: 00:00:02
Fold 3 Epoch 088; Train loss: 0.0058; Time: 00:00:02
Fold 3 Epoch 089; Train loss: 0.0057; Time: 00:00:02
Fold 3 Epoch 090; Train loss: 0.0053; Time: 00:00:01
Fold 3: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.544702   0.401335   0.657285   0.438121  
Loss: 0.0070
Fold 3 Epoch 091; Train loss: 0.0054; Time: 00:00:02
Fold 3 Epoch 092; Train loss: 0.0050; Time: 00:00:02
Fold 3 Epoch 093; Train loss: 0.0050; Time: 00:00:02
Fold 3 Epoch 094; Train loss: 0.0048; Time: 00:00:01
Fold 3 Epoch 095; Train loss: 0.0047; Time: 00:00:01
Fold 3 Epoch 096; Train loss: 0.0045; Time: 00:00:01
Fold 3 Epoch 097; Train loss: 0.0045; Time: 00:00:01
Fold 3 Epoch 098; Train loss: 0.0041; Time: 00:00:01
Fold 3 Epoch 099; Train loss: 0.0040; Time: 00:00:01
Fold 3 Epoch 100; Train loss: 0.0039; Time: 00:00:01
Fold 3: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.594371   0.390797   0.721854   0.432406  
Loss: 0.0038
[optimizer candidate adam] Fold 3: loss = [np.float64(0.0910060927271843), np.float64(0.07345356792211533), np.float64(0.06342387944459915), np.float64(0.04581404849886894), np.float64(0.036288030445575714), np.float64(0.0215142834931612), np.float64(0.015307242050766945), np.float64(0.01084041129797697), np.float64(0.00697260582819581), np.float64(0.003797398181632161)]
Tuning optimizer: 100%|██████████| 4/4 [06:40<00:00, 105.38s/it]Tuning optimizer: 100%|██████████| 4/4 [06:40<00:00, 100.15s/it]

Best optimizer found: lamb
Tuning data for optimizer (loss) saved to ./category/tuning_optimizer.json
Tuning timesteps:   0%|          | 0/5 [00:00<?, ?it/s]
========== Fold 3 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 001; Train loss: 1.1004; Time: 00:00:01
Fold 3 Epoch 002; Train loss: 0.8023; Time: 00:00:01
Fold 3 Epoch 003; Train loss: 0.6372; Time: 00:00:01
Fold 3 Epoch 004; Train loss: 0.5236; Time: 00:00:01
Fold 3 Epoch 005; Train loss: 0.4231; Time: 00:00:01
Fold 3 Epoch 006; Train loss: 0.3435; Time: 00:00:01
Fold 3 Epoch 007; Train loss: 0.2802; Time: 00:00:01
Fold 3 Epoch 008; Train loss: 0.2300; Time: 00:00:01
Fold 3 Epoch 009; Train loss: 0.1895; Time: 00:00:01
Fold 3 Epoch 010; Train loss: 0.1592; Time: 00:00:01
Fold 3: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.579470   0.449415   0.754967   0.505603  
Loss: 0.2530
Fold 3 Epoch 011; Train loss: 0.1358; Time: 00:00:01
Fold 3 Epoch 012; Train loss: 0.1173; Time: 00:00:01
Fold 3 Epoch 013; Train loss: 0.1052; Time: 00:00:01
Fold 3 Epoch 014; Train loss: 0.0990; Time: 00:00:01
Fold 3 Epoch 015; Train loss: 0.0880; Time: 00:00:01
Fold 3 Epoch 016; Train loss: 0.0828; Time: 00:00:01
Fold 3 Epoch 017; Train loss: 0.0772; Time: 00:00:01
Fold 3 Epoch 018; Train loss: 0.0734; Time: 00:00:01
Fold 3 Epoch 019; Train loss: 0.0713; Time: 00:00:01
Fold 3 Epoch 020; Train loss: 0.0671; Time: 00:00:01
Fold 3: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.574503   0.454049   0.733444   0.504750  
Loss: 0.0941
Fold 3 Epoch 021; Train loss: 0.0656; Time: 00:00:01
Fold 3 Epoch 022; Train loss: 0.0617; Time: 00:00:01
Fold 3 Epoch 023; Train loss: 0.0612; Time: 00:00:01
Fold 3 Epoch 024; Train loss: 0.0593; Time: 00:00:01
Fold 3 Epoch 025; Train loss: 0.0566; Time: 00:00:01
Fold 3 Epoch 026; Train loss: 0.0535; Time: 00:00:01
Fold 3 Epoch 027; Train loss: 0.0533; Time: 00:00:01
Fold 3 Epoch 028; Train loss: 0.0527; Time: 00:00:01
Fold 3 Epoch 029; Train loss: 0.0506; Time: 00:00:01
Fold 3 Epoch 030; Train loss: 0.0489; Time: 00:00:01
Fold 3: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.500000   0.366511   0.726821   0.440051  
Loss: 0.0623
Fold 3 Epoch 031; Train loss: 0.0472; Time: 00:00:01
Fold 3 Epoch 032; Train loss: 0.0467; Time: 00:00:01
Fold 3 Epoch 033; Train loss: 0.0448; Time: 00:00:01
Fold 3 Epoch 034; Train loss: 0.0436; Time: 00:00:01
Fold 3 Epoch 035; Train loss: 0.0420; Time: 00:00:01
Fold 3 Epoch 036; Train loss: 0.0420; Time: 00:00:01
Fold 3 Epoch 037; Train loss: 0.0412; Time: 00:00:01
Fold 3 Epoch 038; Train loss: 0.0395; Time: 00:00:01
Fold 3 Epoch 039; Train loss: 0.0390; Time: 00:00:01
Fold 3 Epoch 040; Train loss: 0.0376; Time: 00:00:01
Fold 3: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.504967   0.418114   0.673841   0.471361  
Loss: 0.0485
Fold 3 Epoch 041; Train loss: 0.0376; Time: 00:00:01
Fold 3 Epoch 042; Train loss: 0.0355; Time: 00:00:01
Fold 3 Epoch 043; Train loss: 0.0340; Time: 00:00:01
Fold 3 Epoch 044; Train loss: 0.0344; Time: 00:00:01
Fold 3 Epoch 045; Train loss: 0.0335; Time: 00:00:01
Fold 3 Epoch 046; Train loss: 0.0322; Time: 00:00:01
Fold 3 Epoch 047; Train loss: 0.0322; Time: 00:00:01
Fold 3 Epoch 048; Train loss: 0.0311; Time: 00:00:01
Fold 3 Epoch 049; Train loss: 0.0307; Time: 00:00:01
Fold 3 Epoch 050; Train loss: 0.0298; Time: 00:00:01
Fold 3: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.500000   0.382723   0.660596   0.434198  
Loss: 0.0314
Fold 3 Epoch 051; Train loss: 0.0283; Time: 00:00:01
Fold 3 Epoch 052; Train loss: 0.0285; Time: 00:00:01
Fold 3 Epoch 053; Train loss: 0.0270; Time: 00:00:01
Fold 3 Epoch 054; Train loss: 0.0261; Time: 00:00:01
Fold 3 Epoch 055; Train loss: 0.0254; Time: 00:00:01
Fold 3 Epoch 056; Train loss: 0.0257; Time: 00:00:01
Fold 3 Epoch 057; Train loss: 0.0244; Time: 00:00:01
Fold 3 Epoch 058; Train loss: 0.0246; Time: 00:00:01
Fold 3 Epoch 059; Train loss: 0.0226; Time: 00:00:01

========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 3 Epoch 060; Train loss: 0.0220; Time: 00:00:01
Fold 3: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.408940   0.276937   0.594371   0.336620  
Loss: 0.0254
Fold 1 Epoch 001; Train loss: 0.5668; Time: 00:00:01
Fold 3 Epoch 061; Train loss: 0.0215; Time: 00:00:01
