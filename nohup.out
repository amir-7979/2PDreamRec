Tuning lr:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 18.1744; Time: 00:00:03
Fold 1 Epoch 002; Train loss: 0.7682; Time: 00:00:02
Fold 1 Epoch 003; Train loss: 0.2012; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.1611; Time: 00:00:02
Fold 1 Epoch 005; Train loss: 0.1512; Time: 00:00:02
Fold 1 Epoch 006; Train loss: 0.3280; Time: 00:00:01
Fold 1 Epoch 007; Train loss: 0.1691; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1224; Time: 00:00:02
Fold 1 Epoch 009; Train loss: 0.1173; Time: 00:00:02
Fold 1 Epoch 010; Train loss: 0.1077; Time: 00:00:02
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.450331   0.366451   0.536424   0.394313  
Loss: 0.1152
Fold 1 Epoch 011; Train loss: 0.1038; Time: 00:00:02
Fold 1 Epoch 012; Train loss: 0.0942; Time: 00:00:02
Fold 1 Epoch 013; Train loss: 0.0930; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.1047; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.1118; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.0750; Time: 00:00:02
Fold 1 Epoch 017; Train loss: 0.0687; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.0668; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.0616; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0570; Time: 00:00:02
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.528146   0.416312   0.614238   0.444650  
Loss: 0.0643
Fold 1 Epoch 021; Train loss: 0.0614; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.0824; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0513; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.0425; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0387; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0375; Time: 00:00:02
Fold 1 Epoch 027; Train loss: 0.0348; Time: 00:00:02
Fold 1 Epoch 028; Train loss: 0.0330; Time: 00:00:02
Fold 1 Epoch 029; Train loss: 0.0302; Time: 00:00:02
Fold 1 Epoch 030; Train loss: 0.0291; Time: 00:00:02
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.500000   0.383298   0.614238   0.419827  
Loss: 0.0259
Fold 1 Epoch 031; Train loss: 0.0288; Time: 00:00:02
Fold 1 Epoch 032; Train loss: 0.0377; Time: 00:00:02
Fold 1 Epoch 033; Train loss: 0.0318; Time: 00:00:02
Fold 1 Epoch 034; Train loss: 0.0228; Time: 00:00:02
Fold 1 Epoch 035; Train loss: 0.0204; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.0184; Time: 00:00:02
Fold 1 Epoch 037; Train loss: 0.0177; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0163; Time: 00:00:02
Fold 1 Epoch 039; Train loss: 0.0149; Time: 00:00:02
Fold 1 Epoch 040; Train loss: 0.0133; Time: 00:00:02
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.371248   0.624172   0.394577  
Loss: 0.0117
Fold 1 Epoch 041; Train loss: 0.0120; Time: 00:00:02
Fold 1 Epoch 042; Train loss: 0.0110; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0080; Time: 00:00:01
Fold 1 Epoch 044; Train loss: 0.0049; Time: 00:00:02
Fold 1 Epoch 045; Train loss: 0.0033; Time: 00:00:02
Fold 1 Epoch 046; Train loss: 0.0023; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.0017; Time: 00:00:02
Fold 1 Epoch 048; Train loss: 0.0022; Time: 00:00:02
Fold 1 Epoch 049; Train loss: 0.0030; Time: 00:00:02
Fold 1 Epoch 050; Train loss: 0.0020; Time: 00:00:02
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.569536   0.420225   0.897351   0.519957  
Loss: 0.0011
Fold 1 Epoch 051; Train loss: 0.0010; Time: 00:00:02
Fold 1 Epoch 052; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 054; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0008; Time: 00:00:02
Fold 1 Epoch 056; Train loss: 0.0017; Time: 00:00:02
Fold 1 Epoch 057; Train loss: 0.0025; Time: 00:00:02
Fold 1 Epoch 058; Train loss: 0.0019; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.0004; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.368193   0.899007   0.491826  
Loss: 0.0003
Fold 1 Epoch 061; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 063; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 064; Train loss: 0.0009; Time: 00:00:02
Fold 1 Epoch 065; Train loss: 0.0014; Time: 00:00:02
Fold 1 Epoch 066; Train loss: 0.0014; Time: 00:00:02
Fold 1 Epoch 067; Train loss: 0.0009; Time: 00:00:02
Fold 1 Epoch 068; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 069; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 070; Train loss: 0.0005; Time: 00:00:02
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.436086   0.899007   0.556113  
Loss: 0.0004
Fold 1 Epoch 071; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 073; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 074; Train loss: 0.0009; Time: 00:00:02
Fold 1 Epoch 075; Train loss: 0.0009; Time: 00:00:02
Fold 1 Epoch 076; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 077; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 079; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0006; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.316053   0.899007   0.430059  
Loss: 0.0005
Fold 1 Epoch 081; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0003; Time: 00:00:02
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.899007   0.527547  
Loss: 0.0003
Fold 1 Epoch 091; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 092; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 093; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 094; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 095; Train loss: 0.0008; Time: 00:00:02
Fold 1 Epoch 096; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 099; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0003; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.899007   0.527547  
Loss: 0.0003
[lr candidate 0.05] Fold 1: HR@10 = [np.float64(0.5364238410596026), np.float64(0.6142384105960265), np.float64(0.6142384105960265), np.float64(0.6241721854304636), np.float64(0.8973509933774835), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563)]
Tuning lr:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [03:44<11:14, 224.79s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 0.5264; Time: 00:00:02
Fold 1 Epoch 002; Train loss: 0.2104; Time: 00:00:02
Fold 1 Epoch 003; Train loss: 0.1676; Time: 00:00:02
Fold 1 Epoch 004; Train loss: 0.1412; Time: 00:00:02
Fold 1 Epoch 005; Train loss: 0.1332; Time: 00:00:02
Fold 1 Epoch 006; Train loss: 0.1268; Time: 00:00:02
Fold 1 Epoch 007; Train loss: 0.1247; Time: 00:00:02
Fold 1 Epoch 008; Train loss: 0.1157; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.1076; Time: 00:00:02
Fold 1 Epoch 010; Train loss: 0.0985; Time: 00:00:02
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.596026   0.454960   0.748344   0.504798  
Loss: 0.1249
Fold 1 Epoch 011; Train loss: 0.0965; Time: 00:00:02
Fold 1 Epoch 012; Train loss: 0.0924; Time: 00:00:02
Fold 1 Epoch 013; Train loss: 0.0842; Time: 00:00:02
Fold 1 Epoch 014; Train loss: 0.0797; Time: 00:00:02
Fold 1 Epoch 015; Train loss: 0.0741; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.0696; Time: 00:00:02
Fold 1 Epoch 017; Train loss: 0.0624; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.0609; Time: 00:00:02
Fold 1 Epoch 019; Train loss: 0.0552; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0531; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.455298   0.344145   0.657285   0.409893  
Loss: 0.0577
Fold 1 Epoch 021; Train loss: 0.0492; Time: 00:00:02
Fold 1 Epoch 022; Train loss: 0.0449; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0402; Time: 00:00:02
Fold 1 Epoch 024; Train loss: 0.0388; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0356; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0326; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0296; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0264; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0262; Time: 00:00:02
Fold 1 Epoch 030; Train loss: 0.0233; Time: 00:00:02
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.750000   0.515907   0.875828   0.556277  
Loss: 0.0250
Fold 1 Epoch 031; Train loss: 0.0212; Time: 00:00:02
Fold 1 Epoch 032; Train loss: 0.0179; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.0164; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.0152; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.0138; Time: 00:00:02
Fold 1 Epoch 036; Train loss: 0.0114; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.0095; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0079; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0064; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0054; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.812914   0.525114   0.897351   0.551396  
Loss: 0.0064
Fold 1 Epoch 041; Train loss: 0.0040; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.0026; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 044; Train loss: 0.0012; Time: 00:00:02
Fold 1 Epoch 045; Train loss: 0.0009; Time: 00:00:02
Fold 1 Epoch 046; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 047; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 048; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 049; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 050; Train loss: 0.0003; Time: 00:00:02
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.401606   0.870861   0.507389  
Loss: 0.0006
Fold 1 Epoch 051; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 052; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 053; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 054; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 055; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 056; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 057; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 058; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 059; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 060; Train loss: 0.0001; Time: 00:00:02
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.436086   0.892384   0.548369  
Loss: 0.0001
Fold 1 Epoch 061; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 062; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 063; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 064; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 065; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 066; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 067; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 068; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 069; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0000; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.899007   0.527547  
Loss: 0.0001
Fold 1 Epoch 071; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 075; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 076; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0000; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.434926   0.899007   0.541207  
Loss: 0.0001
Fold 1 Epoch 081; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 088; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 090; Train loss: 0.0000; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.899007   0.523169  
Loss: 0.0000
Fold 1 Epoch 091; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 092; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 094; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 095; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 096; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 097; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 098; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 099; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 100; Train loss: 0.0000; Time: 00:00:02
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.899007   0.523169  
Loss: 0.0000
[lr candidate 0.01] Fold 1: HR@10 = [np.float64(0.7483443708609272), np.float64(0.6572847682119205), np.float64(0.8758278145695364), np.float64(0.8973509933774835), np.float64(0.8708609271523179), np.float64(0.8923841059602649), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8990066225165563)]
Tuning lr:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [07:35<07:36, 228.05s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 0.6177; Time: 00:00:01
Fold 1 Epoch 002; Train loss: 0.2674; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 0.1910; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.1645; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 0.1500; Time: 00:00:02
Fold 1 Epoch 006; Train loss: 0.1432; Time: 00:00:02
Fold 1 Epoch 007; Train loss: 0.1370; Time: 00:00:02
Fold 1 Epoch 008; Train loss: 0.1322; Time: 00:00:02
Fold 1 Epoch 009; Train loss: 0.1253; Time: 00:00:02
Fold 1 Epoch 010; Train loss: 0.1244; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.503311   0.402360   0.673841   0.456358  
Loss: 0.1386
Fold 1 Epoch 011; Train loss: 0.1194; Time: 00:00:02
Fold 1 Epoch 012; Train loss: 0.1161; Time: 00:00:02
Fold 1 Epoch 013; Train loss: 0.1123; Time: 00:00:02
Fold 1 Epoch 014; Train loss: 0.1111; Time: 00:00:02
Fold 1 Epoch 015; Train loss: 0.1066; Time: 00:00:02
Fold 1 Epoch 016; Train loss: 0.1022; Time: 00:00:02
Fold 1 Epoch 017; Train loss: 0.1000; Time: 00:00:02
Fold 1 Epoch 018; Train loss: 0.0951; Time: 00:00:02
Fold 1 Epoch 019; Train loss: 0.0927; Time: 00:00:02
Fold 1 Epoch 020; Train loss: 0.0921; Time: 00:00:02
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.549669   0.452045   0.711921   0.502991  
Loss: 0.0997
Fold 1 Epoch 021; Train loss: 0.0881; Time: 00:00:02
Fold 1 Epoch 022; Train loss: 0.0860; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0819; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.0781; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0776; Time: 00:00:02
Fold 1 Epoch 026; Train loss: 0.0723; Time: 00:00:02
Fold 1 Epoch 027; Train loss: 0.0718; Time: 00:00:02
Fold 1 Epoch 028; Train loss: 0.0702; Time: 00:00:02
Fold 1 Epoch 029; Train loss: 0.0672; Time: 00:00:02
Fold 1 Epoch 030; Train loss: 0.0641; Time: 00:00:02
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.488411   0.412005   0.649007   0.464269  
Loss: 0.0694
Fold 1 Epoch 031; Train loss: 0.0599; Time: 00:00:02
Fold 1 Epoch 032; Train loss: 0.0602; Time: 00:00:02
Fold 1 Epoch 033; Train loss: 0.0563; Time: 00:00:02
Fold 1 Epoch 034; Train loss: 0.0545; Time: 00:00:02
Fold 1 Epoch 035; Train loss: 0.0526; Time: 00:00:02
Fold 1 Epoch 036; Train loss: 0.0504; Time: 00:00:02
Fold 1 Epoch 037; Train loss: 0.0482; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0466; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0442; Time: 00:00:02
Fold 1 Epoch 040; Train loss: 0.0424; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.470199   0.308101   0.652318   0.366159  
Loss: 0.0452
Fold 1 Epoch 041; Train loss: 0.0403; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.0383; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0362; Time: 00:00:01
Fold 1 Epoch 044; Train loss: 0.0350; Time: 00:00:02
Fold 1 Epoch 045; Train loss: 0.0338; Time: 00:00:02
Fold 1 Epoch 046; Train loss: 0.0315; Time: 00:00:02
Fold 1 Epoch 047; Train loss: 0.0300; Time: 00:00:02
Fold 1 Epoch 048; Train loss: 0.0279; Time: 00:00:02
Fold 1 Epoch 049; Train loss: 0.0265; Time: 00:00:02
Fold 1 Epoch 050; Train loss: 0.0244; Time: 00:00:02
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.526490   0.342497   0.799669   0.428618  
Loss: 0.0274
Fold 1 Epoch 051; Train loss: 0.0230; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.0210; Time: 00:00:02
Fold 1 Epoch 053; Train loss: 0.0197; Time: 00:00:02
Fold 1 Epoch 054; Train loss: 0.0180; Time: 00:00:02
Fold 1 Epoch 055; Train loss: 0.0167; Time: 00:00:02
Fold 1 Epoch 056; Train loss: 0.0155; Time: 00:00:02
Fold 1 Epoch 057; Train loss: 0.0140; Time: 00:00:02
Fold 1 Epoch 058; Train loss: 0.0128; Time: 00:00:02
Fold 1 Epoch 059; Train loss: 0.0116; Time: 00:00:02
Fold 1 Epoch 060; Train loss: 0.0106; Time: 00:00:02
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.440397   0.246684   0.783113   0.353405  
Loss: 0.0107
Fold 1 Epoch 061; Train loss: 0.0094; Time: 00:00:02
Fold 1 Epoch 062; Train loss: 0.0083; Time: 00:00:02
Fold 1 Epoch 063; Train loss: 0.0075; Time: 00:00:02
Fold 1 Epoch 064; Train loss: 0.0065; Time: 00:00:02
Fold 1 Epoch 065; Train loss: 0.0059; Time: 00:00:01
Fold 1 Epoch 066; Train loss: 0.0052; Time: 00:00:02
Fold 1 Epoch 067; Train loss: 0.0045; Time: 00:00:02
Fold 1 Epoch 068; Train loss: 0.0038; Time: 00:00:02
Fold 1 Epoch 069; Train loss: 0.0032; Time: 00:00:02
Fold 1 Epoch 070; Train loss: 0.0029; Time: 00:00:02
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.554636   0.287392   0.938742   0.413298  
Loss: 0.0029
Fold 1 Epoch 071; Train loss: 0.0024; Time: 00:00:02
Fold 1 Epoch 072; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 073; Train loss: 0.0016; Time: 00:00:02
Fold 1 Epoch 074; Train loss: 0.0013; Time: 00:00:02
Fold 1 Epoch 075; Train loss: 0.0010; Time: 00:00:02
Fold 1 Epoch 076; Train loss: 0.0008; Time: 00:00:02
Fold 1 Epoch 077; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 078; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 079; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 080; Train loss: 0.0005; Time: 00:00:02
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.323780   0.925497   0.447515  
Loss: 0.0008
Fold 1 Epoch 081; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 082; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 083; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 084; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 085; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 087; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0001; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.892384   0.443053  
Loss: 0.0003
Fold 1 Epoch 091; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 093; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 098; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 099; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 100; Train loss: 0.0001; Time: 00:00:02
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.412381   0.892384   0.524663  
Loss: 0.0003
[lr candidate 0.005] Fold 1: HR@10 = [np.float64(0.6738410596026491), np.float64(0.7119205298013245), np.float64(0.6490066225165563), np.float64(0.652317880794702), np.float64(0.7996688741721855), np.float64(0.7831125827814569), np.float64(0.9387417218543046), np.float64(0.9254966887417219), np.float64(0.8923841059602649), np.float64(0.8923841059602649)]
Tuning lr:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [11:36<03:53, 233.99s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 0.9175; Time: 00:00:02
Fold 1 Epoch 002; Train loss: 0.6087; Time: 00:00:02
Fold 1 Epoch 003; Train loss: 0.4703; Time: 00:00:02
Fold 1 Epoch 004; Train loss: 0.3832; Time: 00:00:02
Fold 1 Epoch 005; Train loss: 0.3262; Time: 00:00:02
Fold 1 Epoch 006; Train loss: 0.2851; Time: 00:00:02
Fold 1 Epoch 007; Train loss: 0.2557; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.2317; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.2192; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.2057; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.592715   0.451505   0.705298   0.487130  
Loss: 0.3084
Fold 1 Epoch 011; Train loss: 0.1876; Time: 00:00:02
Fold 1 Epoch 012; Train loss: 0.1843; Time: 00:00:02
Fold 1 Epoch 013; Train loss: 0.1797; Time: 00:00:02
Fold 1 Epoch 014; Train loss: 0.1726; Time: 00:00:02
Fold 1 Epoch 015; Train loss: 0.1679; Time: 00:00:02
Fold 1 Epoch 016; Train loss: 0.1627; Time: 00:00:02
Fold 1 Epoch 017; Train loss: 0.1584; Time: 00:00:02
Fold 1 Epoch 018; Train loss: 0.1602; Time: 00:00:02
Fold 1 Epoch 019; Train loss: 0.1548; Time: 00:00:02
Fold 1 Epoch 020; Train loss: 0.1515; Time: 00:00:02
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.548013   0.450494   0.657285   0.485013  
Loss: 0.2080
Fold 1 Epoch 021; Train loss: 0.1470; Time: 00:00:02
Fold 1 Epoch 022; Train loss: 0.1506; Time: 00:00:02
Fold 1 Epoch 023; Train loss: 0.1445; Time: 00:00:02
Fold 1 Epoch 024; Train loss: 0.1429; Time: 00:00:02
Fold 1 Epoch 025; Train loss: 0.1415; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.1411; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.1398; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.1382; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.1370; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.1349; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.544702   0.447856   0.653974   0.483061  
Loss: 0.1753
Fold 1 Epoch 031; Train loss: 0.1325; Time: 00:00:02
Fold 1 Epoch 032; Train loss: 0.1320; Time: 00:00:02
Fold 1 Epoch 033; Train loss: 0.1305; Time: 00:00:02
Fold 1 Epoch 034; Train loss: 0.1287; Time: 00:00:02
Fold 1 Epoch 035; Train loss: 0.1307; Time: 00:00:02
Fold 1 Epoch 036; Train loss: 0.1257; Time: 00:00:02
Fold 1 Epoch 037; Train loss: 0.1266; Time: 00:00:02
Fold 1 Epoch 038; Train loss: 0.1273; Time: 00:00:02
Fold 1 Epoch 039; Train loss: 0.1268; Time: 00:00:02
Fold 1 Epoch 040; Train loss: 0.1229; Time: 00:00:02
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.554636   0.457280   0.680464   0.497829  
Loss: 0.1517
Fold 1 Epoch 041; Train loss: 0.1254; Time: 00:00:02
Fold 1 Epoch 042; Train loss: 0.1227; Time: 00:00:02
Fold 1 Epoch 043; Train loss: 0.1221; Time: 00:00:02
Fold 1 Epoch 044; Train loss: 0.1202; Time: 00:00:02
Fold 1 Epoch 045; Train loss: 0.1191; Time: 00:00:02
Fold 1 Epoch 046; Train loss: 0.1211; Time: 00:00:02
Fold 1 Epoch 047; Train loss: 0.1204; Time: 00:00:02
Fold 1 Epoch 048; Train loss: 0.1168; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.1181; Time: 00:00:02
Fold 1 Epoch 050; Train loss: 0.1154; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.592715   0.483216   0.720199   0.523723  
Loss: 0.1510
Fold 1 Epoch 051; Train loss: 0.1157; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.1172; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.1135; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.1125; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.1176; Time: 00:00:01
Fold 1 Epoch 056; Train loss: 0.1134; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.1114; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.1109; Time: 00:00:02
Fold 1 Epoch 059; Train loss: 0.1126; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.1115; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.556291   0.453873   0.660596   0.487245  
Loss: 0.1364
Fold 1 Epoch 061; Train loss: 0.1107; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.1084; Time: 00:00:02
Fold 1 Epoch 063; Train loss: 0.1066; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.1071; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.1062; Time: 00:00:01
Fold 1 Epoch 066; Train loss: 0.1066; Time: 00:00:02
Fold 1 Epoch 067; Train loss: 0.1027; Time: 00:00:02
Fold 1 Epoch 068; Train loss: 0.1068; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.1045; Time: 00:00:02
Fold 1 Epoch 070; Train loss: 0.1031; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.579470   0.471607   0.693709   0.508138  
Loss: 0.1269
Fold 1 Epoch 071; Train loss: 0.1032; Time: 00:00:02
Fold 1 Epoch 072; Train loss: 0.1007; Time: 00:00:02
Fold 1 Epoch 073; Train loss: 0.0997; Time: 00:00:02
Fold 1 Epoch 074; Train loss: 0.1013; Time: 00:00:02
Fold 1 Epoch 075; Train loss: 0.0993; Time: 00:00:02
Fold 1 Epoch 076; Train loss: 0.0981; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0968; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0974; Time: 00:00:02
Fold 1 Epoch 079; Train loss: 0.0962; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0954; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.435986   0.637417   0.471571  
Loss: 0.1301
Fold 1 Epoch 081; Train loss: 0.0955; Time: 00:00:02
Fold 1 Epoch 082; Train loss: 0.0955; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0962; Time: 00:00:02
Fold 1 Epoch 084; Train loss: 0.0930; Time: 00:00:02
Fold 1 Epoch 085; Train loss: 0.0934; Time: 00:00:02
Fold 1 Epoch 086; Train loss: 0.0924; Time: 00:00:02
Fold 1 Epoch 087; Train loss: 0.0916; Time: 00:00:02
Fold 1 Epoch 088; Train loss: 0.0906; Time: 00:00:02
Fold 1 Epoch 089; Train loss: 0.0896; Time: 00:00:02
Fold 1 Epoch 090; Train loss: 0.0881; Time: 00:00:02
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.508278   0.421167   0.625828   0.458446  
Loss: 0.1171
Fold 1 Epoch 091; Train loss: 0.0889; Time: 00:00:02
Fold 1 Epoch 092; Train loss: 0.0883; Time: 00:00:02
Fold 1 Epoch 093; Train loss: 0.0863; Time: 00:00:02
Fold 1 Epoch 094; Train loss: 0.0868; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0868; Time: 00:00:02
Fold 1 Epoch 096; Train loss: 0.0854; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0844; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0837; Time: 00:00:02
Fold 1 Epoch 099; Train loss: 0.0827; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0835; Time: 00:00:02
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.569536   0.462817   0.688742   0.500957  
Loss: 0.1086
[lr candidate 0.001] Fold 1: HR@10 = [np.float64(0.7052980132450332), np.float64(0.6572847682119205), np.float64(0.6539735099337748), np.float64(0.6804635761589404), np.float64(0.7201986754966887), np.float64(0.6605960264900662), np.float64(0.6937086092715232), np.float64(0.6374172185430463), np.float64(0.6258278145695364), np.float64(0.6887417218543046)]
Tuning lr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [15:26<00:00, 232.70s/it]Tuning lr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [15:26<00:00, 231.73s/it]

Best learning rate found: 0.05
Tuning optimizer:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 0.6186; Time: 00:00:02
Fold 1 Epoch 002; Train loss: 0.2152; Time: 00:00:02
Fold 1 Epoch 003; Train loss: 0.1415; Time: 00:00:02
Fold 1 Epoch 004; Train loss: 0.0957; Time: 00:00:02
Fold 1 Epoch 005; Train loss: 0.0624; Time: 00:00:02
Fold 1 Epoch 006; Train loss: 0.0414; Time: 00:00:02
Fold 1 Epoch 007; Train loss: 0.0260; Time: 00:00:02
Fold 1 Epoch 008; Train loss: 0.0126; Time: 00:00:02
Fold 1 Epoch 009; Train loss: 0.0047; Time: 00:00:02
Fold 1 Epoch 010; Train loss: 0.0027; Time: 00:00:02
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.503311   0.213845   0.586093   0.241761  
Loss: 0.0023
Fold 1 Epoch 011; Train loss: 0.0016; Time: 00:00:02
Fold 1 Epoch 012; Train loss: 0.0011; Time: 00:00:02
Fold 1 Epoch 013; Train loss: 0.0009; Time: 00:00:02
Fold 1 Epoch 014; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 015; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 016; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 017; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 018; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 019; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 020; Train loss: 0.0005; Time: 00:00:02
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.059603   0.029550   0.182119   0.069271  
Loss: 0.0005
Fold 1 Epoch 021; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 022; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 023; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 024; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 025; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 026; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 027; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 028; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 029; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 030; Train loss: 0.0004; Time: 00:00:02
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.327815   0.151726   0.433775   0.185702  
Loss: 0.0005
Fold 1 Epoch 031; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 032; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 033; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 034; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 035; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 036; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 037; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 038; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 039; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 040; Train loss: 0.0004; Time: 00:00:02
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.316225   0.146767   0.594371   0.231874  
Loss: 0.0005
Fold 1 Epoch 041; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 042; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 043; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 044; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 045; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 046; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 047; Train loss: 0.0020; Time: 00:00:02
Fold 1 Epoch 048; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 049; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 050; Train loss: 0.0003; Time: 00:00:02
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.044702   0.026205   0.312914   0.108004  
Loss: 0.0007
Fold 1 Epoch 051; Train loss: 0.0009; Time: 00:00:02
Fold 1 Epoch 052; Train loss: 0.0015; Time: 00:00:02
Fold 1 Epoch 053; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 054; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 055; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 056; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 057; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 058; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 059; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 060; Train loss: 0.0020; Time: 00:00:02
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.327815   0.167781   0.496689   0.220334  
Loss: 0.0021
Fold 1 Epoch 061; Train loss: 0.0020; Time: 00:00:02
Fold 1 Epoch 062; Train loss: 0.0020; Time: 00:00:03
Fold 1 Epoch 063; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 064; Train loss: 0.0020; Time: 00:00:02
Fold 1 Epoch 065; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 066; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 067; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 068; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 069; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 070; Train loss: 0.0019; Time: 00:00:02
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.268212   0.148442   0.571192   0.249418  
Loss: 0.0020
Fold 1 Epoch 071; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 072; Train loss: 0.0020; Time: 00:00:02
Fold 1 Epoch 073; Train loss: 0.0020; Time: 00:00:02
Fold 1 Epoch 074; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 075; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 076; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 077; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 078; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 079; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 080; Train loss: 0.0019; Time: 00:00:02
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.188742   0.081310   0.554636   0.199461  
Loss: 0.0023
Fold 1 Epoch 081; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 082; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 083; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 084; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 085; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 086; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 087; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 088; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 089; Train loss: 0.0020; Time: 00:00:02
Fold 1 Epoch 090; Train loss: 0.0019; Time: 00:00:02
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.033113   0.016806   0.533113   0.168768  
Loss: 0.0021
Fold 1 Epoch 091; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 092; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 093; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 094; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 095; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 096; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 097; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 098; Train loss: 0.0017; Time: 00:00:02
Fold 1 Epoch 099; Train loss: 0.0017; Time: 00:00:02
Fold 1 Epoch 100; Train loss: 0.0017; Time: 00:00:02
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.200331   0.080184   0.455298   0.162128  
Loss: 0.0020
[optimizer candidate lamb] Fold 1: HR@10 = [np.float64(0.5860927152317881), np.float64(0.18211920529801323), np.float64(0.4337748344370861), np.float64(0.5943708609271523), np.float64(0.3129139072847682), np.float64(0.4966887417218543), np.float64(0.5711920529801324), np.float64(0.554635761589404), np.float64(0.5331125827814569), np.float64(0.4552980132450331)]
Tuning optimizer:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [04:07<12:21, 247.09s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 8.5749; Time: 00:00:01
Fold 1 Epoch 002; Train loss: 1.8376; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 0.5368; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.2637; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 0.1659; Time: 00:00:02
Fold 1 Epoch 006; Train loss: 0.1260; Time: 00:00:02
Fold 1 Epoch 007; Train loss: 0.1060; Time: 00:00:02
Fold 1 Epoch 008; Train loss: 0.0972; Time: 00:00:02
Fold 1 Epoch 009; Train loss: 0.0888; Time: 00:00:02
Fold 1 Epoch 010; Train loss: 0.0854; Time: 00:00:02
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.296358   0.161301   0.455298   0.213381  
Loss: 0.0931
Fold 1 Epoch 011; Train loss: 0.0760; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.0718; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.0660; Time: 00:00:02
Fold 1 Epoch 014; Train loss: 0.0606; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.0569; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.0516; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.0466; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.0419; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.0375; Time: 00:00:02
Fold 1 Epoch 020; Train loss: 0.0337; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.329470   0.185103   0.485099   0.234866  
Loss: 0.0401
Fold 1 Epoch 021; Train loss: 0.0308; Time: 00:00:02
Fold 1 Epoch 022; Train loss: 0.0284; Time: 00:00:02
Fold 1 Epoch 023; Train loss: 0.0260; Time: 00:00:02
Fold 1 Epoch 024; Train loss: 0.0236; Time: 00:00:02
Fold 1 Epoch 025; Train loss: 0.0209; Time: 00:00:02
Fold 1 Epoch 026; Train loss: 0.0191; Time: 00:00:02
Fold 1 Epoch 027; Train loss: 0.0166; Time: 00:00:02
Fold 1 Epoch 028; Train loss: 0.0150; Time: 00:00:02
Fold 1 Epoch 029; Train loss: 0.0133; Time: 00:00:02
Fold 1 Epoch 030; Train loss: 0.0108; Time: 00:00:02
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.337748   0.150125   0.624172   0.239230  
Loss: 0.0123
Fold 1 Epoch 031; Train loss: 0.0087; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.0066; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.0049; Time: 00:00:02
Fold 1 Epoch 034; Train loss: 0.0034; Time: 00:00:02
Fold 1 Epoch 035; Train loss: 0.0023; Time: 00:00:02
Fold 1 Epoch 036; Train loss: 0.0014; Time: 00:00:02
Fold 1 Epoch 037; Train loss: 0.0010; Time: 00:00:02
Fold 1 Epoch 038; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0008; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.250000   0.099578   0.360927   0.134552  
Loss: 0.0029
Fold 1 Epoch 041; Train loss: 0.0008; Time: 00:00:02
Fold 1 Epoch 042; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 044; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 046; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 048; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.0006; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.046358   0.020287   0.632450   0.209621  
Loss: 0.0027
Fold 1 Epoch 051; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 053; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 054; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 055; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 056; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 057; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 058; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 059; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 060; Train loss: 0.0005; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.117550   0.059575   0.607616   0.208958  
Loss: 0.0023
Fold 1 Epoch 061; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 065; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 066; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 067; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 068; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0004; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.019868   0.009503   0.395695   0.128545  
Loss: 0.0017
Fold 1 Epoch 071; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 072; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 073; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 074; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 075; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 077; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0003; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.309603   0.140458   0.870861   0.310047  
Loss: 0.0015
Fold 1 Epoch 081; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 085; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 086; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 087; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 088; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 089; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0003; Time: 00:00:02
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.077815   0.033834   0.599338   0.211419  
Loss: 0.0009
Fold 1 Epoch 091; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 092; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 093; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 094; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 096; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0002; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.051325   0.026447   0.304636   0.100848  
Loss: 0.0012
[optimizer candidate adamw] Fold 1: HR@10 = [np.float64(0.4552980132450331), np.float64(0.48509933774834435), np.float64(0.6241721854304636), np.float64(0.3609271523178808), np.float64(0.6324503311258278), np.float64(0.6076158940397351), np.float64(0.3956953642384106), np.float64(0.8708609271523179), np.float64(0.5993377483443708), np.float64(0.304635761589404)]
Tuning optimizer:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [07:50<07:46, 233.39s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Fold 1 Epoch 001; Train loss: 1.0024; Time: 00:00:02
Fold 1 Epoch 002; Train loss: 0.8452; Time: 00:00:02
Fold 1 Epoch 003; Train loss: 0.7109; Time: 00:00:02
Fold 1 Epoch 004; Train loss: 0.6071; Time: 00:00:02
Fold 1 Epoch 005; Train loss: 0.5209; Time: 00:00:02
Fold 1 Epoch 006; Train loss: 0.4568; Time: 00:00:02
Fold 1 Epoch 007; Train loss: 0.4090; Time: 00:00:02
Fold 1 Epoch 008; Train loss: 0.3633; Time: 00:00:02
Fold 1 Epoch 009; Train loss: 0.3383; Time: 00:00:02
Fold 1 Epoch 010; Train loss: 0.3118; Time: 00:00:02
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.412252   0.351211   0.536424   0.389954  
Loss: 0.4384
Fold 1 Epoch 011; Train loss: 0.2919; Time: 00:00:02
Fold 1 Epoch 012; Train loss: 0.2797; Time: 00:00:02
Fold 1 Epoch 013; Train loss: 0.2669; Time: 00:00:02
Fold 1 Epoch 014; Train loss: 0.2564; Time: 00:00:02
Fold 1 Epoch 015; Train loss: 0.2470; Time: 00:00:02
Fold 1 Epoch 016; Train loss: 0.2429; Time: 00:00:02
Fold 1 Epoch 017; Train loss: 0.2347; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.2241; Time: 00:00:02
Fold 1 Epoch 019; Train loss: 0.2203; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.2129; Time: 00:00:02
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.511589   0.404764   0.710265   0.467810  
Loss: 0.2975
Fold 1 Epoch 021; Train loss: 0.2025; Time: 00:00:02
Fold 1 Epoch 022; Train loss: 0.2012; Time: 00:00:02
Fold 1 Epoch 023; Train loss: 0.2029; Time: 00:00:02
Fold 1 Epoch 024; Train loss: 0.1930; Time: 00:00:02
Fold 1 Epoch 025; Train loss: 0.1914; Time: 00:00:02
Fold 1 Epoch 026; Train loss: 0.1905; Time: 00:00:02
Fold 1 Epoch 027; Train loss: 0.1878; Time: 00:00:02
Fold 1 Epoch 028; Train loss: 0.1842; Time: 00:00:02
Fold 1 Epoch 029; Train loss: 0.1877; Time: 00:00:02
Fold 1 Epoch 030; Train loss: 0.1801; Time: 00:00:02
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.554636   0.439993   0.683775   0.481204  
Loss: 0.2349
Fold 1 Epoch 031; Train loss: 0.1778; Time: 00:00:02
Fold 1 Epoch 032; Train loss: 0.1749; Time: 00:00:02
Fold 1 Epoch 033; Train loss: 0.1724; Time: 00:00:02
Fold 1 Epoch 034; Train loss: 0.1711; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.1728; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.1672; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.1697; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.1676; Time: 00:00:02
Fold 1 Epoch 039; Train loss: 0.1663; Time: 00:00:02
Fold 1 Epoch 040; Train loss: 0.1640; Time: 00:00:02
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.538079   0.440380   0.665563   0.480810  
Loss: 0.2124
Fold 1 Epoch 041; Train loss: 0.1638; Time: 00:00:02
Fold 1 Epoch 042; Train loss: 0.1620; Time: 00:00:02
Fold 1 Epoch 043; Train loss: 0.1574; Time: 00:00:02
Fold 1 Epoch 044; Train loss: 0.1582; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.1568; Time: 00:00:01
Fold 1 Epoch 046; Train loss: 0.1544; Time: 00:00:02
Fold 1 Epoch 047; Train loss: 0.1527; Time: 00:00:02
Fold 1 Epoch 048; Train loss: 0.1549; Time: 00:00:02
Fold 1 Epoch 049; Train loss: 0.1544; Time: 00:00:02
Fold 1 Epoch 050; Train loss: 0.1543; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.569536   0.456721   0.718543   0.504245  
Loss: 0.1881
Fold 1 Epoch 051; Train loss: 0.1502; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.1528; Time: 00:00:02
Fold 1 Epoch 053; Train loss: 0.1525; Time: 00:00:02
Fold 1 Epoch 054; Train loss: 0.1476; Time: 00:00:02
Fold 1 Epoch 055; Train loss: 0.1532; Time: 00:00:02
Fold 1 Epoch 056; Train loss: 0.1480; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.1500; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.1504; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.1472; Time: 00:00:02
Fold 1 Epoch 060; Train loss: 0.1458; Time: 00:00:02
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.567881   0.469320   0.697020   0.510578  
Loss: 0.1933
Fold 1 Epoch 061; Train loss: 0.1444; Time: 00:00:02
Fold 1 Epoch 062; Train loss: 0.1485; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.1496; Time: 00:00:02
Fold 1 Epoch 064; Train loss: 0.1446; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.1443; Time: 00:00:02
Fold 1 Epoch 066; Train loss: 0.1440; Time: 00:00:02
Fold 1 Epoch 067; Train loss: 0.1455; Time: 00:00:02
Fold 1 Epoch 068; Train loss: 0.1424; Time: 00:00:02
Fold 1 Epoch 069; Train loss: 0.1439; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.1427; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.609272   0.497858   0.736755   0.538642  
Loss: 0.1892
Fold 1 Epoch 071; Train loss: 0.1421; Time: 00:00:02
Fold 1 Epoch 072; Train loss: 0.1436; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.1424; Time: 00:00:02
Fold 1 Epoch 074; Train loss: 0.1414; Time: 00:00:02
Fold 1 Epoch 075; Train loss: 0.1401; Time: 00:00:02
Fold 1 Epoch 076; Train loss: 0.1430; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.1395; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.1401; Time: 00:00:02
Fold 1 Epoch 079; Train loss: 0.1425; Time: 00:00:02
Fold 1 Epoch 080; Train loss: 0.1395; Time: 00:00:02
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.592715   0.481784   0.708609   0.518948  
Loss: 0.1955
Fold 1 Epoch 081; Train loss: 0.1402; Time: 00:00:02
Fold 1 Epoch 082; Train loss: 0.1346; Time: 00:00:02
Fold 1 Epoch 083; Train loss: 0.1392; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.1403; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.1430; Time: 00:00:02
Fold 1 Epoch 086; Train loss: 0.1362; Time: 00:00:02
Fold 1 Epoch 087; Train loss: 0.1416; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.1382; Time: 00:00:02
Fold 1 Epoch 089; Train loss: 0.1381; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.1365; Time: 00:00:02
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.582781   0.477408   0.703642   0.516052  
Loss: 0.1876
Fold 1 Epoch 091; Train loss: 0.1365; Time: 00:00:02
Fold 1 Epoch 092; Train loss: 0.1353; Time: 00:00:02
Fold 1 Epoch 093; Train loss: 0.1366; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.1372; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.1379; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.1344; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.1387; Time: 00:00:02
Fold 1 Epoch 098; Train loss: 0.1410; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.1381; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.1343; Time: 00:00:02
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.600993   0.493127   0.706954   0.527398  
Loss: 0.1859
[optimizer candidate adabelief] Fold 1: HR@10 = [np.float64(0.5364238410596026), np.float64(0.7102649006622517), np.float64(0.6837748344370861), np.float64(0.6655629139072847), np.float64(0.7185430463576159), np.float64(0.6970198675496688), np.float64(0.7367549668874173), np.float64(0.7086092715231788), np.float64(0.7036423841059603), np.float64(0.706953642384106)]
Tuning optimizer:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [11:46<03:54, 234.52s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 64.0334; Time: 00:00:02
Fold 1 Epoch 002; Train loss: 1.7050; Time: 00:00:02
Fold 1 Epoch 003; Train loss: 0.3035; Time: 00:00:02
Fold 1 Epoch 004; Train loss: 0.2276; Time: 00:00:02
Fold 1 Epoch 005; Train loss: 0.3183; Time: 00:00:02
Fold 1 Epoch 006; Train loss: 0.3149; Time: 00:00:02
Fold 1 Epoch 007; Train loss: 0.1496; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1375; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.1240; Time: 00:00:02
Fold 1 Epoch 010; Train loss: 0.1178; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.447020   0.331561   0.622517   0.388722  
Loss: 0.1181
Fold 1 Epoch 011; Train loss: 0.1091; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.1164; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.1963; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.0991; Time: 00:00:02
Fold 1 Epoch 015; Train loss: 0.0849; Time: 00:00:02
Fold 1 Epoch 016; Train loss: 0.0823; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.0775; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.0727; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.0717; Time: 00:00:02
Fold 1 Epoch 020; Train loss: 0.0675; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.461921   0.346194   0.610927   0.394037  
Loss: 0.0777
Fold 1 Epoch 021; Train loss: 0.0628; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.0593; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0575; Time: 00:00:01
Fold 1 Epoch 024; Train loss: 0.0572; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0871; Time: 00:00:02
Fold 1 Epoch 026; Train loss: 0.0602; Time: 00:00:02
Fold 1 Epoch 027; Train loss: 0.0457; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0433; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0424; Time: 00:00:02
Fold 1 Epoch 030; Train loss: 0.0403; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.478477   0.353927   0.609272   0.396002  
Loss: 0.0365
Fold 1 Epoch 031; Train loss: 0.0375; Time: 00:00:02
Fold 1 Epoch 032; Train loss: 0.0367; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.0355; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.0325; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.0334; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.0350; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.0308; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0271; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0252; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0242; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.405629   0.339406   0.508278   0.371924  
Loss: 0.0202
Fold 1 Epoch 041; Train loss: 0.0224; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.0215; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0200; Time: 00:00:01
Fold 1 Epoch 044; Train loss: 0.0189; Time: 00:00:02
Fold 1 Epoch 045; Train loss: 0.0197; Time: 00:00:02
Fold 1 Epoch 046; Train loss: 0.0360; Time: 00:00:02
Fold 1 Epoch 047; Train loss: 0.0217; Time: 00:00:02
Fold 1 Epoch 048; Train loss: 0.0149; Time: 00:00:02
Fold 1 Epoch 049; Train loss: 0.0135; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.0118; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.374172   0.321726   0.690397   0.419333  
Loss: 0.0095
Fold 1 Epoch 051; Train loss: 0.0101; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.0087; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0069; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.0054; Time: 00:00:02
Fold 1 Epoch 055; Train loss: 0.0043; Time: 00:00:02
Fold 1 Epoch 056; Train loss: 0.0042; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.0058; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.0043; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.0023; Time: 00:00:02
Fold 1 Epoch 060; Train loss: 0.0011; Time: 00:00:02
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.437154   0.892384   0.461496  
Loss: 0.0008
Fold 1 Epoch 061; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 062; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 063; Train loss: 0.0005; Time: 00:00:03
Fold 1 Epoch 064; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 065; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 066; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 067; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 068; Train loss: 0.0013; Time: 00:00:02
Fold 1 Epoch 069; Train loss: 0.0021; Time: 00:00:02
Fold 1 Epoch 070; Train loss: 0.0024; Time: 00:00:02
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.411034   0.899007   0.524443  
Loss: 0.0015
Fold 1 Epoch 071; Train loss: 0.0018; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0010; Time: 00:00:02
Fold 1 Epoch 073; Train loss: 0.0008; Time: 00:00:02
Fold 1 Epoch 074; Train loss: 0.0008; Time: 00:00:02
Fold 1 Epoch 075; Train loss: 0.0011; Time: 00:00:02
Fold 1 Epoch 076; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0011; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0011; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0011; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.548299   0.899007   0.574199  
Loss: 0.0017
Fold 1 Epoch 081; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 083; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 085; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0010; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0017; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0017; Time: 00:00:02
Fold 1 Epoch 090; Train loss: 0.0012; Time: 00:00:02
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.434926   0.894040   0.544007  
Loss: 0.0016
Fold 1 Epoch 091; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 092; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 093; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 094; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 096; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 097; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0011; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0024; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.512871   0.899007   0.539128  
Loss: 0.0025
[optimizer candidate nadam] Fold 1: HR@10 = [np.float64(0.6225165562913907), np.float64(0.6109271523178808), np.float64(0.609271523178808), np.float64(0.5082781456953642), np.float64(0.6903973509933775), np.float64(0.8923841059602649), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8940397350993378), np.float64(0.8990066225165563)]
Tuning optimizer: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [15:27<00:00, 228.92s/it]Tuning optimizer: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [15:27<00:00, 231.77s/it]

Best optimizer found: nadam
Tuning timesteps:   0%|          | 0/4 [00:00<?, ?it/s]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 14.2955; Time: 00:00:02
Fold 1 Epoch 002; Train loss: 0.2485; Time: 00:00:02
Fold 1 Epoch 003; Train loss: 0.2247; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.1451; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 0.1318; Time: 00:00:01
Fold 1 Epoch 006; Train loss: 0.1177; Time: 00:00:01
Fold 1 Epoch 007; Train loss: 0.1097; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1134; Time: 00:00:02
Fold 1 Epoch 009; Train loss: 0.1166; Time: 00:00:02
Fold 1 Epoch 010; Train loss: 0.0872; Time: 00:00:02
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.488411   0.379328   0.619205   0.420976  
Loss: 0.0895
Fold 1 Epoch 011; Train loss: 0.0797; Time: 00:00:02
Fold 1 Epoch 012; Train loss: 0.0732; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.0689; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.0671; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.0789; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.0562; Time: 00:00:02
Fold 1 Epoch 017; Train loss: 0.0473; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.0446; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.0405; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0388; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.301325   0.234985   0.624172   0.340060  
Loss: 0.0292
Fold 1 Epoch 021; Train loss: 0.0370; Time: 00:00:02
Fold 1 Epoch 022; Train loss: 0.0359; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0489; Time: 00:00:02
Fold 1 Epoch 024; Train loss: 0.0442; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0275; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0251; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0245; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0218; Time: 00:00:02
Fold 1 Epoch 029; Train loss: 0.0225; Time: 00:00:02
Fold 1 Epoch 030; Train loss: 0.0211; Time: 00:00:02
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.311258   0.261797   0.513245   0.325469  
Loss: 0.0163
Fold 1 Epoch 031; Train loss: 0.0189; Time: 00:00:02
Fold 1 Epoch 032; Train loss: 0.0185; Time: 00:00:02
Fold 1 Epoch 033; Train loss: 0.0169; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.0168; Time: 00:00:02
Fold 1 Epoch 035; Train loss: 0.0290; Time: 00:00:02
Fold 1 Epoch 036; Train loss: 0.0229; Time: 00:00:02
Fold 1 Epoch 037; Train loss: 0.0108; Time: 00:00:02
Fold 1 Epoch 038; Train loss: 0.0082; Time: 00:00:02
Fold 1 Epoch 039; Train loss: 0.0060; Time: 00:00:02
Fold 1 Epoch 040; Train loss: 0.0043; Time: 00:00:02
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.549669   0.375221   0.642384   0.405265  
Loss: 0.0030
Fold 1 Epoch 041; Train loss: 0.0027; Time: 00:00:02
Fold 1 Epoch 042; Train loss: 0.0015; Time: 00:00:02
Fold 1 Epoch 043; Train loss: 0.0008; Time: 00:00:02
Fold 1 Epoch 044; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 045; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 046; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 047; Train loss: 0.0027; Time: 00:00:02
Fold 1 Epoch 048; Train loss: 0.0105; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.0045; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.0004; Time: 00:00:02
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.523870   0.895695   0.549872  
Loss: 0.0002
Fold 1 Epoch 051; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 052; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 053; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 054; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 055; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 056; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 057; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 058; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 059; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 060; Train loss: 0.0003; Time: 00:00:02
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.491814   0.899007   0.518071  
Loss: 0.0005
Fold 1 Epoch 061; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0045; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.0057; Time: 00:00:02
Fold 1 Epoch 064; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 065; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 066; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 067; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 068; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 069; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 070; Train loss: 0.0001; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.379602   0.892384   0.497714  
Loss: 0.0001
Fold 1 Epoch 071; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 072; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 074; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 075; Train loss: 0.0009; Time: 00:00:02
Fold 1 Epoch 076; Train loss: 0.0026; Time: 00:00:02
Fold 1 Epoch 077; Train loss: 0.0035; Time: 00:00:02
Fold 1 Epoch 078; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 080; Train loss: 0.0001; Time: 00:00:01
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.409873   0.899007   0.529899  
Loss: 0.0001
Fold 1 Epoch 081; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 082; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 083; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 084; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 086; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 088; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0018; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0045; Time: 00:00:02
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.614238   0.289279   0.890728   0.377218  
Loss: 0.0051
Fold 1 Epoch 091; Train loss: 0.0026; Time: 00:00:02
Fold 1 Epoch 092; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 093; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 096; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 097; Train loss: 0.0000; Time: 00:00:02
Fold 1 Epoch 098; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0000; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0000; Time: 00:00:02
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.892384   0.437032  
Loss: 0.0001
[timesteps candidate 200] Fold 1: HR@10 = [np.float64(0.6192052980132451), np.float64(0.6241721854304636), np.float64(0.5132450331125827), np.float64(0.6423841059602649), np.float64(0.8956953642384106), np.float64(0.8990066225165563), np.float64(0.8923841059602649), np.float64(0.8990066225165563), np.float64(0.890728476821192), np.float64(0.8923841059602649)]
Tuning timesteps:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [03:53<11:40, 233.39s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 19.3602; Time: 00:00:02
Fold 1 Epoch 002; Train loss: 0.4308; Time: 00:00:02
Fold 1 Epoch 003; Train loss: 0.3158; Time: 00:00:02
Fold 1 Epoch 004; Train loss: 0.6718; Time: 00:00:02
Fold 1 Epoch 005; Train loss: 0.2123; Time: 00:00:02
Fold 1 Epoch 006; Train loss: 0.1856; Time: 00:00:02
Fold 1 Epoch 007; Train loss: 0.1647; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1441; Time: 00:00:02
Fold 1 Epoch 009; Train loss: 0.1275; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.1087; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.428808   0.326333   0.538079   0.360770  
Loss: 0.1082
Fold 1 Epoch 011; Train loss: 0.0977; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.0976; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.1383; Time: 00:00:02
Fold 1 Epoch 014; Train loss: 0.0661; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.0524; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.0447; Time: 00:00:02
Fold 1 Epoch 017; Train loss: 0.0386; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.0325; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.0261; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0212; Time: 00:00:02
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.615894   0.357226   0.710265   0.387679  
Loss: 0.0146
Fold 1 Epoch 021; Train loss: 0.0163; Time: 00:00:02
Fold 1 Epoch 022; Train loss: 0.0122; Time: 00:00:02
Fold 1 Epoch 023; Train loss: 0.0169; Time: 00:00:02
Fold 1 Epoch 024; Train loss: 0.0717; Time: 00:00:02
Fold 1 Epoch 025; Train loss: 0.0066; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0020; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0011; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.0008; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.426778   0.899007   0.453360  
Loss: 0.0006
Fold 1 Epoch 031; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 032; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 034; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 035; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 040; Train loss: 0.0005; Time: 00:00:02
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.892384   0.437032  
Loss: 0.0003
Fold 1 Epoch 041; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 042; Train loss: 0.0022; Time: 00:00:02
Fold 1 Epoch 043; Train loss: 0.0132; Time: 00:00:02
Fold 1 Epoch 044; Train loss: 0.0145; Time: 00:00:02
Fold 1 Epoch 045; Train loss: 0.0010; Time: 00:00:02
Fold 1 Epoch 046; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 047; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 048; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 049; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 050; Train loss: 0.0003; Time: 00:00:02
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.323780   0.899007   0.444132  
Loss: 0.0003
Fold 1 Epoch 051; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 052; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 053; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 054; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 056; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 057; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 058; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 059; Train loss: 0.0030; Time: 00:00:02
Fold 1 Epoch 060; Train loss: 0.0108; Time: 00:00:02
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.105960   0.067026   0.362583   0.155840  
Loss: 0.0110
Fold 1 Epoch 061; Train loss: 0.0059; Time: 00:00:02
Fold 1 Epoch 062; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 063; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 066; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 067; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 068; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 070; Train loss: 0.0002; Time: 00:00:02
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.434926   0.899007   0.544969  
Loss: 0.0002
Fold 1 Epoch 071; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 072; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 073; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 075; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 078; Train loss: 0.0022; Time: 00:00:02
Fold 1 Epoch 079; Train loss: 0.0073; Time: 00:00:02
Fold 1 Epoch 080; Train loss: 0.0046; Time: 00:00:02
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.313532   0.892384   0.430681  
Loss: 0.0010
Fold 1 Epoch 081; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 082; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 083; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 084; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 085; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 086; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 087; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 088; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 089; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 090; Train loss: 0.0001; Time: 00:00:02
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.409873   0.899007   0.519500  
Loss: 0.0001
Fold 1 Epoch 091; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 094; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 095; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 097; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0027; Time: 00:00:02
Fold 1 Epoch 100; Train loss: 0.0035; Time: 00:00:02
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.518212   0.220914   0.857616   0.321461  
Loss: 0.0039
[timesteps candidate 400] Fold 1: HR@10 = [np.float64(0.5380794701986755), np.float64(0.7102649006622517), np.float64(0.8990066225165563), np.float64(0.8923841059602649), np.float64(0.8990066225165563), np.float64(0.36258278145695366), np.float64(0.8990066225165563), np.float64(0.8923841059602649), np.float64(0.8990066225165563), np.float64(0.8576158940397351)]
Tuning timesteps:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [07:55<07:56, 238.47s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 11.9298; Time: 00:00:02
Fold 1 Epoch 002; Train loss: 0.6931; Time: 00:00:02
Fold 1 Epoch 003; Train loss: 0.3312; Time: 00:00:02
Fold 1 Epoch 004; Train loss: 0.3400; Time: 00:00:02
Fold 1 Epoch 005; Train loss: 0.2386; Time: 00:00:02
Fold 1 Epoch 006; Train loss: 0.1608; Time: 00:00:02
Fold 1 Epoch 007; Train loss: 0.1266; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.0981; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.0803; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.1240; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.581126   0.424148   0.683775   0.457162  
Loss: 0.0868
Fold 1 Epoch 011; Train loss: 0.0578; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.0305; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.0205; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.0130; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.0078; Time: 00:00:01
Fold 1 Epoch 016; Train loss: 0.0047; Time: 00:00:01
Fold 1 Epoch 017; Train loss: 0.0034; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.0026; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.0022; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0020; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.537924   0.897351   0.564444  
Loss: 0.0008
Fold 1 Epoch 021; Train loss: 0.0042; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.0177; Time: 00:00:01
Fold 1 Epoch 023; Train loss: 0.0137; Time: 00:00:02
Fold 1 Epoch 024; Train loss: 0.0020; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 026; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0011; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 029; Train loss: 0.0019; Time: 00:00:02
Fold 1 Epoch 030; Train loss: 0.0039; Time: 00:00:02
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.241142   0.897351   0.355035  
Loss: 0.0058
Fold 1 Epoch 031; Train loss: 0.0064; Time: 00:00:02
Fold 1 Epoch 032; Train loss: 0.0028; Time: 00:00:01
Fold 1 Epoch 033; Train loss: 0.0009; Time: 00:00:02
Fold 1 Epoch 034; Train loss: 0.0008; Time: 00:00:02
Fold 1 Epoch 035; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 036; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 039; Train loss: 0.0025; Time: 00:00:02
Fold 1 Epoch 040; Train loss: 0.0054; Time: 00:00:02
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.299411   0.897351   0.412561  
Loss: 0.0044
Fold 1 Epoch 041; Train loss: 0.0046; Time: 00:00:02
Fold 1 Epoch 042; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 044; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 045; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 046; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 047; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 048; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.0003; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.543046   0.431723   0.892384   0.542801  
Loss: 0.0002
Fold 1 Epoch 051; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 052; Train loss: 0.0014; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0033; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.0041; Time: 00:00:02
Fold 1 Epoch 055; Train loss: 0.0012; Time: 00:00:02
Fold 1 Epoch 056; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 058; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 059; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.0003; Time: 00:00:01
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.537924   0.899007   0.564180  
Loss: 0.0004
Fold 1 Epoch 061; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.0017; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0022; Time: 00:00:02
Fold 1 Epoch 065; Train loss: 0.0014; Time: 00:00:02
Fold 1 Epoch 066; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 067; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 069; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 070; Train loss: 0.0002; Time: 00:00:02
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.814570   0.515379   0.899007   0.541636  
Loss: 0.0001
Fold 1 Epoch 071; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 072; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 073; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 074; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 075; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 076; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0010; Time: 00:00:02
Fold 1 Epoch 078; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 080; Train loss: 0.0004; Time: 00:00:02
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.436086   0.867550   0.546663  
Loss: 0.0001
Fold 1 Epoch 081; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 085; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 090; Train loss: 0.0005; Time: 00:00:02
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.897351   0.438833  
Loss: 0.0004
Fold 1 Epoch 091; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0012; Time: 00:00:02
Fold 1 Epoch 093; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 094; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 095; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 098; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 099; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 100; Train loss: 0.0001; Time: 00:00:01
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.788079   0.503971   0.899007   0.539664  
Loss: 0.0001
[timesteps candidate 600] Fold 1: HR@10 = [np.float64(0.6837748344370861), np.float64(0.8973509933774835), np.float64(0.8973509933774835), np.float64(0.8973509933774835), np.float64(0.8923841059602649), np.float64(0.8990066225165563), np.float64(0.8990066225165563), np.float64(0.8675496688741722), np.float64(0.8973509933774835), np.float64(0.8990066225165563)]
Tuning timesteps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [11:46<03:55, 235.13s/it]
========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 14.3403; Time: 00:00:01
Fold 1 Epoch 002; Train loss: 0.4493; Time: 00:00:02
Fold 1 Epoch 003; Train loss: 0.3409; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.3214; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 0.2536; Time: 00:00:02
Fold 1 Epoch 006; Train loss: 0.1860; Time: 00:00:01
Fold 1 Epoch 007; Train loss: 0.1459; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1113; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.0883; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.1618; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.410596   0.312078   0.774834   0.426440  
Loss: 0.0729
Fold 1 Epoch 011; Train loss: 0.0499; Time: 00:00:02
Fold 1 Epoch 012; Train loss: 0.0333; Time: 00:00:01
Fold 1 Epoch 013; Train loss: 0.0222; Time: 00:00:01
Fold 1 Epoch 014; Train loss: 0.0148; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.0095; Time: 00:00:02
Fold 1 Epoch 016; Train loss: 0.0061; Time: 00:00:02
Fold 1 Epoch 017; Train loss: 0.0041; Time: 00:00:01
Fold 1 Epoch 018; Train loss: 0.0029; Time: 00:00:01
Fold 1 Epoch 019; Train loss: 0.0021; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0018; Time: 00:00:01
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.325613   0.867550   0.436190  
Loss: 0.0009
Fold 1 Epoch 021; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.0030; Time: 00:00:02
Fold 1 Epoch 023; Train loss: 0.0233; Time: 00:00:02
Fold 1 Epoch 024; Train loss: 0.0144; Time: 00:00:01
Fold 1 Epoch 025; Train loss: 0.0013; Time: 00:00:02
Fold 1 Epoch 026; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 027; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 028; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 029; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 030; Train loss: 0.0006; Time: 00:00:02
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.412381   0.897351   0.532255  
Loss: 0.0008
Fold 1 Epoch 031; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.0015; Time: 00:00:02
Fold 1 Epoch 033; Train loss: 0.0042; Time: 00:00:02
Fold 1 Epoch 034; Train loss: 0.0141; Time: 00:00:02
Fold 1 Epoch 035; Train loss: 0.0088; Time: 00:00:02
Fold 1 Epoch 036; Train loss: 0.0011; Time: 00:00:01
Fold 1 Epoch 037; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 038; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 039; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0004; Time: 00:00:01
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.899007   0.534322  
Loss: 0.0004
Fold 1 Epoch 041; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 043; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 044; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.0032; Time: 00:00:02
Fold 1 Epoch 046; Train loss: 0.0163; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.0068; Time: 00:00:02
Fold 1 Epoch 048; Train loss: 0.0005; Time: 00:00:02
Fold 1 Epoch 049; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 050; Train loss: 0.0003; Time: 00:00:02
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.892384   0.443244  
Loss: 0.0003
Fold 1 Epoch 051; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 054; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 056; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 057; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 058; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 059; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 060; Train loss: 0.0028; Time: 00:00:02
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.788079   0.404426   0.902318   0.440721  
Loss: 0.0062
Fold 1 Epoch 061; Train loss: 0.0063; Time: 00:00:01
Fold 1 Epoch 062; Train loss: 0.0038; Time: 00:00:02
Fold 1 Epoch 063; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 066; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 067; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 069; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0001; Time: 00:00:02
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.788079   0.415369   0.892384   0.449473  
Loss: 0.0002
Fold 1 Epoch 071; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 075; Train loss: 0.0012; Time: 00:00:02
Fold 1 Epoch 076; Train loss: 0.0077; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0087; Time: 00:00:01
Fold 1 Epoch 078; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 079; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 080; Train loss: 0.0001; Time: 00:00:02
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.556291   0.301895   0.897351   0.411009  
Loss: 0.0001
Fold 1 Epoch 081; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 083; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 084; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 085; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 088; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 089; Train loss: 0.0001; Time: 00:00:02
Fold 1 Epoch 090; Train loss: 0.0001; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.897351   0.528542  
Loss: 0.0001
Fold 1 Epoch 091; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.0001; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0030; Time: 00:00:01
Fold 1 Epoch 098; Train loss: 0.0082; Time: 00:00:02
Fold 1 Epoch 099; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0001; Time: 00:00:02
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.556291   0.280001   0.892384   0.391721  
Loss: 0.0001
[timesteps candidate 800] Fold 1: HR@10 = [np.float64(0.7748344370860927), np.float64(0.8675496688741722), np.float64(0.8973509933774835), np.float64(0.8990066225165563), np.float64(0.8923841059602649), np.float64(0.902317880794702), np.float64(0.8923841059602649), np.float64(0.8973509933774835), np.float64(0.8973509933774835), np.float64(0.8923841059602649)]
Tuning timesteps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [15:26<00:00, 229.15s/it]Tuning timesteps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [15:26<00:00, 231.64s/it]

Best timesteps found: 600
Tuning data for lr saved to ./category/tuning_lr.json
Tuning data for optimizer saved to ./category/tuning_optimizer.json
Tuning data for timesteps saved to ./category/tuning_timesteps.json

========== Fold 1 ==========
INFO:root:Using statics: seq_size = 10, genre_vocab_size = 18
Fold 1 Epoch 001; Train loss: 16.6147; Time: 00:00:01
Fold 1 Epoch 002; Train loss: 0.5396; Time: 00:00:01
Fold 1 Epoch 003; Train loss: 1.0581; Time: 00:00:01
Fold 1 Epoch 004; Train loss: 0.2800; Time: 00:00:01
Fold 1 Epoch 005; Train loss: 0.2359; Time: 00:00:02
Fold 1 Epoch 006; Train loss: 0.1978; Time: 00:00:02
Fold 1 Epoch 007; Train loss: 0.1619; Time: 00:00:01
Fold 1 Epoch 008; Train loss: 0.1338; Time: 00:00:01
Fold 1 Epoch 009; Train loss: 0.1069; Time: 00:00:01
Fold 1 Epoch 010; Train loss: 0.0847; Time: 00:00:01
Fold 1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.675497   0.443702   0.880795   0.510668  
Loss: 0.0829
Fold 1 Epoch 011; Train loss: 0.0683; Time: 00:00:01
Fold 1 Epoch 012; Train loss: 0.0565; Time: 00:00:02
Fold 1 Epoch 013; Train loss: 0.0983; Time: 00:00:02
Fold 1 Epoch 014; Train loss: 0.0469; Time: 00:00:01
Fold 1 Epoch 015; Train loss: 0.0196; Time: 00:00:02
Fold 1 Epoch 016; Train loss: 0.0128; Time: 00:00:02
Fold 1 Epoch 017; Train loss: 0.0083; Time: 00:00:02
Fold 1 Epoch 018; Train loss: 0.0056; Time: 00:00:02
Fold 1 Epoch 019; Train loss: 0.0041; Time: 00:00:01
Fold 1 Epoch 020; Train loss: 0.0035; Time: 00:00:02
Fold 1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.402318   0.248033   0.897351   0.417114  
Loss: 0.0028
Fold 1 Epoch 021; Train loss: 0.0030; Time: 00:00:01
Fold 1 Epoch 022; Train loss: 0.0040; Time: 00:00:02
Fold 1 Epoch 023; Train loss: 0.0082; Time: 00:00:02
Fold 1 Epoch 024; Train loss: 0.0159; Time: 00:00:02
Fold 1 Epoch 025; Train loss: 0.0091; Time: 00:00:02
Fold 1 Epoch 026; Train loss: 0.0028; Time: 00:00:02
Fold 1 Epoch 027; Train loss: 0.0018; Time: 00:00:02
Fold 1 Epoch 028; Train loss: 0.0015; Time: 00:00:02
Fold 1 Epoch 029; Train loss: 0.0013; Time: 00:00:01
Fold 1 Epoch 030; Train loss: 0.0013; Time: 00:00:01
Fold 1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.402134   0.899007   0.525575  
Loss: 0.0008
Fold 1 Epoch 031; Train loss: 0.0012; Time: 00:00:01
Fold 1 Epoch 032; Train loss: 0.0012; Time: 00:00:02
Fold 1 Epoch 033; Train loss: 0.0014; Time: 00:00:02
Fold 1 Epoch 034; Train loss: 0.0027; Time: 00:00:02
Fold 1 Epoch 035; Train loss: 0.0133; Time: 00:00:02
Fold 1 Epoch 036; Train loss: 0.0156; Time: 00:00:02
Fold 1 Epoch 037; Train loss: 0.0014; Time: 00:00:02
Fold 1 Epoch 038; Train loss: 0.0008; Time: 00:00:02
Fold 1 Epoch 039; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 040; Train loss: 0.0007; Time: 00:00:02
Fold 1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.413542   0.925497   0.535205  
Loss: 0.0007
Fold 1 Epoch 041; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 042; Train loss: 0.0007; Time: 00:00:02
Fold 1 Epoch 043; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 044; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 045; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 046; Train loss: 0.0018; Time: 00:00:01
Fold 1 Epoch 047; Train loss: 0.0045; Time: 00:00:02
Fold 1 Epoch 048; Train loss: 0.0046; Time: 00:00:01
Fold 1 Epoch 049; Train loss: 0.0018; Time: 00:00:01
Fold 1 Epoch 050; Train loss: 0.0007; Time: 00:00:01
Fold 1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.313532   0.897351   0.436495  
Loss: 0.0007
Fold 1 Epoch 051; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 052; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 053; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 054; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 055; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 056; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 057; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 058; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 059; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 060; Train loss: 0.0042; Time: 00:00:02
Fold 1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.227897   0.897351   0.346691  
Loss: 0.0120
Fold 1 Epoch 061; Train loss: 0.0088; Time: 00:00:02
Fold 1 Epoch 062; Train loss: 0.0020; Time: 00:00:01
Fold 1 Epoch 063; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 064; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 065; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 066; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 067; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 068; Train loss: 0.0002; Time: 00:00:02
Fold 1 Epoch 069; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 070; Train loss: 0.0002; Time: 00:00:01
Fold 1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.412381   0.892384   0.524472  
Loss: 0.0003
Fold 1 Epoch 071; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 072; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 073; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 074; Train loss: 0.0004; Time: 00:00:02
Fold 1 Epoch 075; Train loss: 0.0006; Time: 00:00:02
Fold 1 Epoch 076; Train loss: 0.0015; Time: 00:00:01
Fold 1 Epoch 077; Train loss: 0.0026; Time: 00:00:02
Fold 1 Epoch 078; Train loss: 0.0015; Time: 00:00:02
Fold 1 Epoch 079; Train loss: 0.0003; Time: 00:00:02
Fold 1 Epoch 080; Train loss: 0.0002; Time: 00:00:02
Fold 1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.316053   0.892384   0.434919  
Loss: 0.0001
Fold 1 Epoch 081; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 082; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 083; Train loss: 0.0010; Time: 00:00:01
Fold 1 Epoch 084; Train loss: 0.0011; Time: 00:00:02
Fold 1 Epoch 085; Train loss: 0.0009; Time: 00:00:01
Fold 1 Epoch 086; Train loss: 0.0008; Time: 00:00:01
Fold 1 Epoch 087; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 088; Train loss: 0.0005; Time: 00:00:01
Fold 1 Epoch 089; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 090; Train loss: 0.0003; Time: 00:00:01
Fold 1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.524834   0.304645   0.899007   0.433693  
Loss: 0.0001
Fold 1 Epoch 091; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 092; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 093; Train loss: 0.0002; Time: 00:00:01
Fold 1 Epoch 094; Train loss: 0.0003; Time: 00:00:01
Fold 1 Epoch 095; Train loss: 0.0006; Time: 00:00:01
Fold 1 Epoch 096; Train loss: 0.0016; Time: 00:00:01
Fold 1 Epoch 097; Train loss: 0.0015; Time: 00:00:02
Fold 1 Epoch 098; Train loss: 0.0007; Time: 00:00:01
Fold 1 Epoch 099; Train loss: 0.0004; Time: 00:00:01
Fold 1 Epoch 100; Train loss: 0.0002; Time: 00:00:02
Fold 1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.551325   0.324941   0.892384   0.437032  
Loss: 0.0001
Tuning fold metrics saved to ./category/fold_metrics_tune.txt
Best candidates saved to ./category/best_candidates.json

========== Running Experimental Folds for Genre Model ==========

========== Experiment p1 ==========
Experiment p1 Epoch 001; Train loss: 13.9956; Time: 00:00:01
Experiment p1 Epoch 002; Train loss: 0.4189; Time: 00:00:01
Experiment p1 Epoch 003; Train loss: 0.4063; Time: 00:00:01
Experiment p1 Epoch 004; Train loss: 0.2508; Time: 00:00:01
Experiment p1 Epoch 005; Train loss: 0.2046; Time: 00:00:01
Experiment p1 Epoch 006; Train loss: 0.1672; Time: 00:00:01
Experiment p1 Epoch 007; Train loss: 0.1302; Time: 00:00:01
Experiment p1 Epoch 008; Train loss: 0.1158; Time: 00:00:01
Experiment p1 Epoch 009; Train loss: 0.1391; Time: 00:00:01
Experiment p1 Epoch 010; Train loss: 0.0750; Time: 00:00:01
Experiment p1: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.451987   0.369586   0.584437   0.411712  
Loss: 0.0566
Experiment p1 Epoch 011; Train loss: 0.0480; Time: 00:00:01
Experiment p1 Epoch 012; Train loss: 0.0356; Time: 00:00:02
Experiment p1 Epoch 013; Train loss: 0.0249; Time: 00:00:01
Experiment p1 Epoch 014; Train loss: 0.0175; Time: 00:00:01
Experiment p1 Epoch 015; Train loss: 0.0120; Time: 00:00:02
Experiment p1 Epoch 016; Train loss: 0.0083; Time: 00:00:02
Experiment p1 Epoch 017; Train loss: 0.0098; Time: 00:00:01
Experiment p1 Epoch 018; Train loss: 0.0208; Time: 00:00:01
Experiment p1 Epoch 019; Train loss: 0.0166; Time: 00:00:01
Experiment p1 Epoch 020; Train loss: 0.0030; Time: 00:00:01
Experiment p1: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.564570   0.433568   0.916391   0.554988  
Loss: 0.0008
Experiment p1 Epoch 021; Train loss: 0.0018; Time: 00:00:01
Experiment p1 Epoch 022; Train loss: 0.0016; Time: 00:00:01
Experiment p1 Epoch 023; Train loss: 0.0014; Time: 00:00:02
Experiment p1 Epoch 024; Train loss: 0.0014; Time: 00:00:01
Experiment p1 Epoch 025; Train loss: 0.0014; Time: 00:00:01
Experiment p1 Epoch 026; Train loss: 0.0012; Time: 00:00:01
Experiment p1 Epoch 027; Train loss: 0.0013; Time: 00:00:01
Experiment p1 Epoch 028; Train loss: 0.0017; Time: 00:00:01
Experiment p1 Epoch 029; Train loss: 0.0037; Time: 00:00:02
Experiment p1 Epoch 030; Train loss: 0.0103; Time: 00:00:01
Experiment p1: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.522351   0.232400   0.905629   0.347532  
Loss: 0.0119
Experiment p1 Epoch 031; Train loss: 0.0137; Time: 00:00:01
Experiment p1 Epoch 032; Train loss: 0.0034; Time: 00:00:01
Experiment p1 Epoch 033; Train loss: 0.0008; Time: 00:00:02
Experiment p1 Epoch 034; Train loss: 0.0007; Time: 00:00:01
Experiment p1 Epoch 035; Train loss: 0.0006; Time: 00:00:02
Experiment p1 Epoch 036; Train loss: 0.0006; Time: 00:00:01
Experiment p1 Epoch 037; Train loss: 0.0005; Time: 00:00:01
Experiment p1 Epoch 038; Train loss: 0.0005; Time: 00:00:01
Experiment p1 Epoch 039; Train loss: 0.0005; Time: 00:00:01
Experiment p1 Epoch 040; Train loss: 0.0005; Time: 00:00:01
Experiment p1: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.539735   0.422872   0.899007   0.542465  
Loss: 0.0004
Experiment p1 Epoch 041; Train loss: 0.0005; Time: 00:00:01
Experiment p1 Epoch 042; Train loss: 0.0005; Time: 00:00:01
Experiment p1 Epoch 043; Train loss: 0.0006; Time: 00:00:01
Experiment p1 Epoch 044; Train loss: 0.0017; Time: 00:00:01
Experiment p1 Epoch 045; Train loss: 0.0068; Time: 00:00:01
Experiment p1 Epoch 046; Train loss: 0.0077; Time: 00:00:01
Experiment p1 Epoch 047; Train loss: 0.0019; Time: 00:00:01
Experiment p1 Epoch 048; Train loss: 0.0005; Time: 00:00:01
Experiment p1 Epoch 049; Train loss: 0.0003; Time: 00:00:01
Experiment p1 Epoch 050; Train loss: 0.0003; Time: 00:00:02
Experiment p1: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.791391   0.531254   0.939570   0.577952  
Loss: 0.0002
Experiment p1 Epoch 051; Train loss: 0.0003; Time: 00:00:01
Experiment p1 Epoch 052; Train loss: 0.0003; Time: 00:00:02
Experiment p1 Epoch 053; Train loss: 0.0003; Time: 00:00:01
Experiment p1 Epoch 054; Train loss: 0.0003; Time: 00:00:01
Experiment p1 Epoch 055; Train loss: 0.0002; Time: 00:00:01
Experiment p1 Epoch 056; Train loss: 0.0002; Time: 00:00:01
Experiment p1 Epoch 057; Train loss: 0.0002; Time: 00:00:01
Experiment p1 Epoch 058; Train loss: 0.0002; Time: 00:00:02
Experiment p1 Epoch 059; Train loss: 0.0002; Time: 00:00:01
Experiment p1 Epoch 060; Train loss: 0.0003; Time: 00:00:01
Experiment p1: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.564570   0.329183   0.916391   0.450544  
Loss: 0.0003
Experiment p1 Epoch 061; Train loss: 0.0009; Time: 00:00:01
Experiment p1 Epoch 062; Train loss: 0.0039; Time: 00:00:01
Experiment p1 Epoch 063; Train loss: 0.0069; Time: 00:00:01
Experiment p1 Epoch 064; Train loss: 0.0018; Time: 00:00:01
Experiment p1 Epoch 065; Train loss: 0.0003; Time: 00:00:01
Experiment p1 Epoch 066; Train loss: 0.0002; Time: 00:00:01
Experiment p1 Epoch 067; Train loss: 0.0002; Time: 00:00:02
Experiment p1 Epoch 068; Train loss: 0.0002; Time: 00:00:02
Experiment p1 Epoch 069; Train loss: 0.0002; Time: 00:00:01
Experiment p1 Epoch 070; Train loss: 0.0002; Time: 00:00:01
Experiment p1: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.539735   0.402097   0.916391   0.526547  
Loss: 0.0002
Experiment p1 Epoch 071; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 072; Train loss: 0.0001; Time: 00:00:02
Experiment p1 Epoch 073; Train loss: 0.0001; Time: 00:00:02
Experiment p1 Epoch 074; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 075; Train loss: 0.0001; Time: 00:00:02
Experiment p1 Epoch 076; Train loss: 0.0001; Time: 00:00:02
Experiment p1 Epoch 077; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 078; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 079; Train loss: 0.0002; Time: 00:00:02
Experiment p1 Epoch 080; Train loss: 0.0006; Time: 00:00:01
Experiment p1: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.371689   0.314096   0.653974   0.407371  
Loss: 0.0015
Experiment p1 Epoch 081; Train loss: 0.0024; Time: 00:00:01
Experiment p1 Epoch 082; Train loss: 0.0056; Time: 00:00:01
Experiment p1 Epoch 083; Train loss: 0.0017; Time: 00:00:01
Experiment p1 Epoch 084; Train loss: 0.0003; Time: 00:00:01
Experiment p1 Epoch 085; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 086; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 087; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 088; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 089; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 090; Train loss: 0.0001; Time: 00:00:01
Experiment p1: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.564570   0.433568   0.916391   0.549172  
Loss: 0.0001
Experiment p1 Epoch 091; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 092; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 093; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 094; Train loss: 0.0001; Time: 00:00:02
Experiment p1 Epoch 095; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 096; Train loss: 0.0002; Time: 00:00:01
Experiment p1 Epoch 097; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 098; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 099; Train loss: 0.0001; Time: 00:00:01
Experiment p1 Epoch 100; Train loss: 0.0002; Time: 00:00:01
Experiment p1: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.564570   0.383528   0.916391   0.494848  
Loss: 0.0003

========== Experiment p2 ==========
Experiment p2 Epoch 001; Train loss: 12.2754; Time: 00:00:01
Experiment p2 Epoch 002; Train loss: 0.4705; Time: 00:00:01
Experiment p2 Epoch 003; Train loss: 0.5431; Time: 00:00:01
Experiment p2 Epoch 004; Train loss: 0.2885; Time: 00:00:02
Experiment p2 Epoch 005; Train loss: 0.2141; Time: 00:00:01
Experiment p2 Epoch 006; Train loss: 0.1726; Time: 00:00:01
Experiment p2 Epoch 007; Train loss: 0.1446; Time: 00:00:02
Experiment p2 Epoch 008; Train loss: 0.1546; Time: 00:00:02
Experiment p2 Epoch 009; Train loss: 0.2137; Time: 00:00:01
Experiment p2 Epoch 010; Train loss: 0.0646; Time: 00:00:01
Experiment p2: Evaluation at Epoch 10
HR@5       NDCG@5     HR@10      NDCG@10   
0.627483   0.347117   0.731788   0.380035  
Loss: 0.0532
Experiment p2 Epoch 011; Train loss: 0.0466; Time: 00:00:02
Experiment p2 Epoch 012; Train loss: 0.0334; Time: 00:00:01
Experiment p2 Epoch 013; Train loss: 0.0225; Time: 00:00:01
Experiment p2 Epoch 014; Train loss: 0.0145; Time: 00:00:01
Experiment p2 Epoch 015; Train loss: 0.0085; Time: 00:00:02
Experiment p2 Epoch 016; Train loss: 0.0050; Time: 00:00:02
Experiment p2 Epoch 017; Train loss: 0.0029; Time: 00:00:01
Experiment p2 Epoch 018; Train loss: 0.0019; Time: 00:00:02
Experiment p2 Epoch 019; Train loss: 0.0015; Time: 00:00:02
Experiment p2 Epoch 020; Train loss: 0.0013; Time: 00:00:01
Experiment p2: Evaluation at Epoch 20
HR@5       NDCG@5     HR@10      NDCG@10   
0.513245   0.272111   0.875000   0.387851  
Loss: 0.0006
Experiment p2 Epoch 021; Train loss: 0.0012; Time: 00:00:01
Experiment p2 Epoch 022; Train loss: 0.0032; Time: 00:00:02
Experiment p2 Epoch 023; Train loss: 0.0436; Time: 00:00:02
Experiment p2 Epoch 024; Train loss: 0.0473; Time: 00:00:01
Experiment p2 Epoch 025; Train loss: 0.0018; Time: 00:00:02
Experiment p2 Epoch 026; Train loss: 0.0009; Time: 00:00:01
Experiment p2 Epoch 027; Train loss: 0.0007; Time: 00:00:02
Experiment p2 Epoch 028; Train loss: 0.0007; Time: 00:00:01
Experiment p2 Epoch 029; Train loss: 0.0006; Time: 00:00:01
Experiment p2 Epoch 030; Train loss: 0.0006; Time: 00:00:01
Experiment p2: Evaluation at Epoch 30
HR@5       NDCG@5     HR@10      NDCG@10   
0.513245   0.286772   0.893212   0.408307  
Loss: 0.0004
Experiment p2 Epoch 031; Train loss: 0.0006; Time: 00:00:01
Experiment p2 Epoch 032; Train loss: 0.0007; Time: 00:00:01
Experiment p2 Epoch 033; Train loss: 0.0013; Time: 00:00:01
Experiment p2 Epoch 034; Train loss: 0.0055; Time: 00:00:01
Experiment p2 Epoch 035; Train loss: 0.0073; Time: 00:00:01
Experiment p2 Epoch 036; Train loss: 0.0028; Time: 00:00:01
Experiment p2 Epoch 037; Train loss: 0.0014; Time: 00:00:02
Experiment p2 Epoch 038; Train loss: 0.0010; Time: 00:00:01
Experiment p2 Epoch 039; Train loss: 0.0011; Time: 00:00:01
Experiment p2 Epoch 040; Train loss: 0.0022; Time: 00:00:01
Experiment p2: Evaluation at Epoch 40
HR@5       NDCG@5     HR@10      NDCG@10   
0.355132   0.153961   0.651490   0.245415  
Loss: 0.0056
Experiment p2 Epoch 041; Train loss: 0.0068; Time: 00:00:01
Experiment p2 Epoch 042; Train loss: 0.0118; Time: 00:00:02
Experiment p2 Epoch 043; Train loss: 0.0099; Time: 00:00:02
Experiment p2 Epoch 044; Train loss: 0.0033; Time: 00:00:01
Experiment p2 Epoch 045; Train loss: 0.0006; Time: 00:00:01
Experiment p2 Epoch 046; Train loss: 0.0003; Time: 00:00:01
Experiment p2 Epoch 047; Train loss: 0.0003; Time: 00:00:01
Experiment p2 Epoch 048; Train loss: 0.0003; Time: 00:00:02
Experiment p2 Epoch 049; Train loss: 0.0003; Time: 00:00:01
Experiment p2 Epoch 050; Train loss: 0.0002; Time: 00:00:01
Experiment p2: Evaluation at Epoch 50
HR@5       NDCG@5     HR@10      NDCG@10   
0.552980   0.295935   0.875000   0.398430  
Loss: 0.0003
Experiment p2 Epoch 051; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 052; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 053; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 054; Train loss: 0.0003; Time: 00:00:01
Experiment p2 Epoch 055; Train loss: 0.0016; Time: 00:00:01
Experiment p2 Epoch 056; Train loss: 0.0115; Time: 00:00:01
Experiment p2 Epoch 057; Train loss: 0.0267; Time: 00:00:01
Experiment p2 Epoch 058; Train loss: 0.0055; Time: 00:00:01
Experiment p2 Epoch 059; Train loss: 0.0003; Time: 00:00:01
Experiment p2 Epoch 060; Train loss: 0.0002; Time: 00:00:01
Experiment p2: Evaluation at Epoch 60
HR@5       NDCG@5     HR@10      NDCG@10   
0.513245   0.379651   0.872517   0.491738  
Loss: 0.0002
Experiment p2 Epoch 061; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 062; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 063; Train loss: 0.0002; Time: 00:00:02
Experiment p2 Epoch 064; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 065; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 066; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 067; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 068; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 069; Train loss: 0.0001; Time: 00:00:02
Experiment p2 Epoch 070; Train loss: 0.0001; Time: 00:00:02
Experiment p2: Evaluation at Epoch 70
HR@5       NDCG@5     HR@10      NDCG@10   
0.360099   0.212866   0.875000   0.380222  
Loss: 0.0002
Experiment p2 Epoch 071; Train loss: 0.0001; Time: 00:00:02
Experiment p2 Epoch 072; Train loss: 0.0001; Time: 00:00:02
Experiment p2 Epoch 073; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 074; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 075; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 076; Train loss: 0.0001; Time: 00:00:02
Experiment p2 Epoch 077; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 078; Train loss: 0.0001; Time: 00:00:02
Experiment p2 Epoch 079; Train loss: 0.0003; Time: 00:00:02
Experiment p2 Epoch 080; Train loss: 0.0018; Time: 00:00:02
Experiment p2: Evaluation at Epoch 80
HR@5       NDCG@5     HR@10      NDCG@10   
0.529801   0.363229   0.856788   0.463143  
Loss: 0.0052
Experiment p2 Epoch 081; Train loss: 0.0113; Time: 00:00:01
Experiment p2 Epoch 082; Train loss: 0.0129; Time: 00:00:01
Experiment p2 Epoch 083; Train loss: 0.0011; Time: 00:00:02
Experiment p2 Epoch 084; Train loss: 0.0002; Time: 00:00:01
Experiment p2 Epoch 085; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 086; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 087; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 088; Train loss: 0.0001; Time: 00:00:02
Experiment p2 Epoch 089; Train loss: 0.0001; Time: 00:00:02
Experiment p2 Epoch 090; Train loss: 0.0001; Time: 00:00:02
Experiment p2: Evaluation at Epoch 90
HR@5       NDCG@5     HR@10      NDCG@10   
0.513245   0.379651   0.875000   0.495391  
Loss: 0.0001
Experiment p2 Epoch 091; Train loss: 0.0001; Time: 00:00:02
Experiment p2 Epoch 092; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 093; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 094; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 095; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 096; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 097; Train loss: 0.0001; Time: 00:00:02
Experiment p2 Epoch 098; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 099; Train loss: 0.0001; Time: 00:00:01
Experiment p2 Epoch 100; Train loss: 0.0001; Time: 00:00:01
Experiment p2: Evaluation at Epoch 100
HR@5       NDCG@5     HR@10      NDCG@10   
0.513245   0.379651   0.875000   0.495391  
Loss: 0.0001
Experimental fold metrics saved to category/genre_exp_p1_metrics.txt and category/genre_exp_p2_metrics.txt
